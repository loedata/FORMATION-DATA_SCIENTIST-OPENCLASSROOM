{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# REDUIRE lES DIMENSIONS ET IMAGE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Les données\n",
    "\n",
    "# La vidéo dure 1 h 36, et contient 174 053 images. Une image est composée de\n",
    "# pixels. \n",
    "# Chaque image mesure 640 pixels en largeur et 360 en hauteur, soit 230 400 \n",
    "# pixels ! En plus, la couleur d'un pixel est encodée selon 3 niveaux : rouge, \n",
    "# vert et bleu. On a donc 174 053 * 230 400 * 3 = 120 305 433 600 unités\n",
    "# d'information dans cette vidéo ! C'est un peu lourd pour nos traitements \n",
    "# statistiques, on devra donc réduire la taille des données.\n",
    "\n",
    "# Pour en réduire la taille, nous ne sélectionnons qu'une image sur 90 (une \n",
    "# toutes les 3 secondes). Ensuite, on réduit la taille des images à 72 pixels\n",
    "# de hauteur et 128 de largeur. Nous réduisons également la palette des \n",
    "# couleurs possibles : originellement, les niveaux des 3 couleurs (RGB) sont \n",
    "# encodés sur une échelle de 0 à 256 : nous réduirons cette échelle à une \n",
    "# échelle de 0 à 64.\n",
    "\n",
    "# On obtient donc un tableau où chaque ligne (chaque individu) correspond à 1 \n",
    "# image. Il y a 1 934 images. Chaque image est caractérisée par 72*128*3 = \n",
    "# 27 648 unités d'information, donc autant de colonnes. On ajoute en plus une \n",
    "# colonne qui indique la position de l'image dans le temps (par exemple, \n",
    "# \"cette image s'affiche à la150e seconde\")."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import imageio\n",
    "import PIL\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paramètres de compression\n",
    "width, height = 128,72\n",
    "img_freq = 90"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import de la video\n",
    "filename = 'ACP.mp4'\n",
    "images_per_seconds = 30 # La vidÃ©o dÃ©file Ã  30 images par secondes\n",
    "url = \"https://youtu.be/uV5hmpzmWsU\"\n",
    "vid = imageio.get_reader(filename,  'ffmpeg')\n",
    "sample = np.arange(0, vid.get_length(), img_freq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extraction des informations\n",
    "first_frame = vid.get_data(0)\n",
    "image_height, image_width, colors = first_frame.shape\n",
    "print(image_height,image_width,vid.get_length(),colors)\n",
    "print(image_height * image_width * vid.get_length() * colors)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extraction des images\n",
    "video = np.zeros((0, width*height*3), dtype=np.int8)\n",
    "for j,i in enumerate(sample):\n",
    "    if j%5 == 0:\n",
    "        print(\"image \",i, max(sample))\n",
    "    image = vid.get_data(i)\n",
    "\n",
    "    # Reduction de la taille des images\n",
    "    img = Image.fromarray(image.astype('uint8'), 'RGB')\n",
    "    img = img.resize((width,height), PIL.Image.ANTIALIAS)\n",
    "    image = np.array(img)\n",
    "    \n",
    "    image = image.reshape(height*width*3)\n",
    "    image = image / 4 #Reduction de l'Ã©chelle des couleurs (0 Ã  256 vers du 0 Ã  64)\n",
    "    image = np.array(image, dtype=np.int8) # Conversion des niveaux de couleurs en int\n",
    "    #display_image(image,height,width,3)\n",
    "    video = np.concatenate([video,[image]])\n",
    "\n",
    "print(video.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# conversion en dataframe\n",
    "video = pd.DataFrame(video)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ajout de la position de l'image, en secondes :\n",
    "video[\"position\"] = [int(frame/images_per_seconds) for frame in sample]\n",
    "# ajout de l'url qui fait dÃ©marrer la vidÃ©o au bon endroit\n",
    "video.index = [\"{}?t={}s\".format(url, p) for p in video[\"position\"]]\n",
    "# inversion de l'ordre des colonnes dans le dataframe\n",
    "cols = list(video.columns)\n",
    "cols.pop(cols.index('position'))\n",
    "video = video[['position'] + cols]\n",
    "\n",
    "# Export CSV\n",
    "video.to_csv(\"video.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
