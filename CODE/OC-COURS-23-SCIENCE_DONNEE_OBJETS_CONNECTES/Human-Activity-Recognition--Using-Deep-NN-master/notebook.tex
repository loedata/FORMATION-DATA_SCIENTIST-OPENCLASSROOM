
% Default to the notebook output style

    


% Inherit from the specified cell style.




    
\documentclass[11pt]{article}

    
    
    \usepackage[T1]{fontenc}
    % Nicer default font (+ math font) than Computer Modern for most use cases
    \usepackage{mathpazo}

    % Basic figure setup, for now with no caption control since it's done
    % automatically by Pandoc (which extracts ![](path) syntax from Markdown).
    \usepackage{graphicx}
    % We will generate all images so they have a width \maxwidth. This means
    % that they will get their normal width if they fit onto the page, but
    % are scaled down if they would overflow the margins.
    \makeatletter
    \def\maxwidth{\ifdim\Gin@nat@width>\linewidth\linewidth
    \else\Gin@nat@width\fi}
    \makeatother
    \let\Oldincludegraphics\includegraphics
    % Set max figure width to be 80% of text width, for now hardcoded.
    \renewcommand{\includegraphics}[1]{\Oldincludegraphics[width=.8\maxwidth]{#1}}
    % Ensure that by default, figures have no caption (until we provide a
    % proper Figure object with a Caption API and a way to capture that
    % in the conversion process - todo).
    \usepackage{caption}
    \DeclareCaptionLabelFormat{nolabel}{}
    \captionsetup{labelformat=nolabel}

    \usepackage{adjustbox} % Used to constrain images to a maximum size 
    \usepackage{xcolor} % Allow colors to be defined
    \usepackage{enumerate} % Needed for markdown enumerations to work
    \usepackage{geometry} % Used to adjust the document margins
    \usepackage{amsmath} % Equations
    \usepackage{amssymb} % Equations
    \usepackage{textcomp} % defines textquotesingle
    % Hack from http://tex.stackexchange.com/a/47451/13684:
    \AtBeginDocument{%
        \def\PYZsq{\textquotesingle}% Upright quotes in Pygmentized code
    }
    \usepackage{upquote} % Upright quotes for verbatim code
    \usepackage{eurosym} % defines \euro
    \usepackage[mathletters]{ucs} % Extended unicode (utf-8) support
    \usepackage[utf8x]{inputenc} % Allow utf-8 characters in the tex document
    \usepackage{fancyvrb} % verbatim replacement that allows latex
    \usepackage{grffile} % extends the file name processing of package graphics 
                         % to support a larger range 
    % The hyperref package gives us a pdf with properly built
    % internal navigation ('pdf bookmarks' for the table of contents,
    % internal cross-reference links, web links for URLs, etc.)
    \usepackage{hyperref}
    \usepackage{longtable} % longtable support required by pandoc >1.10
    \usepackage{booktabs}  % table support for pandoc > 1.12.2
    \usepackage[inline]{enumitem} % IRkernel/repr support (it uses the enumerate* environment)
    \usepackage[normalem]{ulem} % ulem is needed to support strikethroughs (\sout)
                                % normalem makes italics be italics, not underlines
    

    
    
    % Colors for the hyperref package
    \definecolor{urlcolor}{rgb}{0,.145,.698}
    \definecolor{linkcolor}{rgb}{.71,0.21,0.01}
    \definecolor{citecolor}{rgb}{.12,.54,.11}

    % ANSI colors
    \definecolor{ansi-black}{HTML}{3E424D}
    \definecolor{ansi-black-intense}{HTML}{282C36}
    \definecolor{ansi-red}{HTML}{E75C58}
    \definecolor{ansi-red-intense}{HTML}{B22B31}
    \definecolor{ansi-green}{HTML}{00A250}
    \definecolor{ansi-green-intense}{HTML}{007427}
    \definecolor{ansi-yellow}{HTML}{DDB62B}
    \definecolor{ansi-yellow-intense}{HTML}{B27D12}
    \definecolor{ansi-blue}{HTML}{208FFB}
    \definecolor{ansi-blue-intense}{HTML}{0065CA}
    \definecolor{ansi-magenta}{HTML}{D160C4}
    \definecolor{ansi-magenta-intense}{HTML}{A03196}
    \definecolor{ansi-cyan}{HTML}{60C6C8}
    \definecolor{ansi-cyan-intense}{HTML}{258F8F}
    \definecolor{ansi-white}{HTML}{C5C1B4}
    \definecolor{ansi-white-intense}{HTML}{A1A6B2}

    % commands and environments needed by pandoc snippets
    % extracted from the output of `pandoc -s`
    \providecommand{\tightlist}{%
      \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}
    \DefineVerbatimEnvironment{Highlighting}{Verbatim}{commandchars=\\\{\}}
    % Add ',fontsize=\small' for more characters per line
    \newenvironment{Shaded}{}{}
    \newcommand{\KeywordTok}[1]{\textcolor[rgb]{0.00,0.44,0.13}{\textbf{{#1}}}}
    \newcommand{\DataTypeTok}[1]{\textcolor[rgb]{0.56,0.13,0.00}{{#1}}}
    \newcommand{\DecValTok}[1]{\textcolor[rgb]{0.25,0.63,0.44}{{#1}}}
    \newcommand{\BaseNTok}[1]{\textcolor[rgb]{0.25,0.63,0.44}{{#1}}}
    \newcommand{\FloatTok}[1]{\textcolor[rgb]{0.25,0.63,0.44}{{#1}}}
    \newcommand{\CharTok}[1]{\textcolor[rgb]{0.25,0.44,0.63}{{#1}}}
    \newcommand{\StringTok}[1]{\textcolor[rgb]{0.25,0.44,0.63}{{#1}}}
    \newcommand{\CommentTok}[1]{\textcolor[rgb]{0.38,0.63,0.69}{\textit{{#1}}}}
    \newcommand{\OtherTok}[1]{\textcolor[rgb]{0.00,0.44,0.13}{{#1}}}
    \newcommand{\AlertTok}[1]{\textcolor[rgb]{1.00,0.00,0.00}{\textbf{{#1}}}}
    \newcommand{\FunctionTok}[1]{\textcolor[rgb]{0.02,0.16,0.49}{{#1}}}
    \newcommand{\RegionMarkerTok}[1]{{#1}}
    \newcommand{\ErrorTok}[1]{\textcolor[rgb]{1.00,0.00,0.00}{\textbf{{#1}}}}
    \newcommand{\NormalTok}[1]{{#1}}
    
    % Additional commands for more recent versions of Pandoc
    \newcommand{\ConstantTok}[1]{\textcolor[rgb]{0.53,0.00,0.00}{{#1}}}
    \newcommand{\SpecialCharTok}[1]{\textcolor[rgb]{0.25,0.44,0.63}{{#1}}}
    \newcommand{\VerbatimStringTok}[1]{\textcolor[rgb]{0.25,0.44,0.63}{{#1}}}
    \newcommand{\SpecialStringTok}[1]{\textcolor[rgb]{0.73,0.40,0.53}{{#1}}}
    \newcommand{\ImportTok}[1]{{#1}}
    \newcommand{\DocumentationTok}[1]{\textcolor[rgb]{0.73,0.13,0.13}{\textit{{#1}}}}
    \newcommand{\AnnotationTok}[1]{\textcolor[rgb]{0.38,0.63,0.69}{\textbf{\textit{{#1}}}}}
    \newcommand{\CommentVarTok}[1]{\textcolor[rgb]{0.38,0.63,0.69}{\textbf{\textit{{#1}}}}}
    \newcommand{\VariableTok}[1]{\textcolor[rgb]{0.10,0.09,0.49}{{#1}}}
    \newcommand{\ControlFlowTok}[1]{\textcolor[rgb]{0.00,0.44,0.13}{\textbf{{#1}}}}
    \newcommand{\OperatorTok}[1]{\textcolor[rgb]{0.40,0.40,0.40}{{#1}}}
    \newcommand{\BuiltInTok}[1]{{#1}}
    \newcommand{\ExtensionTok}[1]{{#1}}
    \newcommand{\PreprocessorTok}[1]{\textcolor[rgb]{0.74,0.48,0.00}{{#1}}}
    \newcommand{\AttributeTok}[1]{\textcolor[rgb]{0.49,0.56,0.16}{{#1}}}
    \newcommand{\InformationTok}[1]{\textcolor[rgb]{0.38,0.63,0.69}{\textbf{\textit{{#1}}}}}
    \newcommand{\WarningTok}[1]{\textcolor[rgb]{0.38,0.63,0.69}{\textbf{\textit{{#1}}}}}
    
    
    % Define a nice break command that doesn't care if a line doesn't already
    % exist.
    \def\br{\hspace*{\fill} \\* }
    % Math Jax compatability definitions
    \def\gt{>}
    \def\lt{<}
    % Document parameters
    \title{Human Activity Detection-Without Verbose }
    
    
    

    % Pygments definitions
    
\makeatletter
\def\PY@reset{\let\PY@it=\relax \let\PY@bf=\relax%
    \let\PY@ul=\relax \let\PY@tc=\relax%
    \let\PY@bc=\relax \let\PY@ff=\relax}
\def\PY@tok#1{\csname PY@tok@#1\endcsname}
\def\PY@toks#1+{\ifx\relax#1\empty\else%
    \PY@tok{#1}\expandafter\PY@toks\fi}
\def\PY@do#1{\PY@bc{\PY@tc{\PY@ul{%
    \PY@it{\PY@bf{\PY@ff{#1}}}}}}}
\def\PY#1#2{\PY@reset\PY@toks#1+\relax+\PY@do{#2}}

\expandafter\def\csname PY@tok@w\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.73,0.73}{##1}}}
\expandafter\def\csname PY@tok@c\endcsname{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.25,0.50,0.50}{##1}}}
\expandafter\def\csname PY@tok@cp\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.74,0.48,0.00}{##1}}}
\expandafter\def\csname PY@tok@k\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@kp\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@kt\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.69,0.00,0.25}{##1}}}
\expandafter\def\csname PY@tok@o\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\expandafter\def\csname PY@tok@ow\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.67,0.13,1.00}{##1}}}
\expandafter\def\csname PY@tok@nb\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@nf\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.00,0.00,1.00}{##1}}}
\expandafter\def\csname PY@tok@nc\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.00,1.00}{##1}}}
\expandafter\def\csname PY@tok@nn\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.00,1.00}{##1}}}
\expandafter\def\csname PY@tok@ne\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.82,0.25,0.23}{##1}}}
\expandafter\def\csname PY@tok@nv\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.10,0.09,0.49}{##1}}}
\expandafter\def\csname PY@tok@no\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.53,0.00,0.00}{##1}}}
\expandafter\def\csname PY@tok@nl\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.63,0.63,0.00}{##1}}}
\expandafter\def\csname PY@tok@ni\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.60,0.60,0.60}{##1}}}
\expandafter\def\csname PY@tok@na\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.49,0.56,0.16}{##1}}}
\expandafter\def\csname PY@tok@nt\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@nd\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.67,0.13,1.00}{##1}}}
\expandafter\def\csname PY@tok@s\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@sd\endcsname{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@si\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.73,0.40,0.53}{##1}}}
\expandafter\def\csname PY@tok@se\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.73,0.40,0.13}{##1}}}
\expandafter\def\csname PY@tok@sr\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.40,0.53}{##1}}}
\expandafter\def\csname PY@tok@ss\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.10,0.09,0.49}{##1}}}
\expandafter\def\csname PY@tok@sx\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@m\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\expandafter\def\csname PY@tok@gh\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.00,0.50}{##1}}}
\expandafter\def\csname PY@tok@gu\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.50,0.00,0.50}{##1}}}
\expandafter\def\csname PY@tok@gd\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.63,0.00,0.00}{##1}}}
\expandafter\def\csname PY@tok@gi\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.00,0.63,0.00}{##1}}}
\expandafter\def\csname PY@tok@gr\endcsname{\def\PY@tc##1{\textcolor[rgb]{1.00,0.00,0.00}{##1}}}
\expandafter\def\csname PY@tok@ge\endcsname{\let\PY@it=\textit}
\expandafter\def\csname PY@tok@gs\endcsname{\let\PY@bf=\textbf}
\expandafter\def\csname PY@tok@gp\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.00,0.50}{##1}}}
\expandafter\def\csname PY@tok@go\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.53,0.53,0.53}{##1}}}
\expandafter\def\csname PY@tok@gt\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.00,0.27,0.87}{##1}}}
\expandafter\def\csname PY@tok@err\endcsname{\def\PY@bc##1{\setlength{\fboxsep}{0pt}\fcolorbox[rgb]{1.00,0.00,0.00}{1,1,1}{\strut ##1}}}
\expandafter\def\csname PY@tok@kc\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@kd\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@kn\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@kr\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@bp\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@fm\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.00,0.00,1.00}{##1}}}
\expandafter\def\csname PY@tok@vc\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.10,0.09,0.49}{##1}}}
\expandafter\def\csname PY@tok@vg\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.10,0.09,0.49}{##1}}}
\expandafter\def\csname PY@tok@vi\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.10,0.09,0.49}{##1}}}
\expandafter\def\csname PY@tok@vm\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.10,0.09,0.49}{##1}}}
\expandafter\def\csname PY@tok@sa\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@sb\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@sc\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@dl\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@s2\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@sh\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@s1\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@mb\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\expandafter\def\csname PY@tok@mf\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\expandafter\def\csname PY@tok@mh\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\expandafter\def\csname PY@tok@mi\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\expandafter\def\csname PY@tok@il\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\expandafter\def\csname PY@tok@mo\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\expandafter\def\csname PY@tok@ch\endcsname{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.25,0.50,0.50}{##1}}}
\expandafter\def\csname PY@tok@cm\endcsname{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.25,0.50,0.50}{##1}}}
\expandafter\def\csname PY@tok@cpf\endcsname{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.25,0.50,0.50}{##1}}}
\expandafter\def\csname PY@tok@c1\endcsname{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.25,0.50,0.50}{##1}}}
\expandafter\def\csname PY@tok@cs\endcsname{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.25,0.50,0.50}{##1}}}

\def\PYZbs{\char`\\}
\def\PYZus{\char`\_}
\def\PYZob{\char`\{}
\def\PYZcb{\char`\}}
\def\PYZca{\char`\^}
\def\PYZam{\char`\&}
\def\PYZlt{\char`\<}
\def\PYZgt{\char`\>}
\def\PYZsh{\char`\#}
\def\PYZpc{\char`\%}
\def\PYZdl{\char`\$}
\def\PYZhy{\char`\-}
\def\PYZsq{\char`\'}
\def\PYZdq{\char`\"}
\def\PYZti{\char`\~}
% for compatibility with earlier versions
\def\PYZat{@}
\def\PYZlb{[}
\def\PYZrb{]}
\makeatother


    % Exact colors from NB
    \definecolor{incolor}{rgb}{0.0, 0.0, 0.5}
    \definecolor{outcolor}{rgb}{0.545, 0.0, 0.0}



    
    % Prevent overflowing lines due to hard-to-break entities
    \sloppy 
    % Setup hyperref package
    \hypersetup{
      breaklinks=true,  % so long urls are correctly broken across lines
      colorlinks=true,
      urlcolor=urlcolor,
      linkcolor=linkcolor,
      citecolor=citecolor,
      }
    % Slightly bigger margins than the latex defaults
    
    \geometry{verbose,tmargin=1in,bmargin=1in,lmargin=1in,rmargin=1in}
    
    

    \begin{document}
    
    
    \maketitle
    
    

    
    \section{Human Activity Recognition}\label{human-activity-recognition}

This project is to build a model that predicts the human activities such
as Walking, Walking\_Upstairs, Walking\_Downstairs, Sitting, Standing or
Laying.

This dataset is collected from 30 persons(referred as subjects in this
dataset), performing different activities with a smartphone to their
waists. The data is recorded with the help of sensors (accelerometer and
Gyroscope) in that smartphone. This experiment was video recorded to
label the data manually.

\subsection{How data was recorded}\label{how-data-was-recorded}

By using the sensors(Gyroscope and accelerometer) in a smartphone, they
have captured '3-axial linear acceleration'(\emph{tAcc-XYZ}) from
accelerometer and '3-axial angular velocity' (\emph{tGyro-XYZ}) from
Gyroscope with several variations.

\begin{quote}
prefix 't' in those metrics denotes time.
\end{quote}

\begin{quote}
suffix 'XYZ' represents 3-axial signals in X , Y, and Z directions.
\end{quote}

\subsubsection{Feature names}\label{feature-names}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  These sensor signals are preprocessed by applying noise filters and
  then sampled in fixed-width windows(sliding windows) of 2.56 seconds
  each with 50\% overlap. ie., each window has 128 readings.
\item
  From Each window, a feature vector was obtianed by calculating
  variables from the time and frequency domain. \textgreater{} In our
  dataset, each datapoint represents a window with different readings
\item
  The accelertion signal was saperated into Body and Gravity
  acceleration signals(\textbf{\emph{tBodyAcc-XYZ}} and
  \textbf{\emph{tGravityAcc-XYZ}}) using some low pass filter with
  corner frequecy of 0.3Hz.
\item
  After that, the body linear acceleration and angular velocity were
  derived in time to obtian \emph{jerk signals}
  (\textbf{\emph{tBodyAccJerk-XYZ}} and
  \textbf{\emph{tBodyGyroJerk-XYZ}}).
\item
  The magnitude of these 3-dimensional signals were calculated using the
  Euclidian norm. This magnitudes are represented as features with names
  like \emph{tBodyAccMag}, \emph{tGravityAccMag},
  \emph{tBodyAccJerkMag}, \emph{tBodyGyroMag} and
  \emph{tBodyGyroJerkMag}.
\item
  Finally, We've got frequency domain signals from some of the available
  signals by applying a FFT (Fast Fourier Transform). These signals
  obtained were labeled with \textbf{\emph{prefix 'f'}} just like
  original signals with \textbf{\emph{prefix 't'}}. These signals are
  labeled as \textbf{\emph{fBodyAcc-XYZ}}, \textbf{\emph{fBodyGyroMag}}
  etc.,.
\item
  These are the signals that we got so far.

  \begin{itemize}
  \tightlist
  \item
    tBodyAcc-XYZ
  \item
    tGravityAcc-XYZ
  \item
    tBodyAccJerk-XYZ
  \item
    tBodyGyro-XYZ
  \item
    tBodyGyroJerk-XYZ
  \item
    tBodyAccMag
  \item
    tGravityAccMag
  \item
    tBodyAccJerkMag
  \item
    tBodyGyroMag
  \item
    tBodyGyroJerkMag
  \item
    fBodyAcc-XYZ
  \item
    fBodyAccJerk-XYZ
  \item
    fBodyGyro-XYZ
  \item
    fBodyAccMag
  \item
    fBodyAccJerkMag
  \item
    fBodyGyroMag
  \item
    fBodyGyroJerkMag
  \end{itemize}
\item
  We can esitmate some set of variables from the above signals. ie., We
  will estimate the following properties on each and every signal that
  we recoreded so far.

  \begin{itemize}
  \tightlist
  \item
    \textbf{\emph{mean()}}: Mean value
  \item
    \textbf{\emph{std()}}: Standard deviation
  \item
    \textbf{\emph{mad()}}: Median absolute deviation
  \item
    \textbf{\emph{max()}}: Largest value in array
  \item
    \textbf{\emph{min()}}: Smallest value in array
  \item
    \textbf{\emph{sma()}}: Signal magnitude area
  \item
    \textbf{\emph{energy()}}: Energy measure. Sum of the squares divided
    by the number of values.
  \item
    \textbf{\emph{iqr()}}: Interquartile range
  \item
    \textbf{\emph{entropy()}}: Signal entropy
  \item
    \textbf{\emph{arCoeff()}}: Autorregresion coefficients with Burg
    order equal to 4
  \item
    \textbf{\emph{correlation()}}: correlation coefficient between two
    signals
  \item
    \textbf{\emph{maxInds()}}: index of the frequency component with
    largest magnitude
  \item
    \textbf{\emph{meanFreq()}}: Weighted average of the frequency
    components to obtain a mean frequency
  \item
    \textbf{\emph{skewness()}}: skewness of the frequency domain signal
  \item
    \textbf{\emph{kurtosis()}}: kurtosis of the frequency domain signal
  \item
    \textbf{\emph{bandsEnergy()}}: Energy of a frequency interval within
    the 64 bins of the FFT of each window.
  \item
    \textbf{\emph{angle()}}: Angle between to vectors.
  \end{itemize}
\item
  We can obtain some other vectors by taking the average of signals in a
  single window sample. These are used on the angle() variable' `

  \begin{itemize}
  \tightlist
  \item
    gravityMean
  \item
    tBodyAccMean
  \item
    tBodyAccJerkMean
  \item
    tBodyGyroMean
  \item
    tBodyGyroJerkMean
  \end{itemize}
\end{enumerate}

\subsubsection{Y\_Labels(Encoded)}\label{y_labelsencoded}

\begin{itemize}
\item
  In the dataset, Y\_labels are represented as numbers from 1 to 6 as
  their identifiers.

  \begin{itemize}
  \tightlist
  \item
    WALKING as \textbf{1}
  \item
    WALKING\_UPSTAIRS as \textbf{2}
  \item
    WALKING\_DOWNSTAIRS as \textbf{3}
  \item
    SITTING as \textbf{4}
  \item
    STANDING as \textbf{5}
  \item
    LAYING as \textbf{6}
  \end{itemize}
\end{itemize}

\subsection{Train and test data were
saperated}\label{train-and-test-data-were-saperated}

\begin{itemize}
\tightlist
\item
  The readings from \textbf{\emph{70\%}} of the volunteers were taken as
  \textbf{\emph{trianing data}} and remaining \textbf{\emph{30\%}}
  subjects recordings were taken for \textbf{\emph{test data}}
\end{itemize}

\subsection{Data}\label{data}

\begin{itemize}
\tightlist
\item
  All the data is present in 'UCI\_HAR\_dataset/' folder in present
  working directory.

  \begin{itemize}
  \tightlist
  \item
    Feature names are present in 'UCI\_HAR\_dataset/features.txt'
  \item
    \textbf{\emph{Train Data}}

    \begin{itemize}
    \tightlist
    \item
      'UCI\_HAR\_dataset/train/X\_train.txt'
    \item
      'UCI\_HAR\_dataset/train/subject\_train.txt'
    \item
      'UCI\_HAR\_dataset/train/y\_train.txt'
    \end{itemize}
  \item
    \textbf{\emph{Test Data}}

    \begin{itemize}
    \tightlist
    \item
      'UCI\_HAR\_dataset/test/X\_test.txt'
    \item
      'UCI\_HAR\_dataset/test/subject\_test.txt'
    \item
      'UCI\_HAR\_dataset/test/y\_test.txt'
    \end{itemize}
  \end{itemize}
\end{itemize}

\subsection{Data Size :}\label{data-size}

\begin{quote}
27 MB
\end{quote}

    

    

    

    \section{Quick overview of the dataset
:}\label{quick-overview-of-the-dataset}

    \begin{itemize}
\item
  Accelerometer and Gyroscope readings are taken from 30
  volunteers(referred as subjects) while performing the following 6
  Activities.

  \begin{enumerate}
  \def\labelenumi{\arabic{enumi}.}
  \tightlist
  \item
    Walking\\
  \item
    WalkingUpstairs
  \item
    WalkingDownstairs
  \item
    Standing
  \item
    Sitting
  \item
    Lying.
  \end{enumerate}
\item
  Readings are divided into a window of 2.56 seconds with 50\%
  overlapping.
\item
  Accelerometer readings are divided into gravity acceleration and body
  acceleration readings, which has x,y and z components each.
\item
  Gyroscope readings are the measure of angular velocities which has x,y
  and z components.
\item
  Jerk signals are calculated for BodyAcceleration readings.
\item
  Fourier Transforms are made on the above time readings to obtain
  frequency readings.
\item
  Now, on all the base signal readings., mean, max, mad, sma,
  arcoefficient, engerybands,entropy etc., are calculated for each
  window.
\item
  We get a feature vector of 561 features and these features are given
  in the dataset.
\item
  Each window of readings is a datapoint of 561 features.
\end{itemize}

\subsection{Problem Framework}\label{problem-framework}

\begin{itemize}
\tightlist
\item
  30 subjects(volunteers) data is randomly split to 70\%(21) test and
  30\%(7) train data.
\item
  Each datapoint corresponds one of the 6 Activities.
\end{itemize}

    \subsection{Problem Statement}\label{problem-statement}

\begin{itemize}
\tightlist
\item
  Given a new datapoint we have to predict the Activity
\end{itemize}

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}1}]:} \PY{k+kn}{import} \PY{n+nn}{numpy} \PY{k}{as} \PY{n+nn}{np}
        \PY{k+kn}{import} \PY{n+nn}{pandas} \PY{k}{as} \PY{n+nn}{pd}
        \PY{k+kn}{import} \PY{n+nn}{warnings}
        \PY{n}{warnings}\PY{o}{.}\PY{n}{filterwarnings}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{ignore}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
        
        \PY{c+c1}{\PYZsh{} get the features from the file features.txt}
        \PY{n}{features} \PY{o}{=} \PY{n+nb}{list}\PY{p}{(}\PY{p}{)}
        \PY{k}{with} \PY{n+nb}{open}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{UCI\PYZus{}HAR\PYZus{}Dataset/features.txt}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)} \PY{k}{as} \PY{n}{f}\PY{p}{:}
            \PY{n}{features} \PY{o}{=} \PY{p}{[}\PY{n}{line}\PY{o}{.}\PY{n}{split}\PY{p}{(}\PY{p}{)}\PY{p}{[}\PY{l+m+mi}{1}\PY{p}{]} \PY{k}{for} \PY{n}{line} \PY{o+ow}{in} \PY{n}{f}\PY{o}{.}\PY{n}{readlines}\PY{p}{(}\PY{p}{)}\PY{p}{]}
        \PY{n+nb}{print}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{No of Features: }\PY{l+s+si}{\PYZob{}\PYZcb{}}\PY{l+s+s1}{\PYZsq{}}\PY{o}{.}\PY{n}{format}\PY{p}{(}\PY{n+nb}{len}\PY{p}{(}\PY{n}{features}\PY{p}{)}\PY{p}{)}\PY{p}{)}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
No of Features: 561

    \end{Verbatim}

    \subsection{Obtain the train data}\label{obtain-the-train-data}

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}12}]:} \PY{c+c1}{\PYZsh{} get the data from txt files to pandas dataffame}
         \PY{n}{X\PYZus{}train} \PY{o}{=} \PY{n}{pd}\PY{o}{.}\PY{n}{read\PYZus{}csv}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{UCI\PYZus{}HAR\PYZus{}Dataset/train/X\PYZus{}train.txt}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{delim\PYZus{}whitespace}\PY{o}{=}\PY{k+kc}{True}\PY{p}{,} \PY{n}{header}\PY{o}{=}\PY{k+kc}{None}\PY{p}{,} \PY{n}{names}\PY{o}{=}\PY{n}{features}\PY{p}{)}
         
         \PY{c+c1}{\PYZsh{} add subject column to the dataframe}
         \PY{n}{X\PYZus{}train}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{subject}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]} \PY{o}{=} \PY{n}{pd}\PY{o}{.}\PY{n}{read\PYZus{}csv}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{UCI\PYZus{}HAR\PYZus{}Dataset/train/subject\PYZus{}train.txt}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{header}\PY{o}{=}\PY{k+kc}{None}\PY{p}{,} \PY{n}{squeeze}\PY{o}{=}\PY{k+kc}{True}\PY{p}{)}
         
         \PY{n}{y\PYZus{}train} \PY{o}{=} \PY{n}{pd}\PY{o}{.}\PY{n}{read\PYZus{}csv}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{UCI\PYZus{}HAR\PYZus{}Dataset/train/y\PYZus{}train.txt}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{names}\PY{o}{=}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Activity}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{,} \PY{n}{squeeze}\PY{o}{=}\PY{k+kc}{True}\PY{p}{)}
         \PY{n}{y\PYZus{}train\PYZus{}labels} \PY{o}{=} \PY{n}{y\PYZus{}train}\PY{o}{.}\PY{n}{map}\PY{p}{(}\PY{p}{\PYZob{}}\PY{l+m+mi}{1}\PY{p}{:} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{WALKING}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+m+mi}{2}\PY{p}{:}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{WALKING\PYZus{}UPSTAIRS}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}\PY{l+m+mi}{3}\PY{p}{:}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{WALKING\PYZus{}DOWNSTAIRS}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}\PYZbs{}
                                \PY{l+m+mi}{4}\PY{p}{:}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{SITTING}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+m+mi}{5}\PY{p}{:}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{STANDING}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}\PY{l+m+mi}{6}\PY{p}{:}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{LAYING}\PY{l+s+s1}{\PYZsq{}}\PY{p}{\PYZcb{}}\PY{p}{)}
         
         \PY{c+c1}{\PYZsh{} put all columns in a single dataframe}
         \PY{n}{train} \PY{o}{=} \PY{n}{X\PYZus{}train}
         \PY{n}{train}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Activity}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]} \PY{o}{=} \PY{n}{y\PYZus{}train}
         \PY{n}{train}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{ActivityName}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]} \PY{o}{=} \PY{n}{y\PYZus{}train\PYZus{}labels}
         \PY{n}{train}\PY{o}{.}\PY{n}{sample}\PY{p}{(}\PY{p}{)}
\end{Verbatim}


\begin{Verbatim}[commandchars=\\\{\}]
{\color{outcolor}Out[{\color{outcolor}12}]:}       tBodyAcc-mean()-X  tBodyAcc-mean()-Y  tBodyAcc-mean()-Z  \textbackslash{}
         6212           0.380322          -0.009925          -0.172745   
         
               tBodyAcc-std()-X  tBodyAcc-std()-Y  tBodyAcc-std()-Z  tBodyAcc-mad()-X  \textbackslash{}
         6212          0.125378         -0.160388          -0.04863          0.076071   
         
               tBodyAcc-mad()-Y  tBodyAcc-mad()-Z  tBodyAcc-max()-X  \textbackslash{}
         6212         -0.115744         -0.016339           0.49712   
         
                      {\ldots}          angle(tBodyAccMean,gravity)  \textbackslash{}
         6212         {\ldots}                            -0.644849   
         
               angle(tBodyAccJerkMean),gravityMean)  angle(tBodyGyroMean,gravityMean)  \textbackslash{}
         6212                              0.184224                          0.870293   
         
               angle(tBodyGyroJerkMean,gravityMean)  angle(X,gravityMean)  \textbackslash{}
         6212                             -0.173777             -0.657367   
         
               angle(Y,gravityMean)  angle(Z,gravityMean)  subject  Activity  \textbackslash{}
         6212              0.203386              0.237609       27         3   
         
                     ActivityName  
         6212  WALKING\_DOWNSTAIRS  
         
         [1 rows x 564 columns]
\end{Verbatim}
            
    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}13}]:} \PY{n}{train}\PY{o}{.}\PY{n}{shape}
\end{Verbatim}


\begin{Verbatim}[commandchars=\\\{\}]
{\color{outcolor}Out[{\color{outcolor}13}]:} (7352, 564)
\end{Verbatim}
            
    \subsection{Obtain the test data}\label{obtain-the-test-data}

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}14}]:} \PY{c+c1}{\PYZsh{} get the data from txt files to pandas dataffame}
         \PY{n}{X\PYZus{}test} \PY{o}{=} \PY{n}{pd}\PY{o}{.}\PY{n}{read\PYZus{}csv}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{UCI\PYZus{}HAR\PYZus{}Dataset/test/X\PYZus{}test.txt}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{delim\PYZus{}whitespace}\PY{o}{=}\PY{k+kc}{True}\PY{p}{,} \PY{n}{header}\PY{o}{=}\PY{k+kc}{None}\PY{p}{,} \PY{n}{names}\PY{o}{=}\PY{n}{features}\PY{p}{)}
         
         \PY{c+c1}{\PYZsh{} add subject column to the dataframe}
         \PY{n}{X\PYZus{}test}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{subject}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]} \PY{o}{=} \PY{n}{pd}\PY{o}{.}\PY{n}{read\PYZus{}csv}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{UCI\PYZus{}HAR\PYZus{}Dataset/test/subject\PYZus{}test.txt}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{header}\PY{o}{=}\PY{k+kc}{None}\PY{p}{,} \PY{n}{squeeze}\PY{o}{=}\PY{k+kc}{True}\PY{p}{)}
         
         \PY{c+c1}{\PYZsh{} get y labels from the txt file}
         \PY{n}{y\PYZus{}test} \PY{o}{=} \PY{n}{pd}\PY{o}{.}\PY{n}{read\PYZus{}csv}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{UCI\PYZus{}HAR\PYZus{}Dataset/test/y\PYZus{}test.txt}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{names}\PY{o}{=}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Activity}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{,} \PY{n}{squeeze}\PY{o}{=}\PY{k+kc}{True}\PY{p}{)}
         \PY{n}{y\PYZus{}test\PYZus{}labels} \PY{o}{=} \PY{n}{y\PYZus{}test}\PY{o}{.}\PY{n}{map}\PY{p}{(}\PY{p}{\PYZob{}}\PY{l+m+mi}{1}\PY{p}{:} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{WALKING}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+m+mi}{2}\PY{p}{:}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{WALKING\PYZus{}UPSTAIRS}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}\PY{l+m+mi}{3}\PY{p}{:}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{WALKING\PYZus{}DOWNSTAIRS}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}\PYZbs{}
                                \PY{l+m+mi}{4}\PY{p}{:}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{SITTING}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+m+mi}{5}\PY{p}{:}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{STANDING}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}\PY{l+m+mi}{6}\PY{p}{:}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{LAYING}\PY{l+s+s1}{\PYZsq{}}\PY{p}{\PYZcb{}}\PY{p}{)}
         
         
         \PY{c+c1}{\PYZsh{} put all columns in a single dataframe}
         \PY{n}{test} \PY{o}{=} \PY{n}{X\PYZus{}test}
         \PY{n}{test}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Activity}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]} \PY{o}{=} \PY{n}{y\PYZus{}test}
         \PY{n}{test}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{ActivityName}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]} \PY{o}{=} \PY{n}{y\PYZus{}test\PYZus{}labels}
         \PY{n}{test}\PY{o}{.}\PY{n}{sample}\PY{p}{(}\PY{p}{)}
\end{Verbatim}


\begin{Verbatim}[commandchars=\\\{\}]
{\color{outcolor}Out[{\color{outcolor}14}]:}       tBodyAcc-mean()-X  tBodyAcc-mean()-Y  tBodyAcc-mean()-Z  \textbackslash{}
         2376           0.142909          -0.022732          -0.077417   
         
               tBodyAcc-std()-X  tBodyAcc-std()-Y  tBodyAcc-std()-Z  tBodyAcc-mad()-X  \textbackslash{}
         2376         -0.300135         -0.087465         -0.268216         -0.379653   
         
               tBodyAcc-mad()-Y  tBodyAcc-mad()-Z  tBodyAcc-max()-X        {\ldots}         \textbackslash{}
         2376         -0.077845         -0.291151         -0.016602        {\ldots}          
         
               angle(tBodyAccMean,gravity)  angle(tBodyAccJerkMean),gravityMean)  \textbackslash{}
         2376                     0.653273                             -0.293463   
         
               angle(tBodyGyroMean,gravityMean)  angle(tBodyGyroJerkMean,gravityMean)  \textbackslash{}
         2376                         -0.210501                             -0.449654   
         
               angle(X,gravityMean)  angle(Y,gravityMean)  angle(Z,gravityMean)  \textbackslash{}
         2376             -0.426216              0.421082              0.239323   
         
               subject  Activity      ActivityName  
         2376       20         2  WALKING\_UPSTAIRS  
         
         [1 rows x 564 columns]
\end{Verbatim}
            
    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}15}]:} \PY{n}{test}\PY{o}{.}\PY{n}{shape}
\end{Verbatim}


\begin{Verbatim}[commandchars=\\\{\}]
{\color{outcolor}Out[{\color{outcolor}15}]:} (2947, 564)
\end{Verbatim}
            
    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}16}]:} \PY{n}{train}\PY{o}{.}\PY{n}{columns}
\end{Verbatim}


\begin{Verbatim}[commandchars=\\\{\}]
{\color{outcolor}Out[{\color{outcolor}16}]:} Index(['tBodyAcc-mean()-X', 'tBodyAcc-mean()-Y', 'tBodyAcc-mean()-Z',
                'tBodyAcc-std()-X', 'tBodyAcc-std()-Y', 'tBodyAcc-std()-Z',
                'tBodyAcc-mad()-X', 'tBodyAcc-mad()-Y', 'tBodyAcc-mad()-Z',
                'tBodyAcc-max()-X',
                {\ldots}
                'angle(tBodyAccMean,gravity)', 'angle(tBodyAccJerkMean),gravityMean)',
                'angle(tBodyGyroMean,gravityMean)',
                'angle(tBodyGyroJerkMean,gravityMean)', 'angle(X,gravityMean)',
                'angle(Y,gravityMean)', 'angle(Z,gravityMean)', 'subject', 'Activity',
                'ActivityName'],
               dtype='object', length=564)
\end{Verbatim}
            
    

    \section{Data Cleaning}\label{data-cleaning}

    \subsection{1. Check for Duplicates}\label{check-for-duplicates}

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}17}]:} \PY{n+nb}{print}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{No of duplicates in train: }\PY{l+s+si}{\PYZob{}\PYZcb{}}\PY{l+s+s1}{\PYZsq{}}\PY{o}{.}\PY{n}{format}\PY{p}{(}\PY{n+nb}{sum}\PY{p}{(}\PY{n}{train}\PY{o}{.}\PY{n}{duplicated}\PY{p}{(}\PY{p}{)}\PY{p}{)}\PY{p}{)}\PY{p}{)}
         \PY{n+nb}{print}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{No of duplicates in test : }\PY{l+s+si}{\PYZob{}\PYZcb{}}\PY{l+s+s1}{\PYZsq{}}\PY{o}{.}\PY{n}{format}\PY{p}{(}\PY{n+nb}{sum}\PY{p}{(}\PY{n}{test}\PY{o}{.}\PY{n}{duplicated}\PY{p}{(}\PY{p}{)}\PY{p}{)}\PY{p}{)}\PY{p}{)}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
No of duplicates in train: 0
No of duplicates in test : 0

    \end{Verbatim}

    

    \subsection{2. Checking for NaN/null
values}\label{checking-for-nannull-values}

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}18}]:} \PY{n+nb}{print}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{We have }\PY{l+s+si}{\PYZob{}\PYZcb{}}\PY{l+s+s1}{ NaN/Null values in train}\PY{l+s+s1}{\PYZsq{}}\PY{o}{.}\PY{n}{format}\PY{p}{(}\PY{n}{train}\PY{o}{.}\PY{n}{isnull}\PY{p}{(}\PY{p}{)}\PY{o}{.}\PY{n}{values}\PY{o}{.}\PY{n}{sum}\PY{p}{(}\PY{p}{)}\PY{p}{)}\PY{p}{)}
         \PY{n+nb}{print}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{We have }\PY{l+s+si}{\PYZob{}\PYZcb{}}\PY{l+s+s1}{ NaN/Null values in test}\PY{l+s+s1}{\PYZsq{}}\PY{o}{.}\PY{n}{format}\PY{p}{(}\PY{n}{test}\PY{o}{.}\PY{n}{isnull}\PY{p}{(}\PY{p}{)}\PY{o}{.}\PY{n}{values}\PY{o}{.}\PY{n}{sum}\PY{p}{(}\PY{p}{)}\PY{p}{)}\PY{p}{)}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
We have 0 NaN/Null values in train
We have 0 NaN/Null values in test

    \end{Verbatim}

    

    

    \subsection{3. Check for data imbalance}\label{check-for-data-imbalance}

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}20}]:} \PY{k+kn}{import} \PY{n+nn}{matplotlib}\PY{n+nn}{.}\PY{n+nn}{pyplot} \PY{k}{as} \PY{n+nn}{plt}
         \PY{k+kn}{import} \PY{n+nn}{seaborn} \PY{k}{as} \PY{n+nn}{sns}
         
         \PY{n}{sns}\PY{o}{.}\PY{n}{set\PYZus{}style}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{whitegrid}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}21}]:} \PY{n}{plt}\PY{o}{.}\PY{n}{figure}\PY{p}{(}\PY{n}{figsize}\PY{o}{=}\PY{p}{(}\PY{l+m+mi}{16}\PY{p}{,}\PY{l+m+mi}{8}\PY{p}{)}\PY{p}{)}
         \PY{n}{plt}\PY{o}{.}\PY{n}{title}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Data provided by each user}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{fontsize}\PY{o}{=}\PY{l+m+mi}{20}\PY{p}{)}
         \PY{n}{sns}\PY{o}{.}\PY{n}{countplot}\PY{p}{(}\PY{n}{x}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{subject}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}\PY{n}{hue}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{ActivityName}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{data} \PY{o}{=} \PY{n}{train}\PY{p}{)}
         \PY{n}{plt}\PY{o}{.}\PY{n}{show}\PY{p}{(}\PY{p}{)}
\end{Verbatim}


    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{output_26_0.png}
    \end{center}
    { \hspace*{\fill} \\}
    
    \begin{quote}
We have got almost same number of reading from all the subjects
\end{quote}

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}22}]:} \PY{n}{plt}\PY{o}{.}\PY{n}{title}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{No of Datapoints per Activity}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{fontsize}\PY{o}{=}\PY{l+m+mi}{15}\PY{p}{)}
         \PY{n}{sns}\PY{o}{.}\PY{n}{countplot}\PY{p}{(}\PY{n}{train}\PY{o}{.}\PY{n}{ActivityName}\PY{p}{)}
         \PY{n}{plt}\PY{o}{.}\PY{n}{xticks}\PY{p}{(}\PY{n}{rotation}\PY{o}{=}\PY{l+m+mi}{90}\PY{p}{)}
         \PY{n}{plt}\PY{o}{.}\PY{n}{show}\PY{p}{(}\PY{p}{)}
\end{Verbatim}


    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{output_28_0.png}
    \end{center}
    { \hspace*{\fill} \\}
    
    \subsubsection{Observation}\label{observation}

\begin{quote}
Our data is well balanced (almost)
\end{quote}

    \subsection{4. Changing feature names}\label{changing-feature-names}

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}23}]:} \PY{n}{columns} \PY{o}{=} \PY{n}{train}\PY{o}{.}\PY{n}{columns}
         
         \PY{c+c1}{\PYZsh{} Removing \PYZsq{}()\PYZsq{} from column names}
         \PY{n}{columns} \PY{o}{=} \PY{n}{columns}\PY{o}{.}\PY{n}{str}\PY{o}{.}\PY{n}{replace}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{[()]}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
         \PY{n}{columns} \PY{o}{=} \PY{n}{columns}\PY{o}{.}\PY{n}{str}\PY{o}{.}\PY{n}{replace}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{[\PYZhy{}]}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{\PYZus{}}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
         \PY{n}{columns} \PY{o}{=} \PY{n}{columns}\PY{o}{.}\PY{n}{str}\PY{o}{.}\PY{n}{replace}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{[,]}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
         
         \PY{n}{train}\PY{o}{.}\PY{n}{columns} \PY{o}{=} \PY{n}{columns}
         \PY{n}{test}\PY{o}{.}\PY{n}{columns} \PY{o}{=} \PY{n}{columns}
         
         \PY{n}{test}\PY{o}{.}\PY{n}{columns}
\end{Verbatim}


\begin{Verbatim}[commandchars=\\\{\}]
{\color{outcolor}Out[{\color{outcolor}23}]:} Index(['tBodyAcc\_mean\_X', 'tBodyAcc\_mean\_Y', 'tBodyAcc\_mean\_Z',
                'tBodyAcc\_std\_X', 'tBodyAcc\_std\_Y', 'tBodyAcc\_std\_Z', 'tBodyAcc\_mad\_X',
                'tBodyAcc\_mad\_Y', 'tBodyAcc\_mad\_Z', 'tBodyAcc\_max\_X',
                {\ldots}
                'angletBodyAccMeangravity', 'angletBodyAccJerkMeangravityMean',
                'angletBodyGyroMeangravityMean', 'angletBodyGyroJerkMeangravityMean',
                'angleXgravityMean', 'angleYgravityMean', 'angleZgravityMean',
                'subject', 'Activity', 'ActivityName'],
               dtype='object', length=564)
\end{Verbatim}
            
    \subsection{5. Save this dataframe in a csv
files}\label{save-this-dataframe-in-a-csv-files}

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}27}]:} \PY{n}{train}\PY{o}{.}\PY{n}{to\PYZus{}csv}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{UCI\PYZus{}HAR\PYZus{}Dataset/csv\PYZus{}files/train.csv}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{index}\PY{o}{=}\PY{k+kc}{False}\PY{p}{)}
         \PY{n}{test}\PY{o}{.}\PY{n}{to\PYZus{}csv}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{UCI\PYZus{}HAR\PYZus{}Dataset/csv\PYZus{}files/test.csv}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{index}\PY{o}{=}\PY{k+kc}{False}\PY{p}{)}
\end{Verbatim}


    

    \section{Exploratory Data Analysis}\label{exploratory-data-analysis}

    "\textbf{\emph{Without domain knowledge EDA has no meaning, without EDA
a problem has no soul.}}"

    \subsubsection{1. Featuring Engineering from Domain
Knowledge}\label{featuring-engineering-from-domain-knowledge}

    \begin{itemize}
\item
  \textbf{Static and Dynamic Activities}

  \begin{itemize}
  \tightlist
  \item
    In static activities (sit, stand, lie down) motion information will
    not be very useful.
  \item
    In the dynamic activities (Walking,
    WalkingUpstairs,WalkingDownstairs) motion info will be significant.
  \end{itemize}
\end{itemize}

    \subsubsection{2. Stationary and Moving activities are completely
different}\label{stationary-and-moving-activities-are-completely-different}

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}36}]:} \PY{n}{sns}\PY{o}{.}\PY{n}{set\PYZus{}palette}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Set1}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{n}{desat}\PY{o}{=}\PY{l+m+mf}{0.80}\PY{p}{)}
         \PY{n}{facetgrid} \PY{o}{=} \PY{n}{sns}\PY{o}{.}\PY{n}{FacetGrid}\PY{p}{(}\PY{n}{train}\PY{p}{,} \PY{n}{hue}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{ActivityName}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{size}\PY{o}{=}\PY{l+m+mi}{6}\PY{p}{,}\PY{n}{aspect}\PY{o}{=}\PY{l+m+mi}{2}\PY{p}{)}
         \PY{n}{facetgrid}\PY{o}{.}\PY{n}{map}\PY{p}{(}\PY{n}{sns}\PY{o}{.}\PY{n}{distplot}\PY{p}{,}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{tBodyAccMag\PYZus{}mean}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{hist}\PY{o}{=}\PY{k+kc}{False}\PY{p}{)}\PYZbs{}
             \PY{o}{.}\PY{n}{add\PYZus{}legend}\PY{p}{(}\PY{p}{)}
         \PY{n}{plt}\PY{o}{.}\PY{n}{annotate}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Stationary Activities}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{n}{xy}\PY{o}{=}\PY{p}{(}\PY{o}{\PYZhy{}}\PY{l+m+mf}{0.956}\PY{p}{,}\PY{l+m+mi}{14}\PY{p}{)}\PY{p}{,} \PY{n}{xytext}\PY{o}{=}\PY{p}{(}\PY{o}{\PYZhy{}}\PY{l+m+mf}{0.9}\PY{p}{,} \PY{l+m+mi}{23}\PY{p}{)}\PY{p}{,} \PY{n}{size}\PY{o}{=}\PY{l+m+mi}{20}\PY{p}{,}\PYZbs{}
                     \PY{n}{va}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{center}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{ha}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{left}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}\PYZbs{}
                     \PY{n}{arrowprops}\PY{o}{=}\PY{n+nb}{dict}\PY{p}{(}\PY{n}{arrowstyle}\PY{o}{=}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{simple}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,}\PY{n}{connectionstyle}\PY{o}{=}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{arc3,rad=0.1}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}\PY{p}{)}
         
         \PY{n}{plt}\PY{o}{.}\PY{n}{annotate}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Moving Activities}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{n}{xy}\PY{o}{=}\PY{p}{(}\PY{l+m+mi}{0}\PY{p}{,}\PY{l+m+mi}{3}\PY{p}{)}\PY{p}{,} \PY{n}{xytext}\PY{o}{=}\PY{p}{(}\PY{l+m+mf}{0.2}\PY{p}{,} \PY{l+m+mi}{9}\PY{p}{)}\PY{p}{,} \PY{n}{size}\PY{o}{=}\PY{l+m+mi}{20}\PY{p}{,}\PYZbs{}
                     \PY{n}{va}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{center}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{ha}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{left}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}\PYZbs{}
                     \PY{n}{arrowprops}\PY{o}{=}\PY{n+nb}{dict}\PY{p}{(}\PY{n}{arrowstyle}\PY{o}{=}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{simple}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,}\PY{n}{connectionstyle}\PY{o}{=}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{arc3,rad=0.1}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}\PY{p}{)}
         \PY{n}{plt}\PY{o}{.}\PY{n}{show}\PY{p}{(}\PY{p}{)}
\end{Verbatim}


    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{output_40_0.png}
    \end{center}
    { \hspace*{\fill} \\}
    
    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}39}]:} \PY{c+c1}{\PYZsh{} for plotting purposes taking datapoints of each activity to a different dataframe}
         \PY{n}{df1} \PY{o}{=} \PY{n}{train}\PY{p}{[}\PY{n}{train}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Activity}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{o}{==}\PY{l+m+mi}{1}\PY{p}{]}
         \PY{n}{df2} \PY{o}{=} \PY{n}{train}\PY{p}{[}\PY{n}{train}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Activity}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{o}{==}\PY{l+m+mi}{2}\PY{p}{]}
         \PY{n}{df3} \PY{o}{=} \PY{n}{train}\PY{p}{[}\PY{n}{train}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Activity}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{o}{==}\PY{l+m+mi}{3}\PY{p}{]}
         \PY{n}{df4} \PY{o}{=} \PY{n}{train}\PY{p}{[}\PY{n}{train}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Activity}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{o}{==}\PY{l+m+mi}{4}\PY{p}{]}
         \PY{n}{df5} \PY{o}{=} \PY{n}{train}\PY{p}{[}\PY{n}{train}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Activity}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{o}{==}\PY{l+m+mi}{5}\PY{p}{]}
         \PY{n}{df6} \PY{o}{=} \PY{n}{train}\PY{p}{[}\PY{n}{train}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Activity}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{o}{==}\PY{l+m+mi}{6}\PY{p}{]}
         
         \PY{n}{plt}\PY{o}{.}\PY{n}{figure}\PY{p}{(}\PY{n}{figsize}\PY{o}{=}\PY{p}{(}\PY{l+m+mi}{14}\PY{p}{,}\PY{l+m+mi}{7}\PY{p}{)}\PY{p}{)}
         \PY{n}{plt}\PY{o}{.}\PY{n}{subplot}\PY{p}{(}\PY{l+m+mi}{2}\PY{p}{,}\PY{l+m+mi}{2}\PY{p}{,}\PY{l+m+mi}{1}\PY{p}{)}
         \PY{n}{plt}\PY{o}{.}\PY{n}{title}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Stationary Activities(Zoomed in)}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
         \PY{n}{sns}\PY{o}{.}\PY{n}{distplot}\PY{p}{(}\PY{n}{df4}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{tBodyAccMag\PYZus{}mean}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{,}\PY{n}{color} \PY{o}{=} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{r}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}\PY{n}{hist} \PY{o}{=} \PY{k+kc}{False}\PY{p}{,} \PY{n}{label} \PY{o}{=} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Sitting}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
         \PY{n}{sns}\PY{o}{.}\PY{n}{distplot}\PY{p}{(}\PY{n}{df5}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{tBodyAccMag\PYZus{}mean}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{,}\PY{n}{color} \PY{o}{=} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{m}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}\PY{n}{hist} \PY{o}{=} \PY{k+kc}{False}\PY{p}{,}\PY{n}{label} \PY{o}{=} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Standing}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
         \PY{n}{sns}\PY{o}{.}\PY{n}{distplot}\PY{p}{(}\PY{n}{df6}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{tBodyAccMag\PYZus{}mean}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{,}\PY{n}{color} \PY{o}{=} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{c}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}\PY{n}{hist} \PY{o}{=} \PY{k+kc}{False}\PY{p}{,} \PY{n}{label} \PY{o}{=} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Laying}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
         \PY{n}{plt}\PY{o}{.}\PY{n}{axis}\PY{p}{(}\PY{p}{[}\PY{o}{\PYZhy{}}\PY{l+m+mf}{1.01}\PY{p}{,} \PY{o}{\PYZhy{}}\PY{l+m+mf}{0.5}\PY{p}{,} \PY{l+m+mi}{0}\PY{p}{,} \PY{l+m+mi}{35}\PY{p}{]}\PY{p}{)}
         \PY{n}{plt}\PY{o}{.}\PY{n}{legend}\PY{p}{(}\PY{n}{loc}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{center}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
         
         \PY{n}{plt}\PY{o}{.}\PY{n}{subplot}\PY{p}{(}\PY{l+m+mi}{2}\PY{p}{,}\PY{l+m+mi}{2}\PY{p}{,}\PY{l+m+mi}{2}\PY{p}{)}
         \PY{n}{plt}\PY{o}{.}\PY{n}{title}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Moving Activities}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
         \PY{n}{sns}\PY{o}{.}\PY{n}{distplot}\PY{p}{(}\PY{n}{df1}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{tBodyAccMag\PYZus{}mean}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{,}\PY{n}{color} \PY{o}{=} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{red}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}\PY{n}{hist} \PY{o}{=} \PY{k+kc}{False}\PY{p}{,} \PY{n}{label} \PY{o}{=} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Walking}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
         \PY{n}{sns}\PY{o}{.}\PY{n}{distplot}\PY{p}{(}\PY{n}{df2}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{tBodyAccMag\PYZus{}mean}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{,}\PY{n}{color} \PY{o}{=} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{blue}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}\PY{n}{hist} \PY{o}{=} \PY{k+kc}{False}\PY{p}{,}\PY{n}{label} \PY{o}{=} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Walking Up}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
         \PY{n}{sns}\PY{o}{.}\PY{n}{distplot}\PY{p}{(}\PY{n}{df3}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{tBodyAccMag\PYZus{}mean}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{,}\PY{n}{color} \PY{o}{=} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{green}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}\PY{n}{hist} \PY{o}{=} \PY{k+kc}{False}\PY{p}{,} \PY{n}{label} \PY{o}{=} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Walking down}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
         \PY{n}{plt}\PY{o}{.}\PY{n}{legend}\PY{p}{(}\PY{n}{loc}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{center right}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
         
         
         \PY{n}{plt}\PY{o}{.}\PY{n}{tight\PYZus{}layout}\PY{p}{(}\PY{p}{)}
         \PY{n}{plt}\PY{o}{.}\PY{n}{show}\PY{p}{(}\PY{p}{)}
\end{Verbatim}


    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{output_41_0.png}
    \end{center}
    { \hspace*{\fill} \\}
    
    \subsubsection{3. Magnitude of an acceleration can saperate it
well}\label{magnitude-of-an-acceleration-can-saperate-it-well}

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}41}]:} \PY{n}{plt}\PY{o}{.}\PY{n}{figure}\PY{p}{(}\PY{n}{figsize}\PY{o}{=}\PY{p}{(}\PY{l+m+mi}{7}\PY{p}{,}\PY{l+m+mi}{7}\PY{p}{)}\PY{p}{)}
         \PY{n}{sns}\PY{o}{.}\PY{n}{boxplot}\PY{p}{(}\PY{n}{x}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{ActivityName}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{y}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{tBodyAccMag\PYZus{}mean}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}\PY{n}{data}\PY{o}{=}\PY{n}{train}\PY{p}{,} \PY{n}{showfliers}\PY{o}{=}\PY{k+kc}{False}\PY{p}{,} \PY{n}{saturation}\PY{o}{=}\PY{l+m+mi}{1}\PY{p}{)}
         \PY{n}{plt}\PY{o}{.}\PY{n}{ylabel}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Acceleration Magnitude mean}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
         \PY{n}{plt}\PY{o}{.}\PY{n}{axhline}\PY{p}{(}\PY{n}{y}\PY{o}{=}\PY{o}{\PYZhy{}}\PY{l+m+mf}{0.7}\PY{p}{,} \PY{n}{xmin}\PY{o}{=}\PY{l+m+mf}{0.1}\PY{p}{,} \PY{n}{xmax}\PY{o}{=}\PY{l+m+mf}{0.9}\PY{p}{,}\PY{n}{dashes}\PY{o}{=}\PY{p}{(}\PY{l+m+mi}{5}\PY{p}{,}\PY{l+m+mi}{5}\PY{p}{)}\PY{p}{,} \PY{n}{c}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{g}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
         \PY{n}{plt}\PY{o}{.}\PY{n}{axhline}\PY{p}{(}\PY{n}{y}\PY{o}{=}\PY{o}{\PYZhy{}}\PY{l+m+mf}{0.05}\PY{p}{,} \PY{n}{xmin}\PY{o}{=}\PY{l+m+mf}{0.4}\PY{p}{,} \PY{n}{dashes}\PY{o}{=}\PY{p}{(}\PY{l+m+mi}{5}\PY{p}{,}\PY{l+m+mi}{5}\PY{p}{)}\PY{p}{,} \PY{n}{c}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{m}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
         \PY{n}{plt}\PY{o}{.}\PY{n}{xticks}\PY{p}{(}\PY{n}{rotation}\PY{o}{=}\PY{l+m+mi}{90}\PY{p}{)}
         \PY{n}{plt}\PY{o}{.}\PY{n}{show}\PY{p}{(}\PY{p}{)}
\end{Verbatim}


    
    \begin{verbatim}
<matplotlib.figure.Figure at 0x1471d613b5f8>
    \end{verbatim}

    
    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{output_43_1.png}
    \end{center}
    { \hspace*{\fill} \\}
    
    \_\_ Observations\_\_: - If tAccMean is \textless{} -0.8 then the
Activities are either Standing or Sitting or Laying. - If tAccMean is
\textgreater{} -0.6 then the Activities are either Walking or
WalkingDownstairs or WalkingUpstairs. - If tAccMean \textgreater{} 0.0
then the Activity is WalkingDownstairs. - We can classify 75\% the
Acitivity labels with some errors.

    \subsubsection{4. Position of GravityAccelerationComponants also
matters}\label{position-of-gravityaccelerationcomponants-also-matters}

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}43}]:} \PY{n}{sns}\PY{o}{.}\PY{n}{boxplot}\PY{p}{(}\PY{n}{x}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{ActivityName}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{y}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{angleXgravityMean}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{data}\PY{o}{=}\PY{n}{train}\PY{p}{)}
         \PY{n}{plt}\PY{o}{.}\PY{n}{axhline}\PY{p}{(}\PY{n}{y}\PY{o}{=}\PY{l+m+mf}{0.08}\PY{p}{,} \PY{n}{xmin}\PY{o}{=}\PY{l+m+mf}{0.1}\PY{p}{,} \PY{n}{xmax}\PY{o}{=}\PY{l+m+mf}{0.9}\PY{p}{,}\PY{n}{c}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{m}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}\PY{n}{dashes}\PY{o}{=}\PY{p}{(}\PY{l+m+mi}{5}\PY{p}{,}\PY{l+m+mi}{3}\PY{p}{)}\PY{p}{)}
         \PY{n}{plt}\PY{o}{.}\PY{n}{title}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Angle between X\PYZhy{}axis and Gravity\PYZus{}mean}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{fontsize}\PY{o}{=}\PY{l+m+mi}{15}\PY{p}{)}
         \PY{n}{plt}\PY{o}{.}\PY{n}{xticks}\PY{p}{(}\PY{n}{rotation} \PY{o}{=} \PY{l+m+mi}{40}\PY{p}{)}
         \PY{n}{plt}\PY{o}{.}\PY{n}{show}\PY{p}{(}\PY{p}{)}
\end{Verbatim}


    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{output_46_0.png}
    \end{center}
    { \hspace*{\fill} \\}
    
    \_\_ Observations\_\_: * If angleX,gravityMean \textgreater{} 0 then
Activity is Laying. * We can classify all datapoints belonging to Laying
activity with just a single if else statement.

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}44}]:} \PY{n}{sns}\PY{o}{.}\PY{n}{boxplot}\PY{p}{(}\PY{n}{x}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{ActivityName}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{y}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{angleYgravityMean}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{data} \PY{o}{=} \PY{n}{train}\PY{p}{,} \PY{n}{showfliers}\PY{o}{=}\PY{k+kc}{False}\PY{p}{)}
         \PY{n}{plt}\PY{o}{.}\PY{n}{title}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Angle between Y\PYZhy{}axis and Gravity\PYZus{}mean}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{fontsize}\PY{o}{=}\PY{l+m+mi}{15}\PY{p}{)}
         \PY{n}{plt}\PY{o}{.}\PY{n}{xticks}\PY{p}{(}\PY{n}{rotation} \PY{o}{=} \PY{l+m+mi}{40}\PY{p}{)}
         \PY{n}{plt}\PY{o}{.}\PY{n}{axhline}\PY{p}{(}\PY{n}{y}\PY{o}{=}\PY{o}{\PYZhy{}}\PY{l+m+mf}{0.22}\PY{p}{,} \PY{n}{xmin}\PY{o}{=}\PY{l+m+mf}{0.1}\PY{p}{,} \PY{n}{xmax}\PY{o}{=}\PY{l+m+mf}{0.8}\PY{p}{,} \PY{n}{dashes}\PY{o}{=}\PY{p}{(}\PY{l+m+mi}{5}\PY{p}{,}\PY{l+m+mi}{3}\PY{p}{)}\PY{p}{,} \PY{n}{c}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{m}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
         \PY{n}{plt}\PY{o}{.}\PY{n}{show}\PY{p}{(}\PY{p}{)}
\end{Verbatim}


    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{output_48_0.png}
    \end{center}
    { \hspace*{\fill} \\}
    
    

    

    

    \section{Apply t-sne on the data}\label{apply-t-sne-on-the-data}

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}45}]:} \PY{k+kn}{import} \PY{n+nn}{numpy} \PY{k}{as} \PY{n+nn}{np}
         \PY{k+kn}{from} \PY{n+nn}{sklearn}\PY{n+nn}{.}\PY{n+nn}{manifold} \PY{k}{import} \PY{n}{TSNE}
         \PY{k+kn}{import} \PY{n+nn}{matplotlib}\PY{n+nn}{.}\PY{n+nn}{pyplot} \PY{k}{as} \PY{n+nn}{plt}
         \PY{k+kn}{import} \PY{n+nn}{seaborn} \PY{k}{as} \PY{n+nn}{sns}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}46}]:} \PY{c+c1}{\PYZsh{} performs t\PYZhy{}sne with different perplexity values and their repective plots..}
         
         \PY{k}{def} \PY{n+nf}{perform\PYZus{}tsne}\PY{p}{(}\PY{n}{X\PYZus{}data}\PY{p}{,} \PY{n}{y\PYZus{}data}\PY{p}{,} \PY{n}{perplexities}\PY{p}{,} \PY{n}{n\PYZus{}iter}\PY{o}{=}\PY{l+m+mi}{1000}\PY{p}{,} \PY{n}{img\PYZus{}name\PYZus{}prefix}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{t\PYZhy{}sne}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}\PY{p}{:}
                 
             \PY{k}{for} \PY{n}{index}\PY{p}{,}\PY{n}{perplexity} \PY{o+ow}{in} \PY{n+nb}{enumerate}\PY{p}{(}\PY{n}{perplexities}\PY{p}{)}\PY{p}{:}
                 \PY{c+c1}{\PYZsh{} perform t\PYZhy{}sne}
                 \PY{n+nb}{print}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+se}{\PYZbs{}n}\PY{l+s+s1}{performing tsne with perplexity }\PY{l+s+si}{\PYZob{}\PYZcb{}}\PY{l+s+s1}{ and with }\PY{l+s+si}{\PYZob{}\PYZcb{}}\PY{l+s+s1}{ iterations at max}\PY{l+s+s1}{\PYZsq{}}\PY{o}{.}\PY{n}{format}\PY{p}{(}\PY{n}{perplexity}\PY{p}{,} \PY{n}{n\PYZus{}iter}\PY{p}{)}\PY{p}{)}
                 \PY{n}{X\PYZus{}reduced} \PY{o}{=} \PY{n}{TSNE}\PY{p}{(}\PY{n}{verbose}\PY{o}{=}\PY{l+m+mi}{2}\PY{p}{,} \PY{n}{perplexity}\PY{o}{=}\PY{n}{perplexity}\PY{p}{)}\PY{o}{.}\PY{n}{fit\PYZus{}transform}\PY{p}{(}\PY{n}{X\PYZus{}data}\PY{p}{)}
                 \PY{n+nb}{print}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Done..}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
                 
                 \PY{c+c1}{\PYZsh{} prepare the data for seaborn         }
                 \PY{n+nb}{print}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Creating plot for this t\PYZhy{}sne visualization..}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
                 \PY{n}{df} \PY{o}{=} \PY{n}{pd}\PY{o}{.}\PY{n}{DataFrame}\PY{p}{(}\PY{p}{\PYZob{}}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{x}\PY{l+s+s1}{\PYZsq{}}\PY{p}{:}\PY{n}{X\PYZus{}reduced}\PY{p}{[}\PY{p}{:}\PY{p}{,}\PY{l+m+mi}{0}\PY{p}{]}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{y}\PY{l+s+s1}{\PYZsq{}}\PY{p}{:}\PY{n}{X\PYZus{}reduced}\PY{p}{[}\PY{p}{:}\PY{p}{,}\PY{l+m+mi}{1}\PY{p}{]} \PY{p}{,}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{label}\PY{l+s+s1}{\PYZsq{}}\PY{p}{:}\PY{n}{y\PYZus{}data}\PY{p}{\PYZcb{}}\PY{p}{)}
                 
                 \PY{c+c1}{\PYZsh{} draw the plot in appropriate place in the grid}
                 \PY{n}{sns}\PY{o}{.}\PY{n}{lmplot}\PY{p}{(}\PY{n}{data}\PY{o}{=}\PY{n}{df}\PY{p}{,} \PY{n}{x}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{x}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{y}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{y}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{hue}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{label}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{fit\PYZus{}reg}\PY{o}{=}\PY{k+kc}{False}\PY{p}{,} \PY{n}{size}\PY{o}{=}\PY{l+m+mi}{8}\PY{p}{,}\PYZbs{}
                            \PY{n}{palette}\PY{o}{=}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Set1}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,}\PY{n}{markers}\PY{o}{=}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{\PYZca{}}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{v}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{s}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{o}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{1}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{2}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{)}
                 \PY{n}{plt}\PY{o}{.}\PY{n}{title}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{perplexity : }\PY{l+s+si}{\PYZob{}\PYZcb{}}\PY{l+s+s2}{ and max\PYZus{}iter : }\PY{l+s+si}{\PYZob{}\PYZcb{}}\PY{l+s+s2}{\PYZdq{}}\PY{o}{.}\PY{n}{format}\PY{p}{(}\PY{n}{perplexity}\PY{p}{,} \PY{n}{n\PYZus{}iter}\PY{p}{)}\PY{p}{)}
                 \PY{n}{img\PYZus{}name} \PY{o}{=} \PY{n}{img\PYZus{}name\PYZus{}prefix} \PY{o}{+} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{\PYZus{}perp\PYZus{}}\PY{l+s+si}{\PYZob{}\PYZcb{}}\PY{l+s+s1}{\PYZus{}iter\PYZus{}}\PY{l+s+si}{\PYZob{}\PYZcb{}}\PY{l+s+s1}{.png}\PY{l+s+s1}{\PYZsq{}}\PY{o}{.}\PY{n}{format}\PY{p}{(}\PY{n}{perplexity}\PY{p}{,} \PY{n}{n\PYZus{}iter}\PY{p}{)}
                 \PY{n+nb}{print}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{saving this plot as image in present working directory...}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
                 \PY{n}{plt}\PY{o}{.}\PY{n}{savefig}\PY{p}{(}\PY{n}{img\PYZus{}name}\PY{p}{)}
                 \PY{n}{plt}\PY{o}{.}\PY{n}{show}\PY{p}{(}\PY{p}{)}
                 \PY{n+nb}{print}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Done}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}47}]:} \PY{n}{X\PYZus{}pre\PYZus{}tsne} \PY{o}{=} \PY{n}{train}\PY{o}{.}\PY{n}{drop}\PY{p}{(}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{subject}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Activity}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{ActivityName}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{,} \PY{n}{axis}\PY{o}{=}\PY{l+m+mi}{1}\PY{p}{)}
         \PY{n}{y\PYZus{}pre\PYZus{}tsne} \PY{o}{=} \PY{n}{train}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{ActivityName}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}
         \PY{n}{perform\PYZus{}tsne}\PY{p}{(}\PY{n}{X\PYZus{}data} \PY{o}{=} \PY{n}{X\PYZus{}pre\PYZus{}tsne}\PY{p}{,}\PY{n}{y\PYZus{}data}\PY{o}{=}\PY{n}{y\PYZus{}pre\PYZus{}tsne}\PY{p}{,} \PY{n}{perplexities} \PY{o}{=}\PY{p}{[}\PY{l+m+mi}{2}\PY{p}{,}\PY{l+m+mi}{5}\PY{p}{,}\PY{l+m+mi}{10}\PY{p}{,}\PY{l+m+mi}{20}\PY{p}{,}\PY{l+m+mi}{50}\PY{p}{]}\PY{p}{)}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]

performing tsne with perplexity 2 and with 1000 iterations at max
[t-SNE] Computing 7 nearest neighbors{\ldots}
[t-SNE] Indexed 7352 samples in 0.096s{\ldots}
[t-SNE] Computed neighbors for 7352 samples in 27.701s{\ldots}
[t-SNE] Computed conditional probabilities for sample 1000 / 7352
[t-SNE] Computed conditional probabilities for sample 2000 / 7352
[t-SNE] Computed conditional probabilities for sample 3000 / 7352
[t-SNE] Computed conditional probabilities for sample 4000 / 7352
[t-SNE] Computed conditional probabilities for sample 5000 / 7352
[t-SNE] Computed conditional probabilities for sample 6000 / 7352
[t-SNE] Computed conditional probabilities for sample 7000 / 7352
[t-SNE] Computed conditional probabilities for sample 7352 / 7352
[t-SNE] Mean sigma: 0.635855
[t-SNE] Computed conditional probabilities in 0.052s
[t-SNE] Iteration 50: error = 124.7532959, gradient norm = 0.0285542 (50 iterations in 6.885s)
[t-SNE] Iteration 100: error = 106.8683777, gradient norm = 0.0273265 (50 iterations in 3.556s)
[t-SNE] Iteration 150: error = 100.6163483, gradient norm = 0.0195194 (50 iterations in 2.591s)
[t-SNE] Iteration 200: error = 97.3039246, gradient norm = 0.0156689 (50 iterations in 2.512s)
[t-SNE] Iteration 250: error = 95.0665588, gradient norm = 0.0124335 (50 iterations in 2.484s)
[t-SNE] KL divergence after 250 iterations with early exaggeration: 95.066559
[t-SNE] Iteration 300: error = 4.1143718, gradient norm = 0.0015598 (50 iterations in 2.224s)
[t-SNE] Iteration 350: error = 3.2087288, gradient norm = 0.0010000 (50 iterations in 1.990s)
[t-SNE] Iteration 400: error = 2.7785664, gradient norm = 0.0007231 (50 iterations in 2.024s)
[t-SNE] Iteration 450: error = 2.5142882, gradient norm = 0.0005710 (50 iterations in 2.042s)
[t-SNE] Iteration 500: error = 2.3313522, gradient norm = 0.0004800 (50 iterations in 2.062s)
[t-SNE] Iteration 550: error = 2.1932867, gradient norm = 0.0004106 (50 iterations in 2.078s)
[t-SNE] Iteration 600: error = 2.0840328, gradient norm = 0.0003637 (50 iterations in 2.089s)
[t-SNE] Iteration 650: error = 1.9942801, gradient norm = 0.0003322 (50 iterations in 2.104s)
[t-SNE] Iteration 700: error = 1.9186578, gradient norm = 0.0003031 (50 iterations in 2.119s)
[t-SNE] Iteration 750: error = 1.8537792, gradient norm = 0.0002782 (50 iterations in 2.127s)
[t-SNE] Iteration 800: error = 1.7970450, gradient norm = 0.0002557 (50 iterations in 2.133s)
[t-SNE] Iteration 850: error = 1.7470232, gradient norm = 0.0002375 (50 iterations in 2.144s)
[t-SNE] Iteration 900: error = 1.7022941, gradient norm = 0.0002236 (50 iterations in 2.137s)
[t-SNE] Iteration 950: error = 1.6622392, gradient norm = 0.0002098 (50 iterations in 2.146s)
[t-SNE] Iteration 1000: error = 1.6259054, gradient norm = 0.0002008 (50 iterations in 2.150s)
[t-SNE] Error after 1000 iterations: 1.625905
Done..
Creating plot for this t-sne visualization..
saving this plot as image in present working directory{\ldots}

    \end{Verbatim}

    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{output_55_1.png}
    \end{center}
    { \hspace*{\fill} \\}
    
    \begin{Verbatim}[commandchars=\\\{\}]
Done

performing tsne with perplexity 5 and with 1000 iterations at max
[t-SNE] Computing 16 nearest neighbors{\ldots}
[t-SNE] Indexed 7352 samples in 0.085s{\ldots}
[t-SNE] Computed neighbors for 7352 samples in 27.997s{\ldots}
[t-SNE] Computed conditional probabilities for sample 1000 / 7352
[t-SNE] Computed conditional probabilities for sample 2000 / 7352
[t-SNE] Computed conditional probabilities for sample 3000 / 7352
[t-SNE] Computed conditional probabilities for sample 4000 / 7352
[t-SNE] Computed conditional probabilities for sample 5000 / 7352
[t-SNE] Computed conditional probabilities for sample 6000 / 7352
[t-SNE] Computed conditional probabilities for sample 7000 / 7352
[t-SNE] Computed conditional probabilities for sample 7352 / 7352
[t-SNE] Mean sigma: 0.961265
[t-SNE] Computed conditional probabilities in 0.058s
[t-SNE] Iteration 50: error = 114.0592880, gradient norm = 0.0203027 (50 iterations in 5.592s)
[t-SNE] Iteration 100: error = 97.2689438, gradient norm = 0.0156565 (50 iterations in 2.620s)
[t-SNE] Iteration 150: error = 92.9875412, gradient norm = 0.0087415 (50 iterations in 2.308s)
[t-SNE] Iteration 200: error = 91.0414810, gradient norm = 0.0071048 (50 iterations in 2.266s)
[t-SNE] Iteration 250: error = 89.8754654, gradient norm = 0.0057384 (50 iterations in 2.205s)
[t-SNE] KL divergence after 250 iterations with early exaggeration: 89.875465
[t-SNE] Iteration 300: error = 3.5759211, gradient norm = 0.0014691 (50 iterations in 2.256s)
[t-SNE] Iteration 350: error = 2.8154438, gradient norm = 0.0007505 (50 iterations in 2.240s)
[t-SNE] Iteration 400: error = 2.4350181, gradient norm = 0.0005242 (50 iterations in 2.264s)
[t-SNE] Iteration 450: error = 2.2171905, gradient norm = 0.0004073 (50 iterations in 2.302s)
[t-SNE] Iteration 500: error = 2.0723400, gradient norm = 0.0003336 (50 iterations in 2.340s)
[t-SNE] Iteration 550: error = 1.9670427, gradient norm = 0.0002847 (50 iterations in 2.343s)
[t-SNE] Iteration 600: error = 1.8857234, gradient norm = 0.0002473 (50 iterations in 2.354s)
[t-SNE] Iteration 650: error = 1.8205318, gradient norm = 0.0002198 (50 iterations in 2.367s)
[t-SNE] Iteration 700: error = 1.7666595, gradient norm = 0.0001984 (50 iterations in 2.379s)
[t-SNE] Iteration 750: error = 1.7211496, gradient norm = 0.0001790 (50 iterations in 2.379s)
[t-SNE] Iteration 800: error = 1.6821029, gradient norm = 0.0001657 (50 iterations in 2.390s)
[t-SNE] Iteration 850: error = 1.6482807, gradient norm = 0.0001518 (50 iterations in 2.398s)
[t-SNE] Iteration 900: error = 1.6185459, gradient norm = 0.0001421 (50 iterations in 2.402s)
[t-SNE] Iteration 950: error = 1.5919563, gradient norm = 0.0001332 (50 iterations in 2.406s)
[t-SNE] Iteration 1000: error = 1.5682360, gradient norm = 0.0001277 (50 iterations in 2.403s)
[t-SNE] Error after 1000 iterations: 1.568236
Done..
Creating plot for this t-sne visualization..
saving this plot as image in present working directory{\ldots}

    \end{Verbatim}

    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{output_55_3.png}
    \end{center}
    { \hspace*{\fill} \\}
    
    \begin{Verbatim}[commandchars=\\\{\}]
Done

performing tsne with perplexity 10 and with 1000 iterations at max
[t-SNE] Computing 31 nearest neighbors{\ldots}
[t-SNE] Indexed 7352 samples in 0.085s{\ldots}
[t-SNE] Computed neighbors for 7352 samples in 28.368s{\ldots}
[t-SNE] Computed conditional probabilities for sample 1000 / 7352
[t-SNE] Computed conditional probabilities for sample 2000 / 7352
[t-SNE] Computed conditional probabilities for sample 3000 / 7352
[t-SNE] Computed conditional probabilities for sample 4000 / 7352
[t-SNE] Computed conditional probabilities for sample 5000 / 7352
[t-SNE] Computed conditional probabilities for sample 6000 / 7352
[t-SNE] Computed conditional probabilities for sample 7000 / 7352
[t-SNE] Computed conditional probabilities for sample 7352 / 7352
[t-SNE] Mean sigma: 1.133828
[t-SNE] Computed conditional probabilities in 0.155s
[t-SNE] Iteration 50: error = 105.6137085, gradient norm = 0.0229994 (50 iterations in 4.228s)
[t-SNE] Iteration 100: error = 89.9958496, gradient norm = 0.0122725 (50 iterations in 3.063s)
[t-SNE] Iteration 150: error = 87.1489944, gradient norm = 0.0071774 (50 iterations in 2.760s)
[t-SNE] Iteration 200: error = 85.9672318, gradient norm = 0.0061608 (50 iterations in 2.772s)
[t-SNE] Iteration 250: error = 85.2867050, gradient norm = 0.0036593 (50 iterations in 2.769s)
[t-SNE] KL divergence after 250 iterations with early exaggeration: 85.286705
[t-SNE] Iteration 300: error = 3.1305749, gradient norm = 0.0013861 (50 iterations in 2.801s)
[t-SNE] Iteration 350: error = 2.4887924, gradient norm = 0.0006460 (50 iterations in 2.720s)
[t-SNE] Iteration 400: error = 2.1697743, gradient norm = 0.0004211 (50 iterations in 2.716s)
[t-SNE] Iteration 450: error = 1.9855604, gradient norm = 0.0003128 (50 iterations in 2.724s)
[t-SNE] Iteration 500: error = 1.8673357, gradient norm = 0.0002509 (50 iterations in 2.730s)
[t-SNE] Iteration 550: error = 1.7841893, gradient norm = 0.0002111 (50 iterations in 2.735s)
[t-SNE] Iteration 600: error = 1.7217950, gradient norm = 0.0001803 (50 iterations in 2.736s)
[t-SNE] Iteration 650: error = 1.6726514, gradient norm = 0.0001601 (50 iterations in 2.735s)
[t-SNE] Iteration 700: error = 1.6333241, gradient norm = 0.0001421 (50 iterations in 2.731s)
[t-SNE] Iteration 750: error = 1.6008626, gradient norm = 0.0001299 (50 iterations in 2.744s)
[t-SNE] Iteration 800: error = 1.5734997, gradient norm = 0.0001197 (50 iterations in 2.738s)
[t-SNE] Iteration 850: error = 1.5501360, gradient norm = 0.0001125 (50 iterations in 2.739s)
[t-SNE] Iteration 900: error = 1.5305120, gradient norm = 0.0001046 (50 iterations in 2.737s)
[t-SNE] Iteration 950: error = 1.5137104, gradient norm = 0.0000972 (50 iterations in 2.745s)
[t-SNE] Iteration 1000: error = 1.4986035, gradient norm = 0.0000922 (50 iterations in 2.751s)
[t-SNE] Error after 1000 iterations: 1.498603
Done..
Creating plot for this t-sne visualization..
saving this plot as image in present working directory{\ldots}

    \end{Verbatim}

    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{output_55_5.png}
    \end{center}
    { \hspace*{\fill} \\}
    
    \begin{Verbatim}[commandchars=\\\{\}]
Done

performing tsne with perplexity 20 and with 1000 iterations at max
[t-SNE] Computing 61 nearest neighbors{\ldots}
[t-SNE] Indexed 7352 samples in 0.085s{\ldots}
[t-SNE] Computed neighbors for 7352 samples in 29.036s{\ldots}
[t-SNE] Computed conditional probabilities for sample 1000 / 7352
[t-SNE] Computed conditional probabilities for sample 2000 / 7352
[t-SNE] Computed conditional probabilities for sample 3000 / 7352
[t-SNE] Computed conditional probabilities for sample 4000 / 7352
[t-SNE] Computed conditional probabilities for sample 5000 / 7352
[t-SNE] Computed conditional probabilities for sample 6000 / 7352
[t-SNE] Computed conditional probabilities for sample 7000 / 7352
[t-SNE] Computed conditional probabilities for sample 7352 / 7352
[t-SNE] Mean sigma: 1.274335
[t-SNE] Computed conditional probabilities in 0.271s
[t-SNE] Iteration 50: error = 97.7926636, gradient norm = 0.0125853 (50 iterations in 10.212s)
[t-SNE] Iteration 100: error = 84.0754013, gradient norm = 0.0064392 (50 iterations in 5.176s)
[t-SNE] Iteration 150: error = 81.9258728, gradient norm = 0.0035655 (50 iterations in 4.332s)
[t-SNE] Iteration 200: error = 81.1771851, gradient norm = 0.0022705 (50 iterations in 4.284s)
[t-SNE] Iteration 250: error = 80.7830048, gradient norm = 0.0021464 (50 iterations in 4.261s)
[t-SNE] KL divergence after 250 iterations with early exaggeration: 80.783005
[t-SNE] Iteration 300: error = 2.7013526, gradient norm = 0.0013006 (50 iterations in 4.028s)
[t-SNE] Iteration 350: error = 2.1675630, gradient norm = 0.0005758 (50 iterations in 3.776s)
[t-SNE] Iteration 400: error = 1.9185538, gradient norm = 0.0003485 (50 iterations in 3.796s)
[t-SNE] Iteration 450: error = 1.7722032, gradient norm = 0.0002463 (50 iterations in 3.821s)
[t-SNE] Iteration 500: error = 1.6783440, gradient norm = 0.0001935 (50 iterations in 3.838s)
[t-SNE] Iteration 550: error = 1.6141162, gradient norm = 0.0001585 (50 iterations in 3.852s)
[t-SNE] Iteration 600: error = 1.5673211, gradient norm = 0.0001348 (50 iterations in 3.869s)
[t-SNE] Iteration 650: error = 1.5318861, gradient norm = 0.0001161 (50 iterations in 3.879s)
[t-SNE] Iteration 700: error = 1.5039140, gradient norm = 0.0001032 (50 iterations in 3.889s)
[t-SNE] Iteration 750: error = 1.4814334, gradient norm = 0.0000954 (50 iterations in 3.893s)
[t-SNE] Iteration 800: error = 1.4631746, gradient norm = 0.0000885 (50 iterations in 3.909s)
[t-SNE] Iteration 850: error = 1.4486455, gradient norm = 0.0000838 (50 iterations in 3.923s)
[t-SNE] Iteration 900: error = 1.4372107, gradient norm = 0.0000781 (50 iterations in 3.938s)
[t-SNE] Iteration 950: error = 1.4272782, gradient norm = 0.0000750 (50 iterations in 3.935s)
[t-SNE] Iteration 1000: error = 1.4186589, gradient norm = 0.0000716 (50 iterations in 3.933s)
[t-SNE] Error after 1000 iterations: 1.418659
Done..
Creating plot for this t-sne visualization..
saving this plot as image in present working directory{\ldots}

    \end{Verbatim}

    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{output_55_7.png}
    \end{center}
    { \hspace*{\fill} \\}
    
    \begin{Verbatim}[commandchars=\\\{\}]
Done

performing tsne with perplexity 50 and with 1000 iterations at max
[t-SNE] Computing 151 nearest neighbors{\ldots}
[t-SNE] Indexed 7352 samples in 0.086s{\ldots}
[t-SNE] Computed neighbors for 7352 samples in 29.958s{\ldots}
[t-SNE] Computed conditional probabilities for sample 1000 / 7352
[t-SNE] Computed conditional probabilities for sample 2000 / 7352
[t-SNE] Computed conditional probabilities for sample 3000 / 7352
[t-SNE] Computed conditional probabilities for sample 4000 / 7352
[t-SNE] Computed conditional probabilities for sample 5000 / 7352
[t-SNE] Computed conditional probabilities for sample 6000 / 7352
[t-SNE] Computed conditional probabilities for sample 7000 / 7352
[t-SNE] Computed conditional probabilities for sample 7352 / 7352
[t-SNE] Mean sigma: 1.437672
[t-SNE] Computed conditional probabilities in 0.563s
[t-SNE] Iteration 50: error = 87.2486420, gradient norm = 0.0071327 (50 iterations in 7.677s)
[t-SNE] Iteration 100: error = 75.6975098, gradient norm = 0.0044917 (50 iterations in 7.338s)
[t-SNE] Iteration 150: error = 74.6203918, gradient norm = 0.0024377 (50 iterations in 6.859s)
[t-SNE] Iteration 200: error = 74.2492752, gradient norm = 0.0015409 (50 iterations in 6.908s)
[t-SNE] Iteration 250: error = 74.0674744, gradient norm = 0.0012064 (50 iterations in 6.929s)
[t-SNE] KL divergence after 250 iterations with early exaggeration: 74.067474
[t-SNE] Iteration 300: error = 2.1519017, gradient norm = 0.0011851 (50 iterations in 6.938s)
[t-SNE] Iteration 350: error = 1.7552953, gradient norm = 0.0004863 (50 iterations in 6.881s)
[t-SNE] Iteration 400: error = 1.5867779, gradient norm = 0.0002808 (50 iterations in 6.877s)
[t-SNE] Iteration 450: error = 1.4929526, gradient norm = 0.0001902 (50 iterations in 6.869s)
[t-SNE] Iteration 500: error = 1.4330895, gradient norm = 0.0001395 (50 iterations in 6.872s)
[t-SNE] Iteration 550: error = 1.3918693, gradient norm = 0.0001124 (50 iterations in 6.866s)
[t-SNE] Iteration 600: error = 1.3627089, gradient norm = 0.0000937 (50 iterations in 6.858s)
[t-SNE] Iteration 650: error = 1.3417925, gradient norm = 0.0000828 (50 iterations in 6.860s)
[t-SNE] Iteration 700: error = 1.3263514, gradient norm = 0.0000745 (50 iterations in 6.865s)
[t-SNE] Iteration 750: error = 1.3148748, gradient norm = 0.0000693 (50 iterations in 6.873s)
[t-SNE] Iteration 800: error = 1.3062829, gradient norm = 0.0000676 (50 iterations in 6.880s)
[t-SNE] Iteration 850: error = 1.2999574, gradient norm = 0.0000594 (50 iterations in 6.882s)
[t-SNE] Iteration 900: error = 1.2946123, gradient norm = 0.0000580 (50 iterations in 6.883s)
[t-SNE] Iteration 950: error = 1.2901206, gradient norm = 0.0000535 (50 iterations in 6.876s)
[t-SNE] Iteration 1000: error = 1.2863228, gradient norm = 0.0000517 (50 iterations in 6.881s)
[t-SNE] Error after 1000 iterations: 1.286323
Done..
Creating plot for this t-sne visualization..
saving this plot as image in present working directory{\ldots}

    \end{Verbatim}

    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{output_55_9.png}
    \end{center}
    { \hspace*{\fill} \\}
    
    \begin{Verbatim}[commandchars=\\\{\}]
Done

    \end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}48}]:} \PY{n}{X\PYZus{}pre\PYZus{}tsne} \PY{o}{=} \PY{n}{train}\PY{o}{.}\PY{n}{drop}\PY{p}{(}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{subject}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Activity}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{ActivityName}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{,} \PY{n}{axis}\PY{o}{=}\PY{l+m+mi}{1}\PY{p}{)}
         \PY{n}{y\PYZus{}pre\PYZus{}tsne} \PY{o}{=} \PY{n}{train}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{ActivityName}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}
         \PY{n}{perform\PYZus{}tsne}\PY{p}{(}\PY{n}{X\PYZus{}data} \PY{o}{=} \PY{n}{X\PYZus{}pre\PYZus{}tsne}\PY{p}{,}\PY{n}{y\PYZus{}data}\PY{o}{=}\PY{n}{y\PYZus{}pre\PYZus{}tsne}\PY{p}{,} \PY{n}{perplexities} \PY{o}{=}\PY{p}{[}\PY{l+m+mi}{20}\PY{p}{,}\PY{l+m+mi}{50}\PY{p}{,}\PY{l+m+mi}{90}\PY{p}{]}\PY{p}{,}\PY{n}{n\PYZus{}iter}\PY{o}{=}\PY{l+m+mi}{2000}\PY{p}{)}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]

performing tsne with perplexity 20 and with 2000 iterations at max
[t-SNE] Computing 61 nearest neighbors{\ldots}
[t-SNE] Indexed 7352 samples in 0.096s{\ldots}
[t-SNE] Computed neighbors for 7352 samples in 29.076s{\ldots}
[t-SNE] Computed conditional probabilities for sample 1000 / 7352
[t-SNE] Computed conditional probabilities for sample 2000 / 7352
[t-SNE] Computed conditional probabilities for sample 3000 / 7352
[t-SNE] Computed conditional probabilities for sample 4000 / 7352
[t-SNE] Computed conditional probabilities for sample 5000 / 7352
[t-SNE] Computed conditional probabilities for sample 6000 / 7352
[t-SNE] Computed conditional probabilities for sample 7000 / 7352
[t-SNE] Computed conditional probabilities for sample 7352 / 7352
[t-SNE] Mean sigma: 1.274335
[t-SNE] Computed conditional probabilities in 0.268s
[t-SNE] Iteration 50: error = 97.7995453, gradient norm = 0.0148661 (50 iterations in 4.925s)
[t-SNE] Iteration 100: error = 84.0072556, gradient norm = 0.0072344 (50 iterations in 4.098s)
[t-SNE] Iteration 150: error = 81.9547729, gradient norm = 0.0038887 (50 iterations in 3.829s)
[t-SNE] Iteration 200: error = 81.1930771, gradient norm = 0.0023243 (50 iterations in 3.886s)
[t-SNE] Iteration 250: error = 80.7936783, gradient norm = 0.0017376 (50 iterations in 3.906s)
[t-SNE] KL divergence after 250 iterations with early exaggeration: 80.793678
[t-SNE] Iteration 300: error = 2.6971016, gradient norm = 0.0013003 (50 iterations in 3.848s)
[t-SNE] Iteration 350: error = 2.1623621, gradient norm = 0.0005753 (50 iterations in 3.746s)
[t-SNE] Iteration 400: error = 1.9135176, gradient norm = 0.0003476 (50 iterations in 3.750s)
[t-SNE] Iteration 450: error = 1.7679424, gradient norm = 0.0002466 (50 iterations in 3.763s)
[t-SNE] Iteration 500: error = 1.6742762, gradient norm = 0.0001907 (50 iterations in 3.771s)
[t-SNE] Iteration 550: error = 1.6101197, gradient norm = 0.0001570 (50 iterations in 3.776s)
[t-SNE] Iteration 600: error = 1.5637125, gradient norm = 0.0001333 (50 iterations in 3.787s)
[t-SNE] Iteration 650: error = 1.5287232, gradient norm = 0.0001169 (50 iterations in 3.789s)
[t-SNE] Iteration 700: error = 1.5011986, gradient norm = 0.0001056 (50 iterations in 3.797s)
[t-SNE] Iteration 750: error = 1.4793161, gradient norm = 0.0000964 (50 iterations in 3.805s)
[t-SNE] Iteration 800: error = 1.4618779, gradient norm = 0.0000929 (50 iterations in 3.807s)
[t-SNE] Iteration 850: error = 1.4484754, gradient norm = 0.0000847 (50 iterations in 3.801s)
[t-SNE] Iteration 900: error = 1.4374721, gradient norm = 0.0000808 (50 iterations in 3.802s)
[t-SNE] Iteration 950: error = 1.4281392, gradient norm = 0.0000762 (50 iterations in 3.805s)
[t-SNE] Iteration 1000: error = 1.4201696, gradient norm = 0.0000742 (50 iterations in 3.811s)
[t-SNE] Error after 1000 iterations: 1.420170
Done..
Creating plot for this t-sne visualization..
saving this plot as image in present working directory{\ldots}

    \end{Verbatim}

    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{output_56_1.png}
    \end{center}
    { \hspace*{\fill} \\}
    
    \begin{Verbatim}[commandchars=\\\{\}]
Done

performing tsne with perplexity 50 and with 2000 iterations at max
[t-SNE] Computing 151 nearest neighbors{\ldots}
[t-SNE] Indexed 7352 samples in 0.084s{\ldots}
[t-SNE] Computed neighbors for 7352 samples in 29.811s{\ldots}
[t-SNE] Computed conditional probabilities for sample 1000 / 7352
[t-SNE] Computed conditional probabilities for sample 2000 / 7352
[t-SNE] Computed conditional probabilities for sample 3000 / 7352
[t-SNE] Computed conditional probabilities for sample 4000 / 7352
[t-SNE] Computed conditional probabilities for sample 5000 / 7352
[t-SNE] Computed conditional probabilities for sample 6000 / 7352
[t-SNE] Computed conditional probabilities for sample 7000 / 7352
[t-SNE] Computed conditional probabilities for sample 7352 / 7352
[t-SNE] Mean sigma: 1.437672
[t-SNE] Computed conditional probabilities in 0.563s
[t-SNE] Iteration 50: error = 86.5717087, gradient norm = 0.0175077 (50 iterations in 9.532s)
[t-SNE] Iteration 100: error = 75.5988235, gradient norm = 0.0040401 (50 iterations in 7.759s)
[t-SNE] Iteration 150: error = 74.7132950, gradient norm = 0.0022374 (50 iterations in 6.777s)
[t-SNE] Iteration 200: error = 74.3355331, gradient norm = 0.0015600 (50 iterations in 6.712s)
[t-SNE] Iteration 250: error = 74.1238327, gradient norm = 0.0013079 (50 iterations in 6.724s)
[t-SNE] KL divergence after 250 iterations with early exaggeration: 74.123833
[t-SNE] Iteration 300: error = 2.1673098, gradient norm = 0.0012021 (50 iterations in 6.918s)
[t-SNE] Iteration 350: error = 1.7651653, gradient norm = 0.0004890 (50 iterations in 6.872s)
[t-SNE] Iteration 400: error = 1.5937643, gradient norm = 0.0002820 (50 iterations in 6.877s)
[t-SNE] Iteration 450: error = 1.4993401, gradient norm = 0.0001900 (50 iterations in 6.881s)
[t-SNE] Iteration 500: error = 1.4392725, gradient norm = 0.0001415 (50 iterations in 6.878s)
[t-SNE] Iteration 550: error = 1.3982749, gradient norm = 0.0001117 (50 iterations in 6.861s)
[t-SNE] Iteration 600: error = 1.3687805, gradient norm = 0.0000930 (50 iterations in 6.867s)
[t-SNE] Iteration 650: error = 1.3471440, gradient norm = 0.0000831 (50 iterations in 6.870s)
[t-SNE] Iteration 700: error = 1.3317789, gradient norm = 0.0000741 (50 iterations in 6.895s)
[t-SNE] Iteration 750: error = 1.3202772, gradient norm = 0.0000682 (50 iterations in 6.894s)
[t-SNE] Iteration 800: error = 1.3111961, gradient norm = 0.0000654 (50 iterations in 6.898s)
[t-SNE] Iteration 850: error = 1.3041462, gradient norm = 0.0000611 (50 iterations in 6.877s)
[t-SNE] Iteration 900: error = 1.2984530, gradient norm = 0.0000579 (50 iterations in 6.878s)
[t-SNE] Iteration 950: error = 1.2937618, gradient norm = 0.0000519 (50 iterations in 6.887s)
[t-SNE] Iteration 1000: error = 1.2894143, gradient norm = 0.0000500 (50 iterations in 6.895s)
[t-SNE] Error after 1000 iterations: 1.289414
Done..
Creating plot for this t-sne visualization..
saving this plot as image in present working directory{\ldots}

    \end{Verbatim}

    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{output_56_3.png}
    \end{center}
    { \hspace*{\fill} \\}
    
    \begin{Verbatim}[commandchars=\\\{\}]
Done

performing tsne with perplexity 90 and with 2000 iterations at max
[t-SNE] Computing 271 nearest neighbors{\ldots}
[t-SNE] Indexed 7352 samples in 0.085s{\ldots}
[t-SNE] Computed neighbors for 7352 samples in 30.783s{\ldots}
[t-SNE] Computed conditional probabilities for sample 1000 / 7352
[t-SNE] Computed conditional probabilities for sample 2000 / 7352
[t-SNE] Computed conditional probabilities for sample 3000 / 7352
[t-SNE] Computed conditional probabilities for sample 4000 / 7352
[t-SNE] Computed conditional probabilities for sample 5000 / 7352
[t-SNE] Computed conditional probabilities for sample 6000 / 7352
[t-SNE] Computed conditional probabilities for sample 7000 / 7352
[t-SNE] Computed conditional probabilities for sample 7352 / 7352
[t-SNE] Mean sigma: 1.540175
[t-SNE] Computed conditional probabilities in 0.960s
[t-SNE] Iteration 50: error = 77.8780289, gradient norm = 0.0304282 (50 iterations in 11.843s)
[t-SNE] Iteration 100: error = 69.3429031, gradient norm = 0.0028602 (50 iterations in 11.184s)
[t-SNE] Iteration 150: error = 68.8140335, gradient norm = 0.0018916 (50 iterations in 10.861s)
[t-SNE] Iteration 200: error = 68.6173096, gradient norm = 0.0011898 (50 iterations in 10.953s)
[t-SNE] Iteration 250: error = 68.5081253, gradient norm = 0.0010420 (50 iterations in 11.034s)
[t-SNE] KL divergence after 250 iterations with early exaggeration: 68.508125
[t-SNE] Iteration 300: error = 1.8464389, gradient norm = 0.0012062 (50 iterations in 11.311s)
[t-SNE] Iteration 350: error = 1.5126369, gradient norm = 0.0004407 (50 iterations in 11.089s)
[t-SNE] Iteration 400: error = 1.3816696, gradient norm = 0.0002530 (50 iterations in 11.059s)
[t-SNE] Iteration 450: error = 1.3117870, gradient norm = 0.0001741 (50 iterations in 11.065s)
[t-SNE] Iteration 500: error = 1.2696241, gradient norm = 0.0001230 (50 iterations in 11.059s)
[t-SNE] Iteration 550: error = 1.2407528, gradient norm = 0.0000947 (50 iterations in 11.048s)
[t-SNE] Iteration 600: error = 1.2200854, gradient norm = 0.0000762 (50 iterations in 11.047s)
[t-SNE] Iteration 650: error = 1.2050776, gradient norm = 0.0000659 (50 iterations in 11.058s)
[t-SNE] Iteration 700: error = 1.1939315, gradient norm = 0.0000586 (50 iterations in 11.072s)
[t-SNE] Iteration 750: error = 1.1858423, gradient norm = 0.0000530 (50 iterations in 11.082s)
[t-SNE] Iteration 800: error = 1.1796997, gradient norm = 0.0000490 (50 iterations in 11.086s)
[t-SNE] Iteration 850: error = 1.1750507, gradient norm = 0.0000472 (50 iterations in 11.079s)
[t-SNE] Iteration 900: error = 1.1714048, gradient norm = 0.0000439 (50 iterations in 11.071s)
[t-SNE] Iteration 950: error = 1.1685311, gradient norm = 0.0000415 (50 iterations in 11.069s)
[t-SNE] Iteration 1000: error = 1.1659497, gradient norm = 0.0000405 (50 iterations in 11.073s)
[t-SNE] Error after 1000 iterations: 1.165950
Done..
Creating plot for this t-sne visualization..
saving this plot as image in present working directory{\ldots}

    \end{Verbatim}

    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{output_56_5.png}
    \end{center}
    { \hspace*{\fill} \\}
    
    \begin{Verbatim}[commandchars=\\\{\}]
Done

    \end{Verbatim}

    

    \subsection{Obtain the train and test
data}\label{obtain-the-train-and-test-data}

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}2}]:} \PY{n}{train} \PY{o}{=} \PY{n}{pd}\PY{o}{.}\PY{n}{read\PYZus{}csv}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{UCI\PYZus{}HAR\PYZus{}Dataset/csv\PYZus{}files/train.csv}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
        \PY{n}{test} \PY{o}{=} \PY{n}{pd}\PY{o}{.}\PY{n}{read\PYZus{}csv}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{UCI\PYZus{}HAR\PYZus{}Dataset/csv\PYZus{}files/test.csv}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
        \PY{n+nb}{print}\PY{p}{(}\PY{n}{train}\PY{o}{.}\PY{n}{shape}\PY{p}{,} \PY{n}{test}\PY{o}{.}\PY{n}{shape}\PY{p}{)}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
(7352, 564) (2947, 564)

    \end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}3}]:} \PY{n}{train}\PY{o}{.}\PY{n}{head}\PY{p}{(}\PY{l+m+mi}{1}\PY{p}{)}
\end{Verbatim}


\begin{Verbatim}[commandchars=\\\{\}]
{\color{outcolor}Out[{\color{outcolor}3}]:}    tBodyAcc\_mean\_X  tBodyAcc\_mean\_Y  tBodyAcc\_mean\_Z  tBodyAcc\_std\_X  \textbackslash{}
        0         0.288585        -0.020294        -0.132905       -0.995279   
        
           tBodyAcc\_std\_Y  tBodyAcc\_std\_Z  tBodyAcc\_mad\_X  tBodyAcc\_mad\_Y  \textbackslash{}
        0       -0.983111       -0.913526       -0.995112       -0.983185   
        
           tBodyAcc\_mad\_Z  tBodyAcc\_max\_X      {\ldots}       angletBodyAccMeangravity  \textbackslash{}
        0       -0.923527       -0.934724      {\ldots}                      -0.112754   
        
           angletBodyAccJerkMeangravityMean  angletBodyGyroMeangravityMean  \textbackslash{}
        0                            0.0304                      -0.464761   
        
           angletBodyGyroJerkMeangravityMean  angleXgravityMean  angleYgravityMean  \textbackslash{}
        0                          -0.018446          -0.841247           0.179941   
        
           angleZgravityMean  subject  Activity  ActivityName  
        0          -0.058627        1         5      STANDING  
        
        [1 rows x 564 columns]
\end{Verbatim}
            
    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}4}]:} \PY{c+c1}{\PYZsh{} get X\PYZus{}train and y\PYZus{}train from csv files}
        \PY{n}{X\PYZus{}train} \PY{o}{=} \PY{n}{train}\PY{o}{.}\PY{n}{drop}\PY{p}{(}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{subject}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Activity}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{ActivityName}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{,} \PY{n}{axis}\PY{o}{=}\PY{l+m+mi}{1}\PY{p}{)}
        \PY{n}{y\PYZus{}train} \PY{o}{=} \PY{n}{train}\PY{o}{.}\PY{n}{ActivityName}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}5}]:} \PY{c+c1}{\PYZsh{} get X\PYZus{}test and y\PYZus{}test from test csv file}
        \PY{n}{X\PYZus{}test} \PY{o}{=} \PY{n}{test}\PY{o}{.}\PY{n}{drop}\PY{p}{(}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{subject}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Activity}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{ActivityName}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{,} \PY{n}{axis}\PY{o}{=}\PY{l+m+mi}{1}\PY{p}{)}
        \PY{n}{y\PYZus{}test} \PY{o}{=} \PY{n}{test}\PY{o}{.}\PY{n}{ActivityName}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}6}]:} \PY{n+nb}{print}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{X\PYZus{}train and y\PYZus{}train : (}\PY{l+s+si}{\PYZob{}\PYZcb{}}\PY{l+s+s1}{,}\PY{l+s+si}{\PYZob{}\PYZcb{}}\PY{l+s+s1}{)}\PY{l+s+s1}{\PYZsq{}}\PY{o}{.}\PY{n}{format}\PY{p}{(}\PY{n}{X\PYZus{}train}\PY{o}{.}\PY{n}{shape}\PY{p}{,} \PY{n}{y\PYZus{}train}\PY{o}{.}\PY{n}{shape}\PY{p}{)}\PY{p}{)}
        \PY{n+nb}{print}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{X\PYZus{}test  and y\PYZus{}test  : (}\PY{l+s+si}{\PYZob{}\PYZcb{}}\PY{l+s+s1}{,}\PY{l+s+si}{\PYZob{}\PYZcb{}}\PY{l+s+s1}{)}\PY{l+s+s1}{\PYZsq{}}\PY{o}{.}\PY{n}{format}\PY{p}{(}\PY{n}{X\PYZus{}test}\PY{o}{.}\PY{n}{shape}\PY{p}{,} \PY{n}{y\PYZus{}test}\PY{o}{.}\PY{n}{shape}\PY{p}{)}\PY{p}{)}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
X\_train and y\_train : ((7352, 561),(7352,))
X\_test  and y\_test  : ((2947, 561),(2947,))

    \end{Verbatim}

    \section{Let's model with our data}\label{lets-model-with-our-data}

    \subsubsection{Labels that are useful in plotting confusion
matrix}\label{labels-that-are-useful-in-plotting-confusion-matrix}

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}43}]:} \PY{n}{labels}\PY{o}{=}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{LAYING}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{SITTING}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{STANDING}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{WALKING}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{WALKING\PYZus{}DOWNSTAIRS}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{WALKING\PYZus{}UPSTAIRS}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}
\end{Verbatim}


    \subsubsection{Function to plot the confusion
matrix}\label{function-to-plot-the-confusion-matrix}

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}176}]:} \PY{k+kn}{import} \PY{n+nn}{itertools}
          \PY{k+kn}{import} \PY{n+nn}{numpy} \PY{k}{as} \PY{n+nn}{np}
          \PY{k+kn}{import} \PY{n+nn}{matplotlib}\PY{n+nn}{.}\PY{n+nn}{pyplot} \PY{k}{as} \PY{n+nn}{plt}
          \PY{k+kn}{from} \PY{n+nn}{sklearn}\PY{n+nn}{.}\PY{n+nn}{metrics} \PY{k}{import} \PY{n}{confusion\PYZus{}matrix}
          
          \PY{k}{def} \PY{n+nf}{plot\PYZus{}confusion\PYZus{}matrix}\PY{p}{(}\PY{n}{cm}\PY{p}{,} \PY{n}{classes}\PY{p}{,}
                                    \PY{n}{normalize}\PY{o}{=}\PY{k+kc}{False}\PY{p}{,}
                                    \PY{n}{title}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Confusion matrix}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}
                                    \PY{n}{cmap}\PY{o}{=}\PY{n}{plt}\PY{o}{.}\PY{n}{cm}\PY{o}{.}\PY{n}{Blues}\PY{p}{)}\PY{p}{:}
              \PY{k}{if} \PY{n}{normalize}\PY{p}{:}
                  \PY{n}{cm} \PY{o}{=} \PY{n}{cm}\PY{o}{.}\PY{n}{astype}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{float}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)} \PY{o}{/} \PY{n}{cm}\PY{o}{.}\PY{n}{sum}\PY{p}{(}\PY{n}{axis}\PY{o}{=}\PY{l+m+mi}{1}\PY{p}{)}\PY{p}{[}\PY{p}{:}\PY{p}{,} \PY{n}{np}\PY{o}{.}\PY{n}{newaxis}\PY{p}{]}
          
              \PY{n}{plt}\PY{o}{.}\PY{n}{imshow}\PY{p}{(}\PY{n}{cm}\PY{p}{,} \PY{n}{interpolation}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{nearest}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{cmap}\PY{o}{=}\PY{n}{cmap}\PY{p}{)}
              \PY{n}{plt}\PY{o}{.}\PY{n}{title}\PY{p}{(}\PY{n}{title}\PY{p}{)}
              \PY{n}{plt}\PY{o}{.}\PY{n}{colorbar}\PY{p}{(}\PY{p}{)}
              \PY{n}{tick\PYZus{}marks} \PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{arange}\PY{p}{(}\PY{n+nb}{len}\PY{p}{(}\PY{n}{classes}\PY{p}{)}\PY{p}{)}
              \PY{n}{plt}\PY{o}{.}\PY{n}{xticks}\PY{p}{(}\PY{n}{tick\PYZus{}marks}\PY{p}{,} \PY{n}{classes}\PY{p}{,} \PY{n}{rotation}\PY{o}{=}\PY{l+m+mi}{90}\PY{p}{)}
              \PY{n}{plt}\PY{o}{.}\PY{n}{yticks}\PY{p}{(}\PY{n}{tick\PYZus{}marks}\PY{p}{,} \PY{n}{classes}\PY{p}{)}
          
              \PY{n}{fmt} \PY{o}{=} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{.2f}\PY{l+s+s1}{\PYZsq{}} \PY{k}{if} \PY{n}{normalize} \PY{k}{else} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{d}\PY{l+s+s1}{\PYZsq{}}
              \PY{n}{thresh} \PY{o}{=} \PY{n}{cm}\PY{o}{.}\PY{n}{max}\PY{p}{(}\PY{p}{)} \PY{o}{/} \PY{l+m+mf}{2.}
              \PY{k}{for} \PY{n}{i}\PY{p}{,} \PY{n}{j} \PY{o+ow}{in} \PY{n}{itertools}\PY{o}{.}\PY{n}{product}\PY{p}{(}\PY{n+nb}{range}\PY{p}{(}\PY{n}{cm}\PY{o}{.}\PY{n}{shape}\PY{p}{[}\PY{l+m+mi}{0}\PY{p}{]}\PY{p}{)}\PY{p}{,} \PY{n+nb}{range}\PY{p}{(}\PY{n}{cm}\PY{o}{.}\PY{n}{shape}\PY{p}{[}\PY{l+m+mi}{1}\PY{p}{]}\PY{p}{)}\PY{p}{)}\PY{p}{:}
                  \PY{n}{plt}\PY{o}{.}\PY{n}{text}\PY{p}{(}\PY{n}{j}\PY{p}{,} \PY{n}{i}\PY{p}{,} \PY{n+nb}{format}\PY{p}{(}\PY{n}{cm}\PY{p}{[}\PY{n}{i}\PY{p}{,} \PY{n}{j}\PY{p}{]}\PY{p}{,} \PY{n}{fmt}\PY{p}{)}\PY{p}{,}
                           \PY{n}{horizontalalignment}\PY{o}{=}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{center}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,}
                           \PY{n}{color}\PY{o}{=}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{white}\PY{l+s+s2}{\PYZdq{}} \PY{k}{if} \PY{n}{cm}\PY{p}{[}\PY{n}{i}\PY{p}{,} \PY{n}{j}\PY{p}{]} \PY{o}{\PYZgt{}} \PY{n}{thresh} \PY{k}{else} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{black}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
          
              \PY{n}{plt}\PY{o}{.}\PY{n}{tight\PYZus{}layout}\PY{p}{(}\PY{p}{)}
              \PY{n}{plt}\PY{o}{.}\PY{n}{ylabel}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{True label}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
              \PY{n}{plt}\PY{o}{.}\PY{n}{xlabel}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Predicted label}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
\end{Verbatim}


    \subsubsection{Generic function to run any model
specified}\label{generic-function-to-run-any-model-specified}

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}177}]:} \PY{k+kn}{from} \PY{n+nn}{datetime} \PY{k}{import} \PY{n}{datetime}
          \PY{k}{def} \PY{n+nf}{perform\PYZus{}model}\PY{p}{(}\PY{n}{model}\PY{p}{,} \PY{n}{X\PYZus{}train}\PY{p}{,} \PY{n}{y\PYZus{}train}\PY{p}{,} \PY{n}{X\PYZus{}test}\PY{p}{,} \PY{n}{y\PYZus{}test}\PY{p}{,} \PY{n}{class\PYZus{}labels}\PY{p}{,} \PY{n}{cm\PYZus{}normalize}\PY{o}{=}\PY{k+kc}{True}\PY{p}{,} \PYZbs{}
                           \PY{n}{print\PYZus{}cm}\PY{o}{=}\PY{k+kc}{True}\PY{p}{,} \PY{n}{cm\PYZus{}cmap}\PY{o}{=}\PY{n}{plt}\PY{o}{.}\PY{n}{cm}\PY{o}{.}\PY{n}{Greens}\PY{p}{)}\PY{p}{:}
              
              \PY{c+c1}{\PYZsh{} to store results at various phases}
              \PY{n}{results} \PY{o}{=} \PY{n+nb}{dict}\PY{p}{(}\PY{p}{)}
              
              \PY{c+c1}{\PYZsh{} time at which model starts training }
              \PY{n}{train\PYZus{}start\PYZus{}time} \PY{o}{=} \PY{n}{datetime}\PY{o}{.}\PY{n}{now}\PY{p}{(}\PY{p}{)}
              \PY{n+nb}{print}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{training the model..}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
              \PY{n}{model}\PY{o}{.}\PY{n}{fit}\PY{p}{(}\PY{n}{X\PYZus{}train}\PY{p}{,} \PY{n}{y\PYZus{}train}\PY{p}{)}
              \PY{n+nb}{print}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Done }\PY{l+s+se}{\PYZbs{}n}\PY{l+s+s1}{ }\PY{l+s+se}{\PYZbs{}n}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
              \PY{n}{train\PYZus{}end\PYZus{}time} \PY{o}{=} \PY{n}{datetime}\PY{o}{.}\PY{n}{now}\PY{p}{(}\PY{p}{)}
              \PY{n}{results}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{training\PYZus{}time}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]} \PY{o}{=}  \PY{n}{train\PYZus{}end\PYZus{}time} \PY{o}{\PYZhy{}} \PY{n}{train\PYZus{}start\PYZus{}time}
              \PY{n+nb}{print}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{training\PYZus{}time(HH:MM:SS.ms) \PYZhy{} }\PY{l+s+si}{\PYZob{}\PYZcb{}}\PY{l+s+se}{\PYZbs{}n}\PY{l+s+se}{\PYZbs{}n}\PY{l+s+s1}{\PYZsq{}}\PY{o}{.}\PY{n}{format}\PY{p}{(}\PY{n}{results}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{training\PYZus{}time}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{)}\PY{p}{)}
              
              
              \PY{c+c1}{\PYZsh{} predict test data}
              \PY{n+nb}{print}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Predicting test data}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
              \PY{n}{test\PYZus{}start\PYZus{}time} \PY{o}{=} \PY{n}{datetime}\PY{o}{.}\PY{n}{now}\PY{p}{(}\PY{p}{)}
              \PY{n}{y\PYZus{}pred} \PY{o}{=} \PY{n}{model}\PY{o}{.}\PY{n}{predict}\PY{p}{(}\PY{n}{X\PYZus{}test}\PY{p}{)}
              \PY{n}{test\PYZus{}end\PYZus{}time} \PY{o}{=} \PY{n}{datetime}\PY{o}{.}\PY{n}{now}\PY{p}{(}\PY{p}{)}
              \PY{n+nb}{print}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Done }\PY{l+s+se}{\PYZbs{}n}\PY{l+s+s1}{ }\PY{l+s+se}{\PYZbs{}n}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
              \PY{n}{results}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{testing\PYZus{}time}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]} \PY{o}{=} \PY{n}{test\PYZus{}end\PYZus{}time} \PY{o}{\PYZhy{}} \PY{n}{test\PYZus{}start\PYZus{}time}
              \PY{n+nb}{print}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{testing time(HH:MM:SS:ms) \PYZhy{} }\PY{l+s+si}{\PYZob{}\PYZcb{}}\PY{l+s+se}{\PYZbs{}n}\PY{l+s+se}{\PYZbs{}n}\PY{l+s+s1}{\PYZsq{}}\PY{o}{.}\PY{n}{format}\PY{p}{(}\PY{n}{results}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{testing\PYZus{}time}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{)}\PY{p}{)}
              \PY{n}{results}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{predicted}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]} \PY{o}{=} \PY{n}{y\PYZus{}pred}
             
          
              \PY{c+c1}{\PYZsh{} calculate overall accuracty of the model}
              \PY{n}{accuracy} \PY{o}{=} \PY{n}{metrics}\PY{o}{.}\PY{n}{accuracy\PYZus{}score}\PY{p}{(}\PY{n}{y\PYZus{}true}\PY{o}{=}\PY{n}{y\PYZus{}test}\PY{p}{,} \PY{n}{y\PYZus{}pred}\PY{o}{=}\PY{n}{y\PYZus{}pred}\PY{p}{)}
              \PY{c+c1}{\PYZsh{} store accuracy in results}
              \PY{n}{results}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{accuracy}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]} \PY{o}{=} \PY{n}{accuracy}
              \PY{n+nb}{print}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
              \PY{n+nb}{print}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{|      Accuracy      |}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
              \PY{n+nb}{print}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
              \PY{n+nb}{print}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+se}{\PYZbs{}n}\PY{l+s+s1}{    }\PY{l+s+si}{\PYZob{}\PYZcb{}}\PY{l+s+se}{\PYZbs{}n}\PY{l+s+se}{\PYZbs{}n}\PY{l+s+s1}{\PYZsq{}}\PY{o}{.}\PY{n}{format}\PY{p}{(}\PY{n}{accuracy}\PY{p}{)}\PY{p}{)}
              
              
              \PY{c+c1}{\PYZsh{} confusion matrix}
              \PY{n}{cm} \PY{o}{=} \PY{n}{metrics}\PY{o}{.}\PY{n}{confusion\PYZus{}matrix}\PY{p}{(}\PY{n}{y\PYZus{}test}\PY{p}{,} \PY{n}{y\PYZus{}pred}\PY{p}{)}
              \PY{n}{results}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{confusion\PYZus{}matrix}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]} \PY{o}{=} \PY{n}{cm}
              \PY{k}{if} \PY{n}{print\PYZus{}cm}\PY{p}{:} 
                  \PY{n+nb}{print}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
                  \PY{n+nb}{print}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{| Confusion Matrix |}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
                  \PY{n+nb}{print}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
                  \PY{n+nb}{print}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+se}{\PYZbs{}n}\PY{l+s+s1}{ }\PY{l+s+si}{\PYZob{}\PYZcb{}}\PY{l+s+s1}{\PYZsq{}}\PY{o}{.}\PY{n}{format}\PY{p}{(}\PY{n}{cm}\PY{p}{)}\PY{p}{)}
                  
              \PY{c+c1}{\PYZsh{} plot confusin matrix}
              \PY{n}{plt}\PY{o}{.}\PY{n}{figure}\PY{p}{(}\PY{n}{figsize}\PY{o}{=}\PY{p}{(}\PY{l+m+mi}{8}\PY{p}{,}\PY{l+m+mi}{8}\PY{p}{)}\PY{p}{)}
              \PY{n}{plt}\PY{o}{.}\PY{n}{grid}\PY{p}{(}\PY{n}{b}\PY{o}{=}\PY{k+kc}{False}\PY{p}{)}
              \PY{n}{plot\PYZus{}confusion\PYZus{}matrix}\PY{p}{(}\PY{n}{cm}\PY{p}{,} \PY{n}{classes}\PY{o}{=}\PY{n}{class\PYZus{}labels}\PY{p}{,} \PY{n}{normalize}\PY{o}{=}\PY{k+kc}{True}\PY{p}{,} \PY{n}{title}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Normalized confusion matrix}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{cmap} \PY{o}{=} \PY{n}{cm\PYZus{}cmap}\PY{p}{)}
              \PY{n}{plt}\PY{o}{.}\PY{n}{show}\PY{p}{(}\PY{p}{)}
              
              \PY{c+c1}{\PYZsh{} get classification report}
              \PY{n+nb}{print}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
              \PY{n+nb}{print}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{| Classifiction Report |}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
              \PY{n+nb}{print}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
              \PY{n}{classification\PYZus{}report} \PY{o}{=} \PY{n}{metrics}\PY{o}{.}\PY{n}{classification\PYZus{}report}\PY{p}{(}\PY{n}{y\PYZus{}test}\PY{p}{,} \PY{n}{y\PYZus{}pred}\PY{p}{)}
              \PY{c+c1}{\PYZsh{} store report in results}
              \PY{n}{results}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{classification\PYZus{}report}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]} \PY{o}{=} \PY{n}{classification\PYZus{}report}
              \PY{n+nb}{print}\PY{p}{(}\PY{n}{classification\PYZus{}report}\PY{p}{)}
              
              \PY{c+c1}{\PYZsh{} add the trained  model to the results}
              \PY{n}{results}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{model}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]} \PY{o}{=} \PY{n}{model}
              
              \PY{k}{return} \PY{n}{results}
\end{Verbatim}


    \subsubsection{Method to print the gridsearch
Attributes}\label{method-to-print-the-gridsearch-attributes}

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}178}]:} \PY{k}{def} \PY{n+nf}{print\PYZus{}grid\PYZus{}search\PYZus{}attributes}\PY{p}{(}\PY{n}{model}\PY{p}{)}\PY{p}{:}
              \PY{c+c1}{\PYZsh{} Estimator that gave highest score among all the estimators formed in GridSearch}
              \PY{n+nb}{print}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
              \PY{n+nb}{print}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{|      Best Estimator     |}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
              \PY{n+nb}{print}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
              \PY{n+nb}{print}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+se}{\PYZbs{}n}\PY{l+s+se}{\PYZbs{}t}\PY{l+s+si}{\PYZob{}\PYZcb{}}\PY{l+s+se}{\PYZbs{}n}\PY{l+s+s1}{\PYZsq{}}\PY{o}{.}\PY{n}{format}\PY{p}{(}\PY{n}{model}\PY{o}{.}\PY{n}{best\PYZus{}estimator\PYZus{}}\PY{p}{)}\PY{p}{)}
          
          
              \PY{c+c1}{\PYZsh{} parameters that gave best results while performing grid search}
              \PY{n+nb}{print}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
              \PY{n+nb}{print}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{|     Best parameters     |}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
              \PY{n+nb}{print}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
              \PY{n+nb}{print}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+se}{\PYZbs{}t}\PY{l+s+s1}{Parameters of best estimator : }\PY{l+s+se}{\PYZbs{}n}\PY{l+s+se}{\PYZbs{}n}\PY{l+s+se}{\PYZbs{}t}\PY{l+s+si}{\PYZob{}\PYZcb{}}\PY{l+s+se}{\PYZbs{}n}\PY{l+s+s1}{\PYZsq{}}\PY{o}{.}\PY{n}{format}\PY{p}{(}\PY{n}{model}\PY{o}{.}\PY{n}{best\PYZus{}params\PYZus{}}\PY{p}{)}\PY{p}{)}
          
          
              \PY{c+c1}{\PYZsh{}  number of cross validation splits}
              \PY{n+nb}{print}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
              \PY{n+nb}{print}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{|   No of CrossValidation sets   |}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
              \PY{n+nb}{print}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
              \PY{n+nb}{print}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+se}{\PYZbs{}n}\PY{l+s+se}{\PYZbs{}t}\PY{l+s+s1}{Total numbre of cross validation sets: }\PY{l+s+si}{\PYZob{}\PYZcb{}}\PY{l+s+se}{\PYZbs{}n}\PY{l+s+s1}{\PYZsq{}}\PY{o}{.}\PY{n}{format}\PY{p}{(}\PY{n}{model}\PY{o}{.}\PY{n}{n\PYZus{}splits\PYZus{}}\PY{p}{)}\PY{p}{)}
          
          
              \PY{c+c1}{\PYZsh{} Average cross validated score of the best estimator, from the Grid Search }
              \PY{n+nb}{print}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
              \PY{n+nb}{print}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{|        Best Score       |}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
              \PY{n+nb}{print}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
              \PY{n+nb}{print}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+se}{\PYZbs{}n}\PY{l+s+se}{\PYZbs{}t}\PY{l+s+s1}{Average Cross Validate scores of best estimator : }\PY{l+s+se}{\PYZbs{}n}\PY{l+s+se}{\PYZbs{}n}\PY{l+s+se}{\PYZbs{}t}\PY{l+s+si}{\PYZob{}\PYZcb{}}\PY{l+s+se}{\PYZbs{}n}\PY{l+s+s1}{\PYZsq{}}\PY{o}{.}\PY{n}{format}\PY{p}{(}\PY{n}{model}\PY{o}{.}\PY{n}{best\PYZus{}score\PYZus{}}\PY{p}{)}\PY{p}{)}
              
\end{Verbatim}


    \section{1. Logistic Regression with Grid
Search}\label{logistic-regression-with-grid-search}

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}11}]:} \PY{k+kn}{from} \PY{n+nn}{sklearn} \PY{k}{import} \PY{n}{linear\PYZus{}model}
         \PY{k+kn}{from} \PY{n+nn}{sklearn} \PY{k}{import} \PY{n}{metrics}
         
         \PY{k+kn}{from} \PY{n+nn}{sklearn}\PY{n+nn}{.}\PY{n+nn}{model\PYZus{}selection} \PY{k}{import} \PY{n}{GridSearchCV}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}12}]:} \PY{c+c1}{\PYZsh{} start Grid search}
         \PY{n}{parameters} \PY{o}{=} \PY{p}{\PYZob{}}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{C}\PY{l+s+s1}{\PYZsq{}}\PY{p}{:}\PY{p}{[}\PY{l+m+mf}{0.01}\PY{p}{,} \PY{l+m+mf}{0.1}\PY{p}{,} \PY{l+m+mi}{1}\PY{p}{,} \PY{l+m+mi}{10}\PY{p}{,} \PY{l+m+mi}{20}\PY{p}{,} \PY{l+m+mi}{30}\PY{p}{]}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{penalty}\PY{l+s+s1}{\PYZsq{}}\PY{p}{:}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{l2}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{l1}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{\PYZcb{}}
         \PY{n}{log\PYZus{}reg} \PY{o}{=} \PY{n}{linear\PYZus{}model}\PY{o}{.}\PY{n}{LogisticRegression}\PY{p}{(}\PY{p}{)}
         \PY{n}{log\PYZus{}reg\PYZus{}grid} \PY{o}{=} \PY{n}{GridSearchCV}\PY{p}{(}\PY{n}{log\PYZus{}reg}\PY{p}{,} \PY{n}{param\PYZus{}grid}\PY{o}{=}\PY{n}{parameters}\PY{p}{,} \PY{n}{cv}\PY{o}{=}\PY{l+m+mi}{3}\PY{p}{,} \PY{n}{verbose}\PY{o}{=}\PY{l+m+mi}{1}\PY{p}{,} \PY{n}{n\PYZus{}jobs}\PY{o}{=}\PY{l+m+mi}{8}\PY{p}{)}
         \PY{n}{log\PYZus{}reg\PYZus{}grid\PYZus{}results} \PY{o}{=}  \PY{n}{perform\PYZus{}model}\PY{p}{(}\PY{n}{log\PYZus{}reg\PYZus{}grid}\PY{p}{,} \PY{n}{X\PYZus{}train}\PY{p}{,} \PY{n}{y\PYZus{}train}\PY{p}{,} \PY{n}{X\PYZus{}test}\PY{p}{,} \PY{n}{y\PYZus{}test}\PY{p}{,} \PY{n}{class\PYZus{}labels}\PY{o}{=}\PY{n}{labels}\PY{p}{)}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
training the model..
Fitting 3 folds for each of 12 candidates, totalling 36 fits

    \end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]
[Parallel(n\_jobs=8)]: Done  36 out of  36 | elapsed:   31.3s finished

    \end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]
Done 
 

training\_time(HH:MM:SS.ms) - 0:00:41.152479


Predicting test data
Done 
 

testing time(HH:MM:SS:ms) - 0:00:00.021982


---------------------
|      Accuracy      |
---------------------

    0.9630132337970818


--------------------
| Confusion Matrix |
--------------------

 [[537   0   0   0   0   0]
 [  2 428  57   0   0   4]
 [  0  11 520   1   0   0]
 [  0   0   0 495   1   0]
 [  0   0   0   3 409   8]
 [  0   0   0  22   0 449]]

    \end{Verbatim}

    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{output_75_3.png}
    \end{center}
    { \hspace*{\fill} \\}
    
    \begin{Verbatim}[commandchars=\\\{\}]
-------------------------
| Classifiction Report |
-------------------------
                    precision    recall  f1-score   support

            LAYING       1.00      1.00      1.00       537
           SITTING       0.97      0.87      0.92       491
          STANDING       0.90      0.98      0.94       532
           WALKING       0.95      1.00      0.97       496
WALKING\_DOWNSTAIRS       1.00      0.97      0.99       420
  WALKING\_UPSTAIRS       0.97      0.95      0.96       471

       avg / total       0.96      0.96      0.96      2947


    \end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}13}]:} \PY{n}{plt}\PY{o}{.}\PY{n}{figure}\PY{p}{(}\PY{n}{figsize}\PY{o}{=}\PY{p}{(}\PY{l+m+mi}{8}\PY{p}{,}\PY{l+m+mi}{8}\PY{p}{)}\PY{p}{)}
         \PY{n}{plt}\PY{o}{.}\PY{n}{grid}\PY{p}{(}\PY{n}{b}\PY{o}{=}\PY{k+kc}{False}\PY{p}{)}
         \PY{n}{plot\PYZus{}confusion\PYZus{}matrix}\PY{p}{(}\PY{n}{log\PYZus{}reg\PYZus{}grid\PYZus{}results}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{confusion\PYZus{}matrix}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{,} \PY{n}{classes}\PY{o}{=}\PY{n}{labels}\PY{p}{,} \PY{n}{cmap}\PY{o}{=}\PY{n}{plt}\PY{o}{.}\PY{n}{cm}\PY{o}{.}\PY{n}{Greens}\PY{p}{,} \PY{p}{)}
         \PY{n}{plt}\PY{o}{.}\PY{n}{show}\PY{p}{(}\PY{p}{)}
\end{Verbatim}


    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{output_76_0.png}
    \end{center}
    { \hspace*{\fill} \\}
    
    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}14}]:} \PY{c+c1}{\PYZsh{} observe the attributes of the model }
         \PY{n}{print\PYZus{}grid\PYZus{}search\PYZus{}attributes}\PY{p}{(}\PY{n}{log\PYZus{}reg\PYZus{}grid\PYZus{}results}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{model}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{)}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
--------------------------
|      Best Estimator     |
--------------------------

	LogisticRegression(C=30, class\_weight=None, dual=False, fit\_intercept=True,
          intercept\_scaling=1, max\_iter=100, multi\_class='ovr', n\_jobs=1,
          penalty='l2', random\_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm\_start=False)

--------------------------
|     Best parameters     |
--------------------------
	Parameters of best estimator : 

	\{'C': 30, 'penalty': 'l2'\}

---------------------------------
|   No of CrossValidation sets   |
--------------------------------

	Total numbre of cross validation sets: 3

--------------------------
|        Best Score       |
--------------------------

	Average Cross Validate scores of best estimator : 

	0.9460010881392819


    \end{Verbatim}

    \section{2. Linear SVC with
GridSearch}\label{linear-svc-with-gridsearch}

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}15}]:} \PY{k+kn}{from} \PY{n+nn}{sklearn}\PY{n+nn}{.}\PY{n+nn}{svm} \PY{k}{import} \PY{n}{LinearSVC}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}16}]:} \PY{n}{parameters} \PY{o}{=} \PY{p}{\PYZob{}}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{C}\PY{l+s+s1}{\PYZsq{}}\PY{p}{:}\PY{p}{[}\PY{l+m+mf}{0.125}\PY{p}{,} \PY{l+m+mf}{0.5}\PY{p}{,} \PY{l+m+mi}{1}\PY{p}{,} \PY{l+m+mi}{2}\PY{p}{,} \PY{l+m+mi}{8}\PY{p}{,} \PY{l+m+mi}{16}\PY{p}{]}\PY{p}{\PYZcb{}}
         \PY{n}{lr\PYZus{}svc} \PY{o}{=} \PY{n}{LinearSVC}\PY{p}{(}\PY{n}{tol}\PY{o}{=}\PY{l+m+mf}{0.00005}\PY{p}{)}
         \PY{n}{lr\PYZus{}svc\PYZus{}grid} \PY{o}{=} \PY{n}{GridSearchCV}\PY{p}{(}\PY{n}{lr\PYZus{}svc}\PY{p}{,} \PY{n}{param\PYZus{}grid}\PY{o}{=}\PY{n}{parameters}\PY{p}{,} \PY{n}{n\PYZus{}jobs}\PY{o}{=}\PY{l+m+mi}{8}\PY{p}{,} \PY{n}{verbose}\PY{o}{=}\PY{l+m+mi}{1}\PY{p}{)}
         \PY{n}{lr\PYZus{}svc\PYZus{}grid\PYZus{}results} \PY{o}{=} \PY{n}{perform\PYZus{}model}\PY{p}{(}\PY{n}{lr\PYZus{}svc\PYZus{}grid}\PY{p}{,} \PY{n}{X\PYZus{}train}\PY{p}{,} \PY{n}{y\PYZus{}train}\PY{p}{,} \PY{n}{X\PYZus{}test}\PY{p}{,} \PY{n}{y\PYZus{}test}\PY{p}{,} \PY{n}{class\PYZus{}labels}\PY{o}{=}\PY{n}{labels}\PY{p}{)}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
training the model..
Fitting 3 folds for each of 6 candidates, totalling 18 fits

    \end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]
[Parallel(n\_jobs=8)]: Done  18 out of  18 | elapsed:    9.5s finished

    \end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]
Done 
 

training\_time(HH:MM:SS.ms) - 0:00:13.065672


Predicting test data
Done 
 

testing time(HH:MM:SS:ms) - 0:00:00.003324


---------------------
|      Accuracy      |
---------------------

    0.9650492025788938


--------------------
| Confusion Matrix |
--------------------

 [[537   0   0   0   0   0]
 [  2 420  65   0   0   4]
 [  0   7 524   1   0   0]
 [  0   0   0 496   0   0]
 [  0   0   0   2 413   5]
 [  0   0   0  17   0 454]]

    \end{Verbatim}

    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{output_80_3.png}
    \end{center}
    { \hspace*{\fill} \\}
    
    \begin{Verbatim}[commandchars=\\\{\}]
-------------------------
| Classifiction Report |
-------------------------
                    precision    recall  f1-score   support

            LAYING       1.00      1.00      1.00       537
           SITTING       0.98      0.86      0.92       491
          STANDING       0.89      0.98      0.93       532
           WALKING       0.96      1.00      0.98       496
WALKING\_DOWNSTAIRS       1.00      0.98      0.99       420
  WALKING\_UPSTAIRS       0.98      0.96      0.97       471

       avg / total       0.97      0.97      0.96      2947


    \end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}17}]:} \PY{n}{print\PYZus{}grid\PYZus{}search\PYZus{}attributes}\PY{p}{(}\PY{n}{lr\PYZus{}svc\PYZus{}grid\PYZus{}results}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{model}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{)}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
--------------------------
|      Best Estimator     |
--------------------------

	LinearSVC(C=1, class\_weight=None, dual=True, fit\_intercept=True,
     intercept\_scaling=1, loss='squared\_hinge', max\_iter=1000,
     multi\_class='ovr', penalty='l2', random\_state=None, tol=5e-05,
     verbose=0)

--------------------------
|     Best parameters     |
--------------------------
	Parameters of best estimator : 

	\{'C': 1\}

---------------------------------
|   No of CrossValidation sets   |
--------------------------------

	Total numbre of cross validation sets: 3

--------------------------
|        Best Score       |
--------------------------

	Average Cross Validate scores of best estimator : 

	0.9455930359085963


    \end{Verbatim}

    \section{3. Kernel SVM with
GridSearch}\label{kernel-svm-with-gridsearch}

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}18}]:} \PY{k+kn}{from} \PY{n+nn}{sklearn}\PY{n+nn}{.}\PY{n+nn}{svm} \PY{k}{import} \PY{n}{SVC}
         \PY{n}{parameters} \PY{o}{=} \PY{p}{\PYZob{}}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{C}\PY{l+s+s1}{\PYZsq{}}\PY{p}{:}\PY{p}{[}\PY{l+m+mi}{2}\PY{p}{,}\PY{l+m+mi}{8}\PY{p}{,}\PY{l+m+mi}{16}\PY{p}{]}\PY{p}{,}\PYZbs{}
                       \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{gamma}\PY{l+s+s1}{\PYZsq{}}\PY{p}{:} \PY{p}{[} \PY{l+m+mf}{0.0078125}\PY{p}{,} \PY{l+m+mf}{0.125}\PY{p}{,} \PY{l+m+mi}{2}\PY{p}{]}\PY{p}{\PYZcb{}}
         \PY{n}{rbf\PYZus{}svm} \PY{o}{=} \PY{n}{SVC}\PY{p}{(}\PY{n}{kernel}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{rbf}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
         \PY{n}{rbf\PYZus{}svm\PYZus{}grid} \PY{o}{=} \PY{n}{GridSearchCV}\PY{p}{(}\PY{n}{rbf\PYZus{}svm}\PY{p}{,}\PY{n}{param\PYZus{}grid}\PY{o}{=}\PY{n}{parameters}\PY{p}{,}\PY{n}{n\PYZus{}jobs}\PY{o}{=}\PY{l+m+mi}{8}\PY{p}{)}
         \PY{n}{rbf\PYZus{}svm\PYZus{}grid\PYZus{}results} \PY{o}{=} \PY{n}{perform\PYZus{}model}\PY{p}{(}\PY{n}{rbf\PYZus{}svm\PYZus{}grid}\PY{p}{,} \PY{n}{X\PYZus{}train}\PY{p}{,} \PY{n}{y\PYZus{}train}\PY{p}{,} \PY{n}{X\PYZus{}test}\PY{p}{,} \PY{n}{y\PYZus{}test}\PY{p}{,} \PY{n}{class\PYZus{}labels}\PY{o}{=}\PY{n}{labels}\PY{p}{)}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
training the model..
Done 
 

training\_time(HH:MM:SS.ms) - 0:02:21.703537


Predicting test data
Done 
 

testing time(HH:MM:SS:ms) - 0:00:02.286671


---------------------
|      Accuracy      |
---------------------

    0.9626739056667798


--------------------
| Confusion Matrix |
--------------------

 [[537   0   0   0   0   0]
 [  0 441  48   0   0   2]
 [  0  12 520   0   0   0]
 [  0   0   0 489   2   5]
 [  0   0   0   4 397  19]
 [  0   0   0  17   1 453]]

    \end{Verbatim}

    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{output_83_1.png}
    \end{center}
    { \hspace*{\fill} \\}
    
    \begin{Verbatim}[commandchars=\\\{\}]
-------------------------
| Classifiction Report |
-------------------------
                    precision    recall  f1-score   support

            LAYING       1.00      1.00      1.00       537
           SITTING       0.97      0.90      0.93       491
          STANDING       0.92      0.98      0.95       532
           WALKING       0.96      0.99      0.97       496
WALKING\_DOWNSTAIRS       0.99      0.95      0.97       420
  WALKING\_UPSTAIRS       0.95      0.96      0.95       471

       avg / total       0.96      0.96      0.96      2947


    \end{Verbatim}

    \section{4. Decision Trees with
GridSearchCV}\label{decision-trees-with-gridsearchcv}

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}19}]:} \PY{k+kn}{from} \PY{n+nn}{sklearn}\PY{n+nn}{.}\PY{n+nn}{tree} \PY{k}{import} \PY{n}{DecisionTreeClassifier}
         \PY{n}{parameters} \PY{o}{=} \PY{p}{\PYZob{}}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{max\PYZus{}depth}\PY{l+s+s1}{\PYZsq{}}\PY{p}{:}\PY{n}{np}\PY{o}{.}\PY{n}{arange}\PY{p}{(}\PY{l+m+mi}{3}\PY{p}{,}\PY{l+m+mi}{10}\PY{p}{,}\PY{l+m+mi}{2}\PY{p}{)}\PY{p}{\PYZcb{}}
         \PY{n}{dt} \PY{o}{=} \PY{n}{DecisionTreeClassifier}\PY{p}{(}\PY{p}{)}
         \PY{n}{dt\PYZus{}grid} \PY{o}{=} \PY{n}{GridSearchCV}\PY{p}{(}\PY{n}{dt}\PY{p}{,}\PY{n}{param\PYZus{}grid}\PY{o}{=}\PY{n}{parameters}\PY{p}{,} \PY{n}{n\PYZus{}jobs}\PY{o}{=}\PY{l+m+mi}{8}\PY{p}{)}
         \PY{n}{dt\PYZus{}grid\PYZus{}results} \PY{o}{=} \PY{n}{perform\PYZus{}model}\PY{p}{(}\PY{n}{dt\PYZus{}grid}\PY{p}{,} \PY{n}{X\PYZus{}train}\PY{p}{,} \PY{n}{y\PYZus{}train}\PY{p}{,} \PY{n}{X\PYZus{}test}\PY{p}{,} \PY{n}{y\PYZus{}test}\PY{p}{,} \PY{n}{class\PYZus{}labels}\PY{o}{=}\PY{n}{labels}\PY{p}{)}
         \PY{n}{print\PYZus{}grid\PYZus{}search\PYZus{}attributes}\PY{p}{(}\PY{n}{dt\PYZus{}grid\PYZus{}results}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{model}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{)}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
training the model..
Done 
 

training\_time(HH:MM:SS.ms) - 0:00:05.120427


Predicting test data
Done 
 

testing time(HH:MM:SS:ms) - 0:00:00.002483


---------------------
|      Accuracy      |
---------------------

    0.8639294197488971


--------------------
| Confusion Matrix |
--------------------

 [[537   0   0   0   0   0]
 [  0 386 105   0   0   0]
 [  0  93 439   0   0   0]
 [  0   0   0 472  16   8]
 [  0   0   0  16 343  61]
 [  0   0   0  78  24 369]]

    \end{Verbatim}

    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{output_85_1.png}
    \end{center}
    { \hspace*{\fill} \\}
    
    \begin{Verbatim}[commandchars=\\\{\}]
-------------------------
| Classifiction Report |
-------------------------
                    precision    recall  f1-score   support

            LAYING       1.00      1.00      1.00       537
           SITTING       0.81      0.79      0.80       491
          STANDING       0.81      0.83      0.82       532
           WALKING       0.83      0.95      0.89       496
WALKING\_DOWNSTAIRS       0.90      0.82      0.85       420
  WALKING\_UPSTAIRS       0.84      0.78      0.81       471

       avg / total       0.86      0.86      0.86      2947

--------------------------
|      Best Estimator     |
--------------------------

	DecisionTreeClassifier(class\_weight=None, criterion='gini', max\_depth=7,
            max\_features=None, max\_leaf\_nodes=None,
            min\_impurity\_decrease=0.0, min\_impurity\_split=None,
            min\_samples\_leaf=1, min\_samples\_split=2,
            min\_weight\_fraction\_leaf=0.0, presort=False, random\_state=None,
            splitter='best')

--------------------------
|     Best parameters     |
--------------------------
	Parameters of best estimator : 

	\{'max\_depth': 7\}

---------------------------------
|   No of CrossValidation sets   |
--------------------------------

	Total numbre of cross validation sets: 3

--------------------------
|        Best Score       |
--------------------------

	Average Cross Validate scores of best estimator : 

	0.8382752992383025


    \end{Verbatim}

    \section{5. Random Forest Classifier with
GridSearch}\label{random-forest-classifier-with-gridsearch}

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}20}]:} \PY{k+kn}{from} \PY{n+nn}{sklearn}\PY{n+nn}{.}\PY{n+nn}{ensemble} \PY{k}{import} \PY{n}{RandomForestClassifier}
         \PY{n}{params} \PY{o}{=} \PY{p}{\PYZob{}}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{n\PYZus{}estimators}\PY{l+s+s1}{\PYZsq{}}\PY{p}{:} \PY{n}{np}\PY{o}{.}\PY{n}{arange}\PY{p}{(}\PY{l+m+mi}{10}\PY{p}{,}\PY{l+m+mi}{201}\PY{p}{,}\PY{l+m+mi}{20}\PY{p}{)}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{max\PYZus{}depth}\PY{l+s+s1}{\PYZsq{}}\PY{p}{:}\PY{n}{np}\PY{o}{.}\PY{n}{arange}\PY{p}{(}\PY{l+m+mi}{3}\PY{p}{,}\PY{l+m+mi}{15}\PY{p}{,}\PY{l+m+mi}{2}\PY{p}{)}\PY{p}{\PYZcb{}}
         \PY{n}{rfc} \PY{o}{=} \PY{n}{RandomForestClassifier}\PY{p}{(}\PY{p}{)}
         \PY{n}{rfc\PYZus{}grid} \PY{o}{=} \PY{n}{GridSearchCV}\PY{p}{(}\PY{n}{rfc}\PY{p}{,} \PY{n}{param\PYZus{}grid}\PY{o}{=}\PY{n}{params}\PY{p}{,} \PY{n}{n\PYZus{}jobs}\PY{o}{=}\PY{l+m+mi}{8}\PY{p}{)}
         \PY{n}{rfc\PYZus{}grid\PYZus{}results} \PY{o}{=} \PY{n}{perform\PYZus{}model}\PY{p}{(}\PY{n}{rfc\PYZus{}grid}\PY{p}{,} \PY{n}{X\PYZus{}train}\PY{p}{,} \PY{n}{y\PYZus{}train}\PY{p}{,} \PY{n}{X\PYZus{}test}\PY{p}{,} \PY{n}{y\PYZus{}test}\PY{p}{,} \PY{n}{class\PYZus{}labels}\PY{o}{=}\PY{n}{labels}\PY{p}{)}
         \PY{n}{print\PYZus{}grid\PYZus{}search\PYZus{}attributes}\PY{p}{(}\PY{n}{rfc\PYZus{}grid\PYZus{}results}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{model}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{)}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
training the model..
Done 
 

training\_time(HH:MM:SS.ms) - 0:01:59.069438


Predicting test data
Done 
 

testing time(HH:MM:SS:ms) - 0:00:00.033301


---------------------
|      Accuracy      |
---------------------

    0.9107567017305734


--------------------
| Confusion Matrix |
--------------------

 [[537   0   0   0   0   0]
 [  0 422  69   0   0   0]
 [  0  49 483   0   0   0]
 [  0   0   0 482  12   2]
 [  0   0   0  40 335  45]
 [  0   0   0  40   6 425]]

    \end{Verbatim}

    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{output_87_1.png}
    \end{center}
    { \hspace*{\fill} \\}
    
    \begin{Verbatim}[commandchars=\\\{\}]
-------------------------
| Classifiction Report |
-------------------------
                    precision    recall  f1-score   support

            LAYING       1.00      1.00      1.00       537
           SITTING       0.90      0.86      0.88       491
          STANDING       0.88      0.91      0.89       532
           WALKING       0.86      0.97      0.91       496
WALKING\_DOWNSTAIRS       0.95      0.80      0.87       420
  WALKING\_UPSTAIRS       0.90      0.90      0.90       471

       avg / total       0.91      0.91      0.91      2947

--------------------------
|      Best Estimator     |
--------------------------

	RandomForestClassifier(bootstrap=True, class\_weight=None, criterion='gini',
            max\_depth=7, max\_features='auto', max\_leaf\_nodes=None,
            min\_impurity\_decrease=0.0, min\_impurity\_split=None,
            min\_samples\_leaf=1, min\_samples\_split=2,
            min\_weight\_fraction\_leaf=0.0, n\_estimators=130, n\_jobs=1,
            oob\_score=False, random\_state=None, verbose=0,
            warm\_start=False)

--------------------------
|     Best parameters     |
--------------------------
	Parameters of best estimator : 

	\{'max\_depth': 7, 'n\_estimators': 130\}

---------------------------------
|   No of CrossValidation sets   |
--------------------------------

	Total numbre of cross validation sets: 3

--------------------------
|        Best Score       |
--------------------------

	Average Cross Validate scores of best estimator : 

	0.9124047878128401


    \end{Verbatim}

    \section{6. Gradient Boosted Decision Trees With
GridSearch}\label{gradient-boosted-decision-trees-with-gridsearch}

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}21}]:} \PY{k+kn}{from} \PY{n+nn}{sklearn}\PY{n+nn}{.}\PY{n+nn}{ensemble} \PY{k}{import} \PY{n}{GradientBoostingClassifier}
         \PY{n}{param\PYZus{}grid} \PY{o}{=} \PY{p}{\PYZob{}}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{max\PYZus{}depth}\PY{l+s+s1}{\PYZsq{}}\PY{p}{:} \PY{n}{np}\PY{o}{.}\PY{n}{arange}\PY{p}{(}\PY{l+m+mi}{5}\PY{p}{,}\PY{l+m+mi}{8}\PY{p}{,}\PY{l+m+mi}{1}\PY{p}{)}\PY{p}{,} \PYZbs{}
                      \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{n\PYZus{}estimators}\PY{l+s+s1}{\PYZsq{}}\PY{p}{:}\PY{n}{np}\PY{o}{.}\PY{n}{arange}\PY{p}{(}\PY{l+m+mi}{130}\PY{p}{,}\PY{l+m+mi}{170}\PY{p}{,}\PY{l+m+mi}{10}\PY{p}{)}\PY{p}{\PYZcb{}}
         \PY{n}{gbdt} \PY{o}{=} \PY{n}{GradientBoostingClassifier}\PY{p}{(}\PY{p}{)}
         \PY{n}{gbdt\PYZus{}grid} \PY{o}{=} \PY{n}{GridSearchCV}\PY{p}{(}\PY{n}{gbdt}\PY{p}{,} \PY{n}{param\PYZus{}grid}\PY{o}{=}\PY{n}{param\PYZus{}grid}\PY{p}{,} \PY{n}{n\PYZus{}jobs}\PY{o}{=}\PY{l+m+mi}{8}\PY{p}{)}
         \PY{n}{gbdt\PYZus{}grid\PYZus{}results} \PY{o}{=} \PY{n}{perform\PYZus{}model}\PY{p}{(}\PY{n}{gbdt\PYZus{}grid}\PY{p}{,} \PY{n}{X\PYZus{}train}\PY{p}{,} \PY{n}{y\PYZus{}train}\PY{p}{,} \PY{n}{X\PYZus{}test}\PY{p}{,} \PY{n}{y\PYZus{}test}\PY{p}{,} \PY{n}{class\PYZus{}labels}\PY{o}{=}\PY{n}{labels}\PY{p}{)}
         \PY{n}{print\PYZus{}grid\PYZus{}search\PYZus{}attributes}\PY{p}{(}\PY{n}{gbdt\PYZus{}grid\PYZus{}results}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{model}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{)}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
training the model..
Done 
 

training\_time(HH:MM:SS.ms) - 0:17:12.707284


Predicting test data
Done 
 

testing time(HH:MM:SS:ms) - 0:00:00.039210


---------------------
|      Accuracy      |
---------------------

    0.9226331862911435


--------------------
| Confusion Matrix |
--------------------

 [[537   0   0   0   0   0]
 [  0 399  90   0   0   2]
 [  0  38 494   0   0   0]
 [  0   0   0 483   7   6]
 [  0   0   0  10 374  36]
 [  0   1   0  32   6 432]]

    \end{Verbatim}

    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{output_89_1.png}
    \end{center}
    { \hspace*{\fill} \\}
    
    \begin{Verbatim}[commandchars=\\\{\}]
-------------------------
| Classifiction Report |
-------------------------
                    precision    recall  f1-score   support

            LAYING       1.00      1.00      1.00       537
           SITTING       0.91      0.81      0.86       491
          STANDING       0.85      0.93      0.89       532
           WALKING       0.92      0.97      0.95       496
WALKING\_DOWNSTAIRS       0.97      0.89      0.93       420
  WALKING\_UPSTAIRS       0.91      0.92      0.91       471

       avg / total       0.92      0.92      0.92      2947

--------------------------
|      Best Estimator     |
--------------------------

	GradientBoostingClassifier(criterion='friedman\_mse', init=None,
              learning\_rate=0.1, loss='deviance', max\_depth=5,
              max\_features=None, max\_leaf\_nodes=None,
              min\_impurity\_decrease=0.0, min\_impurity\_split=None,
              min\_samples\_leaf=1, min\_samples\_split=2,
              min\_weight\_fraction\_leaf=0.0, n\_estimators=150,
              presort='auto', random\_state=None, subsample=1.0, verbose=0,
              warm\_start=False)

--------------------------
|     Best parameters     |
--------------------------
	Parameters of best estimator : 

	\{'max\_depth': 5, 'n\_estimators': 150\}

---------------------------------
|   No of CrossValidation sets   |
--------------------------------

	Total numbre of cross validation sets: 3

--------------------------
|        Best Score       |
--------------------------

	Average Cross Validate scores of best estimator : 

	0.9036996735582155


    \end{Verbatim}

    \section{7. Comparing all models}\label{comparing-all-models}

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}22}]:} \PY{n+nb}{print}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+se}{\PYZbs{}n}\PY{l+s+s1}{                     Accuracy     Error}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
         \PY{n+nb}{print}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{                     \PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}   \PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
         \PY{n+nb}{print}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Logistic Regression : }\PY{l+s+si}{\PYZob{}:.04\PYZcb{}}\PY{l+s+s1}{\PYZpc{}}\PY{l+s+s1}{       }\PY{l+s+si}{\PYZob{}:.04\PYZcb{}}\PY{l+s+s1}{\PYZpc{}}\PY{l+s+s1}{\PYZsq{}}\PY{o}{.}\PY{n}{format}\PY{p}{(}\PY{n}{log\PYZus{}reg\PYZus{}grid\PYZus{}results}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{accuracy}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]} \PY{o}{*} \PY{l+m+mi}{100}\PY{p}{,}\PYZbs{}
                                                           \PY{l+m+mi}{100}\PY{o}{\PYZhy{}}\PY{p}{(}\PY{n}{log\PYZus{}reg\PYZus{}grid\PYZus{}results}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{accuracy}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]} \PY{o}{*} \PY{l+m+mi}{100}\PY{p}{)}\PY{p}{)}\PY{p}{)}
         
         \PY{n+nb}{print}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Linear SVC          : }\PY{l+s+si}{\PYZob{}:.04\PYZcb{}}\PY{l+s+s1}{\PYZpc{}}\PY{l+s+s1}{       }\PY{l+s+si}{\PYZob{}:.04\PYZcb{}}\PY{l+s+s1}{\PYZpc{}}\PY{l+s+s1}{ }\PY{l+s+s1}{\PYZsq{}}\PY{o}{.}\PY{n}{format}\PY{p}{(}\PY{n}{lr\PYZus{}svc\PYZus{}grid\PYZus{}results}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{accuracy}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]} \PY{o}{*} \PY{l+m+mi}{100}\PY{p}{,}\PYZbs{}
                                                                 \PY{l+m+mi}{100}\PY{o}{\PYZhy{}}\PY{p}{(}\PY{n}{lr\PYZus{}svc\PYZus{}grid\PYZus{}results}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{accuracy}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]} \PY{o}{*} \PY{l+m+mi}{100}\PY{p}{)}\PY{p}{)}\PY{p}{)}
         
         \PY{n+nb}{print}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{rbf SVM classifier  : }\PY{l+s+si}{\PYZob{}:.04\PYZcb{}}\PY{l+s+s1}{\PYZpc{}}\PY{l+s+s1}{      }\PY{l+s+si}{\PYZob{}:.04\PYZcb{}}\PY{l+s+s1}{\PYZpc{}}\PY{l+s+s1}{ }\PY{l+s+s1}{\PYZsq{}}\PY{o}{.}\PY{n}{format}\PY{p}{(}\PY{n}{rbf\PYZus{}svm\PYZus{}grid\PYZus{}results}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{accuracy}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]} \PY{o}{*} \PY{l+m+mi}{100}\PY{p}{,}\PYZbs{}
                                                                   \PY{l+m+mi}{100}\PY{o}{\PYZhy{}}\PY{p}{(}\PY{n}{rbf\PYZus{}svm\PYZus{}grid\PYZus{}results}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{accuracy}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]} \PY{o}{*} \PY{l+m+mi}{100}\PY{p}{)}\PY{p}{)}\PY{p}{)}
         
         \PY{n+nb}{print}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{DecisionTree        : }\PY{l+s+si}{\PYZob{}:.04\PYZcb{}}\PY{l+s+s1}{\PYZpc{}}\PY{l+s+s1}{      }\PY{l+s+si}{\PYZob{}:.04\PYZcb{}}\PY{l+s+s1}{\PYZpc{}}\PY{l+s+s1}{ }\PY{l+s+s1}{\PYZsq{}}\PY{o}{.}\PY{n}{format}\PY{p}{(}\PY{n}{dt\PYZus{}grid\PYZus{}results}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{accuracy}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]} \PY{o}{*} \PY{l+m+mi}{100}\PY{p}{,}\PYZbs{}
                                                                 \PY{l+m+mi}{100}\PY{o}{\PYZhy{}}\PY{p}{(}\PY{n}{dt\PYZus{}grid\PYZus{}results}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{accuracy}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]} \PY{o}{*} \PY{l+m+mi}{100}\PY{p}{)}\PY{p}{)}\PY{p}{)}
         
         \PY{n+nb}{print}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Random Forest       : }\PY{l+s+si}{\PYZob{}:.04\PYZcb{}}\PY{l+s+s1}{\PYZpc{}}\PY{l+s+s1}{      }\PY{l+s+si}{\PYZob{}:.04\PYZcb{}}\PY{l+s+s1}{\PYZpc{}}\PY{l+s+s1}{ }\PY{l+s+s1}{\PYZsq{}}\PY{o}{.}\PY{n}{format}\PY{p}{(}\PY{n}{rfc\PYZus{}grid\PYZus{}results}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{accuracy}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]} \PY{o}{*} \PY{l+m+mi}{100}\PY{p}{,}\PYZbs{}
                                                                    \PY{l+m+mi}{100}\PY{o}{\PYZhy{}}\PY{p}{(}\PY{n}{rfc\PYZus{}grid\PYZus{}results}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{accuracy}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]} \PY{o}{*} \PY{l+m+mi}{100}\PY{p}{)}\PY{p}{)}\PY{p}{)}
         \PY{n+nb}{print}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{GradientBoosting DT : }\PY{l+s+si}{\PYZob{}:.04\PYZcb{}}\PY{l+s+s1}{\PYZpc{}}\PY{l+s+s1}{      }\PY{l+s+si}{\PYZob{}:.04\PYZcb{}}\PY{l+s+s1}{\PYZpc{}}\PY{l+s+s1}{ }\PY{l+s+s1}{\PYZsq{}}\PY{o}{.}\PY{n}{format}\PY{p}{(}\PY{n}{rfc\PYZus{}grid\PYZus{}results}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{accuracy}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]} \PY{o}{*} \PY{l+m+mi}{100}\PY{p}{,}\PYZbs{}
                                                                 \PY{l+m+mi}{100}\PY{o}{\PYZhy{}}\PY{p}{(}\PY{n}{rfc\PYZus{}grid\PYZus{}results}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{accuracy}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]} \PY{o}{*} \PY{l+m+mi}{100}\PY{p}{)}\PY{p}{)}\PY{p}{)}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]

                     Accuracy     Error
                     ----------   --------
Logistic Regression : 96.3\%       3.699\%
Linear SVC          : 96.5\%       3.495\% 
rbf SVM classifier  : 96.27\%      3.733\% 
DecisionTree        : 86.39\%      13.61\% 
Random Forest       : 91.08\%      8.924\% 
GradientBoosting DT : 91.08\%      8.924\% 

    \end{Verbatim}

    \subsection{Using raw time series data and deep learning
methods:}\label{using-raw-time-series-data-and-deep-learning-methods}

Approch 1 - Using LSTM\\
Approch 2 - Using CNN - CNN are useful to get best features and
realtions between sequnce data using convolution.\\
Approch 3 - Using some cascading techniques.

    \subsection{LSTM}\label{lstm}

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}6}]:} \PY{c+c1}{\PYZsh{} Importing libraries}
        \PY{k+kn}{import} \PY{n+nn}{numpy} \PY{k}{as} \PY{n+nn}{np}
        \PY{k+kn}{import} \PY{n+nn}{pandas} \PY{k}{as} \PY{n+nn}{pd}
        \PY{k+kn}{from} \PY{n+nn}{numpy} \PY{k}{import} \PY{n}{mean}
        \PY{k+kn}{from} \PY{n+nn}{numpy} \PY{k}{import} \PY{n}{std}
        \PY{k+kn}{from} \PY{n+nn}{numpy} \PY{k}{import} \PY{n}{dstack}
        \PY{k+kn}{from} \PY{n+nn}{pandas} \PY{k}{import} \PY{n}{read\PYZus{}csv}
        \PY{k+kn}{from} \PY{n+nn}{matplotlib} \PY{k}{import} \PY{n}{pyplot}
        \PY{k+kn}{from} \PY{n+nn}{sklearn}\PY{n+nn}{.}\PY{n+nn}{preprocessing} \PY{k}{import} \PY{n}{StandardScaler}
        \PY{k+kn}{from} \PY{n+nn}{keras}\PY{n+nn}{.}\PY{n+nn}{models} \PY{k}{import} \PY{n}{Sequential}
        \PY{k+kn}{from} \PY{n+nn}{keras}\PY{n+nn}{.}\PY{n+nn}{layers} \PY{k}{import} \PY{n}{Dense}
        \PY{k+kn}{from} \PY{n+nn}{keras}\PY{n+nn}{.}\PY{n+nn}{layers} \PY{k}{import} \PY{n}{Flatten}
        \PY{k+kn}{from} \PY{n+nn}{keras}\PY{n+nn}{.}\PY{n+nn}{layers} \PY{k}{import} \PY{n}{Dropout}
        \PY{k+kn}{from} \PY{n+nn}{keras}\PY{n+nn}{.}\PY{n+nn}{layers}\PY{n+nn}{.}\PY{n+nn}{convolutional} \PY{k}{import} \PY{n}{Conv1D}
        \PY{k+kn}{from} \PY{n+nn}{keras}\PY{n+nn}{.}\PY{n+nn}{layers}\PY{n+nn}{.}\PY{n+nn}{convolutional} \PY{k}{import} \PY{n}{MaxPooling1D}
        \PY{k+kn}{from} \PY{n+nn}{keras}\PY{n+nn}{.}\PY{n+nn}{utils} \PY{k}{import} \PY{n}{to\PYZus{}categorical}
        \PY{k+kn}{from} \PY{n+nn}{keras}\PY{n+nn}{.}\PY{n+nn}{models} \PY{k}{import} \PY{n}{Sequential}
        \PY{k+kn}{from} \PY{n+nn}{keras}\PY{n+nn}{.}\PY{n+nn}{layers} \PY{k}{import} \PY{n}{LSTM}
        \PY{k+kn}{from} \PY{n+nn}{keras}\PY{n+nn}{.}\PY{n+nn}{layers}\PY{n+nn}{.}\PY{n+nn}{core} \PY{k}{import} \PY{n}{Dense}\PY{p}{,} \PY{n}{Dropout}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
Using TensorFlow backend.

    \end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}9}]:} \PY{c+c1}{\PYZsh{} Activities are the class labels}
        \PY{c+c1}{\PYZsh{} It is a 6 class classification}
        \PY{n}{ACTIVITIES} \PY{o}{=} \PY{p}{\PYZob{}}
            \PY{l+m+mi}{0}\PY{p}{:} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{WALKING}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}
            \PY{l+m+mi}{1}\PY{p}{:} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{WALKING\PYZus{}UPSTAIRS}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}
            \PY{l+m+mi}{2}\PY{p}{:} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{WALKING\PYZus{}DOWNSTAIRS}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}
            \PY{l+m+mi}{3}\PY{p}{:} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{SITTING}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}
            \PY{l+m+mi}{4}\PY{p}{:} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{STANDING}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}
            \PY{l+m+mi}{5}\PY{p}{:} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{LAYING}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}
        \PY{p}{\PYZcb{}}
        
        \PY{c+c1}{\PYZsh{} Utility function to print the confusion matrix}
        \PY{k}{def} \PY{n+nf}{confusion\PYZus{}matrix}\PY{p}{(}\PY{n}{Y\PYZus{}true}\PY{p}{,} \PY{n}{Y\PYZus{}pred}\PY{p}{)}\PY{p}{:}
            \PY{n}{Y\PYZus{}true} \PY{o}{=} \PY{n}{pd}\PY{o}{.}\PY{n}{Series}\PY{p}{(}\PY{p}{[}\PY{n}{ACTIVITIES}\PY{p}{[}\PY{n}{y}\PY{p}{]} \PY{k}{for} \PY{n}{y} \PY{o+ow}{in} \PY{n}{np}\PY{o}{.}\PY{n}{argmax}\PY{p}{(}\PY{n}{Y\PYZus{}true}\PY{p}{,} \PY{n}{axis}\PY{o}{=}\PY{l+m+mi}{1}\PY{p}{)}\PY{p}{]}\PY{p}{)}
            \PY{n}{Y\PYZus{}pred} \PY{o}{=} \PY{n}{pd}\PY{o}{.}\PY{n}{Series}\PY{p}{(}\PY{p}{[}\PY{n}{ACTIVITIES}\PY{p}{[}\PY{n}{y}\PY{p}{]} \PY{k}{for} \PY{n}{y} \PY{o+ow}{in} \PY{n}{np}\PY{o}{.}\PY{n}{argmax}\PY{p}{(}\PY{n}{Y\PYZus{}pred}\PY{p}{,} \PY{n}{axis}\PY{o}{=}\PY{l+m+mi}{1}\PY{p}{)}\PY{p}{]}\PY{p}{)}
        
            \PY{k}{return} \PY{n}{pd}\PY{o}{.}\PY{n}{crosstab}\PY{p}{(}\PY{n}{Y\PYZus{}true}\PY{p}{,} \PY{n}{Y\PYZus{}pred}\PY{p}{,} \PY{n}{rownames}\PY{o}{=}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{True}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{,} \PY{n}{colnames}\PY{o}{=}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Pred}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{)}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}10}]:} \PY{c+c1}{\PYZsh{} Data directory}
         \PY{n}{DATADIR} \PY{o}{=} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{UCI\PYZus{}HAR\PYZus{}Dataset}\PY{l+s+s1}{\PYZsq{}}
         \PY{c+c1}{\PYZsh{} Raw data signals}
         \PY{c+c1}{\PYZsh{} Signals are from Accelerometer and Gyroscope}
         \PY{c+c1}{\PYZsh{} The signals are in x,y,z directions}
         \PY{c+c1}{\PYZsh{} Sensor signals are filtered to have only body acceleration}
         \PY{c+c1}{\PYZsh{} excluding the acceleration due to gravity}
         \PY{c+c1}{\PYZsh{} Triaxial acceleration from the accelerometer is total acceleration}
         \PY{n}{SIGNALS} \PY{o}{=} \PY{p}{[}
             \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{body\PYZus{}acc\PYZus{}x}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,}
             \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{body\PYZus{}acc\PYZus{}y}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,}
             \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{body\PYZus{}acc\PYZus{}z}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,}
             \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{body\PYZus{}gyro\PYZus{}x}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,}
             \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{body\PYZus{}gyro\PYZus{}y}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,}
             \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{body\PYZus{}gyro\PYZus{}z}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,}
             \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{total\PYZus{}acc\PYZus{}x}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,}
             \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{total\PYZus{}acc\PYZus{}y}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,}
             \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{total\PYZus{}acc\PYZus{}z}\PY{l+s+s2}{\PYZdq{}}
         \PY{p}{]}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}11}]:} \PY{c+c1}{\PYZsh{} Utility function to read the data from csv file}
         \PY{k}{def} \PY{n+nf}{\PYZus{}read\PYZus{}csv}\PY{p}{(}\PY{n}{filename}\PY{p}{)}\PY{p}{:}
             \PY{k}{return} \PY{n}{pd}\PY{o}{.}\PY{n}{read\PYZus{}csv}\PY{p}{(}\PY{n}{filename}\PY{p}{,} \PY{n}{delim\PYZus{}whitespace}\PY{o}{=}\PY{k+kc}{True}\PY{p}{,} \PY{n}{header}\PY{o}{=}\PY{k+kc}{None}\PY{p}{)}
         
         \PY{c+c1}{\PYZsh{} Utility function to load the load}
         \PY{k}{def} \PY{n+nf}{load\PYZus{}signals}\PY{p}{(}\PY{n}{subset}\PY{p}{)}\PY{p}{:}
             \PY{n}{signals\PYZus{}data} \PY{o}{=} \PY{p}{[}\PY{p}{]}
         
             \PY{k}{for} \PY{n}{signal} \PY{o+ow}{in} \PY{n}{SIGNALS}\PY{p}{:}
                 \PY{n}{filename} \PY{o}{=} \PY{n}{f}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{UCI\PYZus{}HAR\PYZus{}Dataset/}\PY{l+s+si}{\PYZob{}subset\PYZcb{}}\PY{l+s+s1}{/Inertial Signals/}\PY{l+s+si}{\PYZob{}signal\PYZcb{}}\PY{l+s+s1}{\PYZus{}}\PY{l+s+si}{\PYZob{}subset\PYZcb{}}\PY{l+s+s1}{.txt}\PY{l+s+s1}{\PYZsq{}}
                 \PY{n}{signals\PYZus{}data}\PY{o}{.}\PY{n}{append}\PY{p}{(}
                     \PY{n}{\PYZus{}read\PYZus{}csv}\PY{p}{(}\PY{n}{filename}\PY{p}{)}\PY{o}{.}\PY{n}{as\PYZus{}matrix}\PY{p}{(}\PY{p}{)}
                 \PY{p}{)} 
         
             \PY{c+c1}{\PYZsh{} Transpose is used to change the dimensionality of the output,}
             \PY{c+c1}{\PYZsh{} aggregating the signals by combination of sample/timestep.}
             \PY{c+c1}{\PYZsh{} Resultant shape is (7352 train/2947 test samples, 128 timesteps, 9 signals)}
             \PY{k}{return} \PY{n}{np}\PY{o}{.}\PY{n}{transpose}\PY{p}{(}\PY{n}{signals\PYZus{}data}\PY{p}{,} \PY{p}{(}\PY{l+m+mi}{1}\PY{p}{,} \PY{l+m+mi}{2}\PY{p}{,} \PY{l+m+mi}{0}\PY{p}{)}\PY{p}{)}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}12}]:} \PY{k}{def} \PY{n+nf}{load\PYZus{}y}\PY{p}{(}\PY{n}{subset}\PY{p}{)}\PY{p}{:}
             \PY{l+s+sd}{\PYZdq{}\PYZdq{}\PYZdq{}}
         \PY{l+s+sd}{    The objective that we are trying to predict is a integer, from 1 to 6,}
         \PY{l+s+sd}{    that represents a human activity. We return a binary representation of }
         \PY{l+s+sd}{    every sample objective as a 6 bits vector using One Hot Encoding}
         \PY{l+s+sd}{    (https://pandas.pydata.org/pandas\PYZhy{}docs/stable/generated/pandas.get\PYZus{}dummies.html)}
         \PY{l+s+sd}{    \PYZdq{}\PYZdq{}\PYZdq{}}
             \PY{n}{filename} \PY{o}{=} \PY{n}{f}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{UCI\PYZus{}HAR\PYZus{}Dataset/}\PY{l+s+si}{\PYZob{}subset\PYZcb{}}\PY{l+s+s1}{/y\PYZus{}}\PY{l+s+si}{\PYZob{}subset\PYZcb{}}\PY{l+s+s1}{.txt}\PY{l+s+s1}{\PYZsq{}}
             \PY{n}{y} \PY{o}{=} \PY{n}{\PYZus{}read\PYZus{}csv}\PY{p}{(}\PY{n}{filename}\PY{p}{)}\PY{p}{[}\PY{l+m+mi}{0}\PY{p}{]}
         
             \PY{k}{return} \PY{n}{pd}\PY{o}{.}\PY{n}{get\PYZus{}dummies}\PY{p}{(}\PY{n}{y}\PY{p}{)}\PY{o}{.}\PY{n}{as\PYZus{}matrix}\PY{p}{(}\PY{p}{)}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}13}]:} \PY{k}{def} \PY{n+nf}{load\PYZus{}data}\PY{p}{(}\PY{p}{)}\PY{p}{:}
             \PY{l+s+sd}{\PYZdq{}\PYZdq{}\PYZdq{}}
         \PY{l+s+sd}{    Obtain the dataset from multiple files.}
         \PY{l+s+sd}{    Returns: X\PYZus{}train, X\PYZus{}test, y\PYZus{}train, y\PYZus{}test}
         \PY{l+s+sd}{    \PYZdq{}\PYZdq{}\PYZdq{}}
             \PY{n}{X\PYZus{}train}\PY{p}{,} \PY{n}{X\PYZus{}test} \PY{o}{=} \PY{n}{load\PYZus{}signals}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{train}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}\PY{p}{,} \PY{n}{load\PYZus{}signals}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{test}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
             \PY{n}{y\PYZus{}train}\PY{p}{,} \PY{n}{y\PYZus{}test} \PY{o}{=} \PY{n}{load\PYZus{}y}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{train}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}\PY{p}{,} \PY{n}{load\PYZus{}y}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{test}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
         
             \PY{k}{return} \PY{n}{X\PYZus{}train}\PY{p}{,} \PY{n}{y\PYZus{}train}\PY{p}{,} \PY{n}{X\PYZus{}test}\PY{p}{,}  \PY{n}{y\PYZus{}test}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}12}]:} \PY{c+c1}{\PYZsh{} Importing tensorflow}
         \PY{n}{np}\PY{o}{.}\PY{n}{random}\PY{o}{.}\PY{n}{seed}\PY{p}{(}\PY{l+m+mi}{42}\PY{p}{)}
         \PY{k+kn}{import} \PY{n+nn}{tensorflow} \PY{k}{as} \PY{n+nn}{tf}
         \PY{n}{tf}\PY{o}{.}\PY{n}{set\PYZus{}random\PYZus{}seed}\PY{p}{(}\PY{l+m+mi}{42}\PY{p}{)}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}13}]:} \PY{c+c1}{\PYZsh{} Importing libraries}
         \PY{k+kn}{from} \PY{n+nn}{keras}\PY{n+nn}{.}\PY{n+nn}{models} \PY{k}{import} \PY{n}{Sequential}
         \PY{k+kn}{from} \PY{n+nn}{keras}\PY{n+nn}{.}\PY{n+nn}{layers} \PY{k}{import} \PY{n}{LSTM}
         \PY{k+kn}{from} \PY{n+nn}{keras}\PY{n+nn}{.}\PY{n+nn}{layers}\PY{n+nn}{.}\PY{n+nn}{core} \PY{k}{import} \PY{n}{Dense}\PY{p}{,} \PY{n}{Dropout}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}14}]:} \PY{c+c1}{\PYZsh{} Initializing parameters}
         \PY{n}{epochs} \PY{o}{=} \PY{l+m+mi}{30}
         \PY{n}{batch\PYZus{}size} \PY{o}{=} \PY{l+m+mi}{16}
         \PY{n}{n\PYZus{}hidden} \PY{o}{=} \PY{l+m+mi}{32}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}14}]:} \PY{c+c1}{\PYZsh{} Utility function to count the number of classes}
         \PY{k}{def} \PY{n+nf}{\PYZus{}count\PYZus{}classes}\PY{p}{(}\PY{n}{y}\PY{p}{)}\PY{p}{:}
             \PY{k}{return} \PY{n+nb}{len}\PY{p}{(}\PY{n+nb}{set}\PY{p}{(}\PY{p}{[}\PY{n+nb}{tuple}\PY{p}{(}\PY{n}{category}\PY{p}{)} \PY{k}{for} \PY{n}{category} \PY{o+ow}{in} \PY{n}{y}\PY{p}{]}\PY{p}{)}\PY{p}{)}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}16}]:} \PY{c+c1}{\PYZsh{} Loading the train and test data}
         \PY{n}{X\PYZus{}train}\PY{p}{,} \PY{n}{Y\PYZus{}train}\PY{p}{,} \PY{n}{X\PYZus{}test}\PY{p}{,}  \PY{n}{Y\PYZus{}test} \PY{o}{=} \PY{n}{load\PYZus{}data}\PY{p}{(}\PY{p}{)}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}17}]:} \PY{n}{timesteps} \PY{o}{=} \PY{n+nb}{len}\PY{p}{(}\PY{n}{X\PYZus{}train}\PY{p}{[}\PY{l+m+mi}{0}\PY{p}{]}\PY{p}{)}
         \PY{n}{input\PYZus{}dim} \PY{o}{=} \PY{n+nb}{len}\PY{p}{(}\PY{n}{X\PYZus{}train}\PY{p}{[}\PY{l+m+mi}{0}\PY{p}{]}\PY{p}{[}\PY{l+m+mi}{0}\PY{p}{]}\PY{p}{)}
         \PY{n}{n\PYZus{}classes} \PY{o}{=} \PY{n}{\PYZus{}count\PYZus{}classes}\PY{p}{(}\PY{n}{Y\PYZus{}train}\PY{p}{)}
         \PY{c+c1}{\PYZsh{}n\PYZus{}classes  = 6}
         \PY{n+nb}{print}\PY{p}{(}\PY{n}{timesteps}\PY{p}{)}
         \PY{n+nb}{print}\PY{p}{(}\PY{n}{input\PYZus{}dim}\PY{p}{)}
         \PY{n+nb}{print}\PY{p}{(}\PY{n+nb}{len}\PY{p}{(}\PY{n}{X\PYZus{}train}\PY{p}{)}\PY{p}{)}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
128
9
7352

    \end{Verbatim}

    \paragraph{Base Model}\label{base-model}

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}14}]:} \PY{c+c1}{\PYZsh{} Initiliazing the sequential model}
         \PY{n}{model} \PY{o}{=} \PY{n}{Sequential}\PY{p}{(}\PY{p}{)}
         \PY{c+c1}{\PYZsh{} Configuring the parameters}
         \PY{n}{model}\PY{o}{.}\PY{n}{add}\PY{p}{(}\PY{n}{LSTM}\PY{p}{(}\PY{n}{n\PYZus{}hidden}\PY{p}{,} \PY{n}{input\PYZus{}shape}\PY{o}{=}\PY{p}{(}\PY{n}{timesteps}\PY{p}{,} \PY{n}{input\PYZus{}dim}\PY{p}{)}\PY{p}{)}\PY{p}{)}
         \PY{c+c1}{\PYZsh{} Adding a dropout layer}
         \PY{n}{model}\PY{o}{.}\PY{n}{add}\PY{p}{(}\PY{n}{Dropout}\PY{p}{(}\PY{l+m+mf}{0.5}\PY{p}{)}\PY{p}{)}
         \PY{c+c1}{\PYZsh{} Adding a dense output layer with sigmoid activation}
         \PY{n}{model}\PY{o}{.}\PY{n}{add}\PY{p}{(}\PY{n}{Dense}\PY{p}{(}\PY{n}{n\PYZus{}classes}\PY{p}{,} \PY{n}{activation}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{sigmoid}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}\PY{p}{)}
         \PY{n}{model}\PY{o}{.}\PY{n}{summary}\PY{p}{(}\PY{p}{)}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_
Layer (type)                 Output Shape              Param \#   
=================================================================
lstm\_1 (LSTM)                (None, 32)                5376      
\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_
dropout\_1 (Dropout)          (None, 32)                0         
\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_
dense\_1 (Dense)              (None, 6)                 198       
=================================================================
Total params: 5,574
Trainable params: 5,574
Non-trainable params: 0
\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_

    \end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}22}]:} \PY{c+c1}{\PYZsh{} Compiling the model}
         \PY{n}{model}\PY{o}{.}\PY{n}{compile}\PY{p}{(}\PY{n}{loss}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{categorical\PYZus{}crossentropy}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}
                       \PY{n}{optimizer}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{rmsprop}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}
                       \PY{n}{metrics}\PY{o}{=}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{accuracy}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{)}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}23}]:} \PY{c+c1}{\PYZsh{} Training the model}
         \PY{n}{model}\PY{o}{.}\PY{n}{fit}\PY{p}{(}\PY{n}{X\PYZus{}train}\PY{p}{,}
                   \PY{n}{Y\PYZus{}train}\PY{p}{,}
                   \PY{n}{batch\PYZus{}size}\PY{o}{=}\PY{n}{batch\PYZus{}size}\PY{p}{,}
                   \PY{n}{validation\PYZus{}data}\PY{o}{=}\PY{p}{(}\PY{n}{X\PYZus{}test}\PY{p}{,} \PY{n}{Y\PYZus{}test}\PY{p}{)}\PY{p}{,}
                   \PY{n}{epochs}\PY{o}{=}\PY{n}{epochs}\PY{p}{)}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
Train on 7352 samples, validate on 2947 samples
Epoch 1/30
7352/7352 [==============================] - 54s 7ms/step - loss: 1.3194 - acc: 0.4376 - val\_loss: 1.1805 - val\_acc: 0.4496
Epoch 2/30
7352/7352 [==============================] - 53s 7ms/step - loss: 0.9842 - acc: 0.5749 - val\_loss: 0.9447 - val\_acc: 0.5857
Epoch 3/30
7352/7352 [==============================] - 53s 7ms/step - loss: 0.7991 - acc: 0.6470 - val\_loss: 0.7865 - val\_acc: 0.6132
Epoch 4/30
7352/7352 [==============================] - 52s 7ms/step - loss: 0.6984 - acc: 0.6661 - val\_loss: 0.8261 - val\_acc: 0.5901
Epoch 5/30
7352/7352 [==============================] - 53s 7ms/step - loss: 0.6306 - acc: 0.6876 - val\_loss: 0.7671 - val\_acc: 0.6434
Epoch 6/30
7352/7352 [==============================] - 52s 7ms/step - loss: 0.6168 - acc: 0.7084 - val\_loss: 0.8407 - val\_acc: 0.6590
Epoch 7/30
7352/7352 [==============================] - 53s 7ms/step - loss: 0.6056 - acc: 0.7361 - val\_loss: 0.6495 - val\_acc: 0.7248
Epoch 8/30
7352/7352 [==============================] - 52s 7ms/step - loss: 0.5260 - acc: 0.7719 - val\_loss: 0.6340 - val\_acc: 0.7265
Epoch 9/30
7352/7352 [==============================] - 53s 7ms/step - loss: 0.4605 - acc: 0.7900 - val\_loss: 0.6768 - val\_acc: 0.7296
Epoch 10/30
7352/7352 [==============================] - 53s 7ms/step - loss: 0.4405 - acc: 0.7999 - val\_loss: 0.5573 - val\_acc: 0.7530
Epoch 11/30
7352/7352 [==============================] - 52s 7ms/step - loss: 0.4180 - acc: 0.8013 - val\_loss: 0.5859 - val\_acc: 0.7201
Epoch 12/30
7352/7352 [==============================] - 52s 7ms/step - loss: 0.4083 - acc: 0.8198 - val\_loss: 0.5773 - val\_acc: 0.7625
Epoch 13/30
7352/7352 [==============================] - 52s 7ms/step - loss: 0.3706 - acc: 0.8560 - val\_loss: 0.6319 - val\_acc: 0.8504
Epoch 14/30
7352/7352 [==============================] - 52s 7ms/step - loss: 0.3456 - acc: 0.8832 - val\_loss: 0.4920 - val\_acc: 0.8717
Epoch 15/30
7352/7352 [==============================] - 53s 7ms/step - loss: 0.2947 - acc: 0.9135 - val\_loss: 0.6581 - val\_acc: 0.8554
Epoch 16/30
7352/7352 [==============================] - 52s 7ms/step - loss: 0.3015 - acc: 0.9159 - val\_loss: 0.4791 - val\_acc: 0.8833
Epoch 17/30
7352/7352 [==============================] - 52s 7ms/step - loss: 0.2472 - acc: 0.9317 - val\_loss: 0.5137 - val\_acc: 0.8785
Epoch 18/30
7352/7352 [==============================] - 53s 7ms/step - loss: 0.2784 - acc: 0.9271 - val\_loss: 0.7416 - val\_acc: 0.8364
Epoch 19/30
7352/7352 [==============================] - 53s 7ms/step - loss: 0.2505 - acc: 0.9306 - val\_loss: 0.4745 - val\_acc: 0.8894
Epoch 20/30
7352/7352 [==============================] - 53s 7ms/step - loss: 0.2093 - acc: 0.9344 - val\_loss: 0.5829 - val\_acc: 0.8775
Epoch 21/30
7352/7352 [==============================] - 53s 7ms/step - loss: 0.2218 - acc: 0.9370 - val\_loss: 0.4609 - val\_acc: 0.8931
Epoch 22/30
7352/7352 [==============================] - 53s 7ms/step - loss: 0.1966 - acc: 0.9414 - val\_loss: 0.4116 - val\_acc: 0.9046
Epoch 23/30
7352/7352 [==============================] - 53s 7ms/step - loss: 0.1827 - acc: 0.9403 - val\_loss: 0.4737 - val\_acc: 0.8979
Epoch 24/30
7352/7352 [==============================] - 53s 7ms/step - loss: 0.1801 - acc: 0.9393 - val\_loss: 0.6009 - val\_acc: 0.8860
Epoch 25/30
7352/7352 [==============================] - 53s 7ms/step - loss: 0.1896 - acc: 0.9433 - val\_loss: 0.4729 - val\_acc: 0.9063
Epoch 26/30
7352/7352 [==============================] - 53s 7ms/step - loss: 0.2555 - acc: 0.9334 - val\_loss: 0.4608 - val\_acc: 0.9070
Epoch 27/30
7352/7352 [==============================] - 53s 7ms/step - loss: 0.1791 - acc: 0.9434 - val\_loss: 0.4300 - val\_acc: 0.9080
Epoch 28/30
7352/7352 [==============================] - 53s 7ms/step - loss: 0.2444 - acc: 0.9339 - val\_loss: 0.4088 - val\_acc: 0.9101
Epoch 29/30
7352/7352 [==============================] - 53s 7ms/step - loss: 0.1938 - acc: 0.9393 - val\_loss: 0.4978 - val\_acc: 0.9050
Epoch 30/30
7352/7352 [==============================] - 53s 7ms/step - loss: 0.1598 - acc: 0.9450 - val\_loss: 0.4559 - val\_acc: 0.9013

    \end{Verbatim}

\begin{Verbatim}[commandchars=\\\{\}]
{\color{outcolor}Out[{\color{outcolor}23}]:} <keras.callbacks.History at 0x14f1ed870710>
\end{Verbatim}
            
    \paragraph{Multi layer LSTM}\label{multi-layer-lstm}

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}16}]:} \PY{c+c1}{\PYZsh{} Initiliazing the sequential model}
         \PY{n}{model} \PY{o}{=} \PY{n}{Sequential}\PY{p}{(}\PY{p}{)}
         \PY{c+c1}{\PYZsh{} Configuring the parameters}
         \PY{n}{model}\PY{o}{.}\PY{n}{add}\PY{p}{(}\PY{n}{LSTM}\PY{p}{(}\PY{l+m+mi}{32}\PY{p}{,}\PY{n}{return\PYZus{}sequences}\PY{o}{=}\PY{k+kc}{True}\PY{p}{,}\PY{n}{input\PYZus{}shape}\PY{o}{=}\PY{p}{(}\PY{n}{timesteps}\PY{p}{,} \PY{n}{input\PYZus{}dim}\PY{p}{)}\PY{p}{)}\PY{p}{)}
         \PY{c+c1}{\PYZsh{} Adding a dropout layer}
         \PY{n}{model}\PY{o}{.}\PY{n}{add}\PY{p}{(}\PY{n}{Dropout}\PY{p}{(}\PY{l+m+mf}{0.5}\PY{p}{)}\PY{p}{)}
         
         \PY{n}{model}\PY{o}{.}\PY{n}{add}\PY{p}{(}\PY{n}{LSTM}\PY{p}{(}\PY{l+m+mi}{28}\PY{p}{,}\PY{n}{input\PYZus{}shape}\PY{o}{=}\PY{p}{(}\PY{n}{timesteps}\PY{p}{,} \PY{n}{input\PYZus{}dim}\PY{p}{)}\PY{p}{)}\PY{p}{)}
         \PY{c+c1}{\PYZsh{} Adding a dropout layer}
         \PY{n}{model}\PY{o}{.}\PY{n}{add}\PY{p}{(}\PY{n}{Dropout}\PY{p}{(}\PY{l+m+mf}{0.6}\PY{p}{)}\PY{p}{)}
         \PY{c+c1}{\PYZsh{} Adding a dense output layer with sigmoid activation}
         \PY{n}{model}\PY{o}{.}\PY{n}{add}\PY{p}{(}\PY{n}{Dense}\PY{p}{(}\PY{n}{n\PYZus{}classes}\PY{p}{,} \PY{n}{activation}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{sigmoid}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}\PY{p}{)}
         \PY{n}{model}\PY{o}{.}\PY{n}{summary}\PY{p}{(}\PY{p}{)}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_
Layer (type)                 Output Shape              Param \#   
=================================================================
lstm\_5 (LSTM)                (None, 128, 32)           5376      
\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_
dropout\_5 (Dropout)          (None, 128, 32)           0         
\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_
lstm\_6 (LSTM)                (None, 28)                6832      
\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_
dropout\_6 (Dropout)          (None, 28)                0         
\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_
dense\_3 (Dense)              (None, 6)                 174       
=================================================================
Total params: 12,382
Trainable params: 12,382
Non-trainable params: 0
\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_

    \end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}17}]:} \PY{c+c1}{\PYZsh{} Compiling the model}
         \PY{n}{model}\PY{o}{.}\PY{n}{compile}\PY{p}{(}\PY{n}{loss}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{categorical\PYZus{}crossentropy}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}
                       \PY{n}{optimizer}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{rmsprop}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}
                       \PY{n}{metrics}\PY{o}{=}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{accuracy}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{)}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}18}]:} \PY{c+c1}{\PYZsh{} Training the model}
         \PY{n}{model}\PY{o}{.}\PY{n}{fit}\PY{p}{(}\PY{n}{X\PYZus{}train}\PY{p}{,}
                   \PY{n}{Y\PYZus{}train}\PY{p}{,}
                   \PY{n}{batch\PYZus{}size}\PY{o}{=}\PY{n}{batch\PYZus{}size}\PY{p}{,}
                   \PY{n}{validation\PYZus{}data}\PY{o}{=}\PY{p}{(}\PY{n}{X\PYZus{}test}\PY{p}{,} \PY{n}{Y\PYZus{}test}\PY{p}{)}\PY{p}{,}
                   \PY{n}{epochs}\PY{o}{=}\PY{n}{epochs}\PY{p}{)}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
Train on 7352 samples, validate on 2947 samples
Epoch 1/30
7352/7352 [==============================] - 109s 15ms/step - loss: 1.3081 - acc: 0.4561 - val\_loss: 0.9680 - val\_acc: 0.5409
Epoch 2/30
7352/7352 [==============================] - 107s 15ms/step - loss: 0.8821 - acc: 0.6051 - val\_loss: 0.8140 - val\_acc: 0.6284
Epoch 3/30
7352/7352 [==============================] - 106s 14ms/step - loss: 0.7624 - acc: 0.6359 - val\_loss: 0.8088 - val\_acc: 0.6037
Epoch 4/30
7352/7352 [==============================] - 104s 14ms/step - loss: 0.7258 - acc: 0.6302 - val\_loss: 0.7932 - val\_acc: 0.6189
Epoch 5/30
7352/7352 [==============================] - 104s 14ms/step - loss: 0.7122 - acc: 0.6474 - val\_loss: 0.7969 - val\_acc: 0.6189
Epoch 6/30
7352/7352 [==============================] - 104s 14ms/step - loss: 0.6977 - acc: 0.6515 - val\_loss: 0.7787 - val\_acc: 0.6152
Epoch 7/30
7352/7352 [==============================] - 104s 14ms/step - loss: 0.6750 - acc: 0.6790 - val\_loss: 0.7335 - val\_acc: 0.6793
Epoch 8/30
7352/7352 [==============================] - 104s 14ms/step - loss: 0.6167 - acc: 0.7329 - val\_loss: 0.7110 - val\_acc: 0.6990
Epoch 9/30
7352/7352 [==============================] - 104s 14ms/step - loss: 0.5178 - acc: 0.7889 - val\_loss: 0.6528 - val\_acc: 0.7357
Epoch 10/30
7352/7352 [==============================] - 104s 14ms/step - loss: 0.4557 - acc: 0.8215 - val\_loss: 0.5696 - val\_acc: 0.8521
Epoch 11/30
7352/7352 [==============================] - 104s 14ms/step - loss: 0.4006 - acc: 0.8554 - val\_loss: 0.7078 - val\_acc: 0.8093
Epoch 12/30
7352/7352 [==============================] - 104s 14ms/step - loss: 0.3518 - acc: 0.8936 - val\_loss: 0.4328 - val\_acc: 0.8884
Epoch 13/30
7352/7352 [==============================] - 105s 14ms/step - loss: 0.2959 - acc: 0.9102 - val\_loss: 0.5183 - val\_acc: 0.8595
Epoch 14/30
7352/7352 [==============================] - 104s 14ms/step - loss: 0.2716 - acc: 0.9240 - val\_loss: 0.5887 - val\_acc: 0.8568
Epoch 15/30
7352/7352 [==============================] - 104s 14ms/step - loss: 0.2532 - acc: 0.9223 - val\_loss: 0.4996 - val\_acc: 0.8887
Epoch 16/30
7352/7352 [==============================] - 105s 14ms/step - loss: 0.2409 - acc: 0.9295 - val\_loss: 0.4287 - val\_acc: 0.8992
Epoch 17/30
7352/7352 [==============================] - 105s 14ms/step - loss: 0.2296 - acc: 0.9342 - val\_loss: 0.4177 - val\_acc: 0.8931
Epoch 18/30
7352/7352 [==============================] - 105s 14ms/step - loss: 0.2039 - acc: 0.9377 - val\_loss: 0.5764 - val\_acc: 0.8962
Epoch 19/30
7352/7352 [==============================] - 105s 14ms/step - loss: 0.2141 - acc: 0.9331 - val\_loss: 0.4349 - val\_acc: 0.9080
Epoch 20/30
7352/7352 [==============================] - 105s 14ms/step - loss: 0.2001 - acc: 0.9382 - val\_loss: 0.5034 - val\_acc: 0.8914
Epoch 21/30
7352/7352 [==============================] - 105s 14ms/step - loss: 0.1917 - acc: 0.9348 - val\_loss: 0.4654 - val\_acc: 0.9108
Epoch 22/30
7352/7352 [==============================] - 105s 14ms/step - loss: 0.1970 - acc: 0.9362 - val\_loss: 0.4669 - val\_acc: 0.8989
Epoch 23/30
7352/7352 [==============================] - 105s 14ms/step - loss: 0.1801 - acc: 0.9425 - val\_loss: 0.5325 - val\_acc: 0.8928
Epoch 24/30
7352/7352 [==============================] - 106s 14ms/step - loss: 0.1680 - acc: 0.9446 - val\_loss: 0.5077 - val\_acc: 0.9030
Epoch 25/30
7352/7352 [==============================] - 105s 14ms/step - loss: 0.1835 - acc: 0.9418 - val\_loss: 0.5613 - val\_acc: 0.9067
Epoch 26/30
7352/7352 [==============================] - 105s 14ms/step - loss: 0.1692 - acc: 0.9449 - val\_loss: 0.4361 - val\_acc: 0.9148
Epoch 27/30
7352/7352 [==============================] - 105s 14ms/step - loss: 0.1722 - acc: 0.9421 - val\_loss: 0.6196 - val\_acc: 0.8985
Epoch 28/30
7352/7352 [==============================] - 104s 14ms/step - loss: 0.1739 - acc: 0.9434 - val\_loss: 0.4876 - val\_acc: 0.9131
Epoch 29/30
7352/7352 [==============================] - 105s 14ms/step - loss: 0.1833 - acc: 0.9421 - val\_loss: 0.6746 - val\_acc: 0.8999
Epoch 30/30
7352/7352 [==============================] - 105s 14ms/step - loss: 0.1730 - acc: 0.9431 - val\_loss: 0.4763 - val\_acc: 0.9084

    \end{Verbatim}

\begin{Verbatim}[commandchars=\\\{\}]
{\color{outcolor}Out[{\color{outcolor}18}]:} <keras.callbacks.History at 0x14f13724bc88>
\end{Verbatim}
            
    Above 2 layer LSTM is giving similar score as 1 layer LSTM which we
trained above.

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}14}]:} \PY{k+kn}{from} \PY{n+nn}{keras}\PY{n+nn}{.}\PY{n+nn}{regularizers} \PY{k}{import} \PY{n}{l2}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}20}]:} \PY{c+c1}{\PYZsh{} Initiliazing the sequential model}
         \PY{n}{model} \PY{o}{=} \PY{n}{Sequential}\PY{p}{(}\PY{p}{)}
         \PY{c+c1}{\PYZsh{} Configuring the parameters}
         \PY{n}{model}\PY{o}{.}\PY{n}{add}\PY{p}{(}\PY{n}{LSTM}\PY{p}{(}\PY{l+m+mi}{32}\PY{p}{,}\PY{n}{recurrent\PYZus{}regularizer}\PY{o}{=}\PY{n}{l2}\PY{p}{(}\PY{l+m+mf}{0.003}\PY{p}{)}\PY{p}{,}\PY{n}{return\PYZus{}sequences}\PY{o}{=}\PY{k+kc}{True}\PY{p}{,}\PY{n}{input\PYZus{}shape}\PY{o}{=}\PY{p}{(}\PY{n}{timesteps}\PY{p}{,} \PY{n}{input\PYZus{}dim}\PY{p}{)}\PY{p}{)}\PY{p}{)}
         \PY{c+c1}{\PYZsh{} Adding a dropout layer}
         \PY{n}{model}\PY{o}{.}\PY{n}{add}\PY{p}{(}\PY{n}{Dropout}\PY{p}{(}\PY{l+m+mf}{0.5}\PY{p}{)}\PY{p}{)}
         
         \PY{n}{model}\PY{o}{.}\PY{n}{add}\PY{p}{(}\PY{n}{LSTM}\PY{p}{(}\PY{l+m+mi}{28}\PY{p}{,}\PY{n}{input\PYZus{}shape}\PY{o}{=}\PY{p}{(}\PY{n}{timesteps}\PY{p}{,} \PY{n}{input\PYZus{}dim}\PY{p}{)}\PY{p}{)}\PY{p}{)}
         \PY{c+c1}{\PYZsh{} Adding a dropout layer}
         \PY{n}{model}\PY{o}{.}\PY{n}{add}\PY{p}{(}\PY{n}{Dropout}\PY{p}{(}\PY{l+m+mf}{0.6}\PY{p}{)}\PY{p}{)}
         \PY{c+c1}{\PYZsh{} Adding a dense output layer with sigmoid activation}
         \PY{n}{model}\PY{o}{.}\PY{n}{add}\PY{p}{(}\PY{n}{Dense}\PY{p}{(}\PY{n}{n\PYZus{}classes}\PY{p}{,} \PY{n}{activation}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{sigmoid}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}\PY{p}{)}
         \PY{n}{model}\PY{o}{.}\PY{n}{summary}\PY{p}{(}\PY{p}{)}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_
Layer (type)                 Output Shape              Param \#   
=================================================================
lstm\_7 (LSTM)                (None, 128, 32)           5376      
\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_
dropout\_7 (Dropout)          (None, 128, 32)           0         
\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_
lstm\_8 (LSTM)                (None, 28)                6832      
\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_
dropout\_8 (Dropout)          (None, 28)                0         
\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_
dense\_4 (Dense)              (None, 6)                 174       
=================================================================
Total params: 12,382
Trainable params: 12,382
Non-trainable params: 0
\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_

    \end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}21}]:} \PY{c+c1}{\PYZsh{} Compiling the model}
         \PY{n}{model}\PY{o}{.}\PY{n}{compile}\PY{p}{(}\PY{n}{loss}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{categorical\PYZus{}crossentropy}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}
                       \PY{n}{optimizer}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{adam}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}
                       \PY{n}{metrics}\PY{o}{=}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{accuracy}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{)}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}22}]:} \PY{c+c1}{\PYZsh{} Training the model}
         \PY{n}{History} \PY{o}{=} \PY{n}{model}\PY{o}{.}\PY{n}{fit}\PY{p}{(}\PY{n}{X\PYZus{}train}\PY{p}{,}
                   \PY{n}{Y\PYZus{}train}\PY{p}{,}
                   \PY{n}{batch\PYZus{}size}\PY{o}{=}\PY{n}{batch\PYZus{}size}\PY{p}{,}
                   \PY{n}{validation\PYZus{}data}\PY{o}{=}\PY{p}{(}\PY{n}{X\PYZus{}test}\PY{p}{,} \PY{n}{Y\PYZus{}test}\PY{p}{)}\PY{p}{,}
                   \PY{n}{epochs}\PY{o}{=}\PY{l+m+mi}{10}\PY{p}{)}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
Train on 7352 samples, validate on 2947 samples
Epoch 1/10
7352/7352 [==============================] - 107s 15ms/step - loss: 1.4263 - acc: 0.4241 - val\_loss: 1.2625 - val\_acc: 0.5175
Epoch 2/10
7352/7352 [==============================] - 105s 14ms/step - loss: 1.2066 - acc: 0.5011 - val\_loss: 1.5878 - val\_acc: 0.3549
Epoch 3/10
7352/7352 [==============================] - 105s 14ms/step - loss: 0.9923 - acc: 0.5695 - val\_loss: 0.9060 - val\_acc: 0.6162
Epoch 4/10
7352/7352 [==============================] - 105s 14ms/step - loss: 0.9109 - acc: 0.5839 - val\_loss: 0.8547 - val\_acc: 0.5962
Epoch 5/10
7352/7352 [==============================] - 105s 14ms/step - loss: 0.7995 - acc: 0.6223 - val\_loss: 0.7806 - val\_acc: 0.6176
Epoch 6/10
7352/7352 [==============================] - 105s 14ms/step - loss: 0.8123 - acc: 0.6062 - val\_loss: 0.8927 - val\_acc: 0.5887
Epoch 7/10
7352/7352 [==============================] - 105s 14ms/step - loss: 0.7574 - acc: 0.6319 - val\_loss: 0.7507 - val\_acc: 0.6050
Epoch 8/10
7352/7352 [==============================] - 105s 14ms/step - loss: 0.7699 - acc: 0.6411 - val\_loss: 0.7285 - val\_acc: 0.6159
Epoch 9/10
7352/7352 [==============================] - 106s 14ms/step - loss: 0.7106 - acc: 0.6493 - val\_loss: 0.8037 - val\_acc: 0.5935
Epoch 10/10
7352/7352 [==============================] - 105s 14ms/step - loss: 0.7854 - acc: 0.6389 - val\_loss: 1.9405 - val\_acc: 0.3936

    \end{Verbatim}

    \subsubsection{Hyperparameter Tuning Using
Hyperas:}\label{hyperparameter-tuning-using-hyperas}

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}18}]:} \PY{c+c1}{\PYZsh{} Importing tensorflow}
         \PY{n}{np}\PY{o}{.}\PY{n}{random}\PY{o}{.}\PY{n}{seed}\PY{p}{(}\PY{l+m+mi}{36}\PY{p}{)}
         \PY{k+kn}{import} \PY{n+nn}{tensorflow} \PY{k}{as} \PY{n+nn}{tf}
         \PY{n}{tf}\PY{o}{.}\PY{n}{set\PYZus{}random\PYZus{}seed}\PY{p}{(}\PY{l+m+mi}{36}\PY{p}{)}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}5}]:} \PY{c+c1}{\PYZsh{} Importing libraries}
        \PY{k+kn}{from} \PY{n+nn}{keras}\PY{n+nn}{.}\PY{n+nn}{models} \PY{k}{import} \PY{n}{Sequential}
        \PY{k+kn}{from} \PY{n+nn}{keras}\PY{n+nn}{.}\PY{n+nn}{layers} \PY{k}{import} \PY{n}{LSTM}
        \PY{k+kn}{from} \PY{n+nn}{keras}\PY{n+nn}{.}\PY{n+nn}{layers}\PY{n+nn}{.}\PY{n+nn}{core} \PY{k}{import} \PY{n}{Dense}\PY{p}{,} \PY{n}{Dropout}
        \PY{k+kn}{from} \PY{n+nn}{hyperopt} \PY{k}{import} \PY{n}{Trials}\PY{p}{,} \PY{n}{STATUS\PYZus{}OK}\PY{p}{,} \PY{n}{tpe}
        \PY{k+kn}{from} \PY{n+nn}{hyperas} \PY{k}{import} \PY{n}{optim}
        \PY{k+kn}{from} \PY{n+nn}{hyperas}\PY{n+nn}{.}\PY{n+nn}{distributions} \PY{k}{import} \PY{n}{choice}\PY{p}{,} \PY{n}{uniform}
        \PY{k+kn}{from} \PY{n+nn}{hyperas}\PY{n+nn}{.}\PY{n+nn}{utils} \PY{k}{import} \PY{n}{eval\PYZus{}hyperopt\PYZus{}space}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}6}]:} \PY{c+c1}{\PYZsh{}\PYZsh{}gives train and validation data }
        \PY{k}{def} \PY{n+nf}{data}\PY{p}{(}\PY{p}{)}\PY{p}{:}
            \PY{l+s+sd}{\PYZdq{}\PYZdq{}\PYZdq{}}
        \PY{l+s+sd}{    Obtain the dataset from multiple files.}
        \PY{l+s+sd}{    Returns: X\PYZus{}train, X\PYZus{}test, y\PYZus{}train, y\PYZus{}test}
        \PY{l+s+sd}{    \PYZdq{}\PYZdq{}\PYZdq{}}
            \PY{c+c1}{\PYZsh{} Data directory}
            \PY{n}{DATADIR} \PY{o}{=} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{UCI\PYZus{}HAR\PYZus{}Dataset}\PY{l+s+s1}{\PYZsq{}}
            \PY{c+c1}{\PYZsh{} Raw data signals}
            \PY{c+c1}{\PYZsh{} Signals are from Accelerometer and Gyroscope}
            \PY{c+c1}{\PYZsh{} The signals are in x,y,z directions}
            \PY{c+c1}{\PYZsh{} Sensor signals are filtered to have only body acceleration}
            \PY{c+c1}{\PYZsh{} excluding the acceleration due to gravity}
            \PY{c+c1}{\PYZsh{} Triaxial acceleration from the accelerometer is total acceleration}
            \PY{n}{SIGNALS} \PY{o}{=} \PY{p}{[}
                \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{body\PYZus{}acc\PYZus{}x}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,}
                \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{body\PYZus{}acc\PYZus{}y}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,}
                \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{body\PYZus{}acc\PYZus{}z}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,}
                \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{body\PYZus{}gyro\PYZus{}x}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,}
                \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{body\PYZus{}gyro\PYZus{}y}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,}
                \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{body\PYZus{}gyro\PYZus{}z}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,}
                \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{total\PYZus{}acc\PYZus{}x}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,}
                \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{total\PYZus{}acc\PYZus{}y}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,}
                \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{total\PYZus{}acc\PYZus{}z}\PY{l+s+s2}{\PYZdq{}}
                \PY{p}{]}
            \PY{c+c1}{\PYZsh{} Utility function to read the data from csv file}
            \PY{k}{def} \PY{n+nf}{\PYZus{}read\PYZus{}csv}\PY{p}{(}\PY{n}{filename}\PY{p}{)}\PY{p}{:}
                \PY{k}{return} \PY{n}{pd}\PY{o}{.}\PY{n}{read\PYZus{}csv}\PY{p}{(}\PY{n}{filename}\PY{p}{,} \PY{n}{delim\PYZus{}whitespace}\PY{o}{=}\PY{k+kc}{True}\PY{p}{,} \PY{n}{header}\PY{o}{=}\PY{k+kc}{None}\PY{p}{)}
        
            \PY{c+c1}{\PYZsh{} Utility function to load the load}
            \PY{k}{def} \PY{n+nf}{load\PYZus{}signals}\PY{p}{(}\PY{n}{subset}\PY{p}{)}\PY{p}{:}
                \PY{n}{signals\PYZus{}data} \PY{o}{=} \PY{p}{[}\PY{p}{]}
        
                \PY{k}{for} \PY{n}{signal} \PY{o+ow}{in} \PY{n}{SIGNALS}\PY{p}{:}
                    \PY{n}{filename} \PY{o}{=} \PY{n}{f}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{UCI\PYZus{}HAR\PYZus{}Dataset/}\PY{l+s+si}{\PYZob{}subset\PYZcb{}}\PY{l+s+s1}{/Inertial Signals/}\PY{l+s+si}{\PYZob{}signal\PYZcb{}}\PY{l+s+s1}{\PYZus{}}\PY{l+s+si}{\PYZob{}subset\PYZcb{}}\PY{l+s+s1}{.txt}\PY{l+s+s1}{\PYZsq{}}
                    \PY{n}{signals\PYZus{}data}\PY{o}{.}\PY{n}{append}\PY{p}{(} \PY{n}{\PYZus{}read\PYZus{}csv}\PY{p}{(}\PY{n}{filename}\PY{p}{)}\PY{o}{.}\PY{n}{as\PYZus{}matrix}\PY{p}{(}\PY{p}{)}\PY{p}{)} 
        
                \PY{c+c1}{\PYZsh{} Transpose is used to change the dimensionality of the output,}
                \PY{c+c1}{\PYZsh{} aggregating the signals by combination of sample/timestep.}
                \PY{c+c1}{\PYZsh{} Resultant shape is (7352 train/2947 test samples, 128 timesteps, 9 signals)}
                \PY{k}{return} \PY{n}{np}\PY{o}{.}\PY{n}{transpose}\PY{p}{(}\PY{n}{signals\PYZus{}data}\PY{p}{,} \PY{p}{(}\PY{l+m+mi}{1}\PY{p}{,} \PY{l+m+mi}{2}\PY{p}{,} \PY{l+m+mi}{0}\PY{p}{)}\PY{p}{)}
            
            \PY{k}{def} \PY{n+nf}{load\PYZus{}y}\PY{p}{(}\PY{n}{subset}\PY{p}{)}\PY{p}{:}
                \PY{l+s+sd}{\PYZdq{}\PYZdq{}\PYZdq{}}
        \PY{l+s+sd}{        The objective that we are trying to predict is a integer, from 1 to 6,}
        \PY{l+s+sd}{        that represents a human activity. We return a binary representation of }
        \PY{l+s+sd}{        every sample objective as a 6 bits vector using One Hot Encoding}
        \PY{l+s+sd}{        (https://pandas.pydata.org/pandas\PYZhy{}docs/stable/generated/pandas.get\PYZus{}dummies.html)}
        \PY{l+s+sd}{        \PYZdq{}\PYZdq{}\PYZdq{}}
                \PY{n}{filename} \PY{o}{=} \PY{n}{f}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{UCI\PYZus{}HAR\PYZus{}Dataset/}\PY{l+s+si}{\PYZob{}subset\PYZcb{}}\PY{l+s+s1}{/y\PYZus{}}\PY{l+s+si}{\PYZob{}subset\PYZcb{}}\PY{l+s+s1}{.txt}\PY{l+s+s1}{\PYZsq{}}
                \PY{n}{y} \PY{o}{=} \PY{n}{\PYZus{}read\PYZus{}csv}\PY{p}{(}\PY{n}{filename}\PY{p}{)}\PY{p}{[}\PY{l+m+mi}{0}\PY{p}{]}
                \PY{k}{return} \PY{n}{pd}\PY{o}{.}\PY{n}{get\PYZus{}dummies}\PY{p}{(}\PY{n}{y}\PY{p}{)}\PY{o}{.}\PY{n}{as\PYZus{}matrix}\PY{p}{(}\PY{p}{)}
            
            \PY{n}{X\PYZus{}train}\PY{p}{,} \PY{n}{X\PYZus{}val} \PY{o}{=} \PY{n}{load\PYZus{}signals}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{train}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}\PY{p}{,} \PY{n}{load\PYZus{}signals}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{test}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
            \PY{n}{Y\PYZus{}train}\PY{p}{,} \PY{n}{Y\PYZus{}val} \PY{o}{=} \PY{n}{load\PYZus{}y}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{train}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}\PY{p}{,} \PY{n}{load\PYZus{}y}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{test}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
        
            \PY{k}{return} \PY{n}{X\PYZus{}train}\PY{p}{,} \PY{n}{Y\PYZus{}train}\PY{p}{,} \PY{n}{X\PYZus{}val}\PY{p}{,}  \PY{n}{Y\PYZus{}val}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}7}]:} \PY{k+kn}{from} \PY{n+nn}{keras}\PY{n+nn}{.}\PY{n+nn}{regularizers} \PY{k}{import} \PY{n}{l2}
        \PY{k+kn}{import} \PY{n+nn}{keras}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}8}]:} \PY{c+c1}{\PYZsh{}\PYZsh{}model}
        \PY{k}{def} \PY{n+nf}{model}\PY{p}{(}\PY{n}{X\PYZus{}train}\PY{p}{,} \PY{n}{Y\PYZus{}train}\PY{p}{,} \PY{n}{X\PYZus{}val}\PY{p}{,} \PY{n}{Y\PYZus{}val}\PY{p}{)}\PY{p}{:}
            \PY{c+c1}{\PYZsh{} Importing tensorflow}
            \PY{n}{np}\PY{o}{.}\PY{n}{random}\PY{o}{.}\PY{n}{seed}\PY{p}{(}\PY{l+m+mi}{36}\PY{p}{)}
            \PY{k+kn}{import} \PY{n+nn}{tensorflow} \PY{k}{as} \PY{n+nn}{tf}
            \PY{n}{tf}\PY{o}{.}\PY{n}{set\PYZus{}random\PYZus{}seed}\PY{p}{(}\PY{l+m+mi}{36}\PY{p}{)}
            \PY{c+c1}{\PYZsh{} Initiliazing the sequential model}
            \PY{n}{model} \PY{o}{=} \PY{n}{Sequential}\PY{p}{(}\PY{p}{)} 
            \PY{k}{if} \PY{n}{conditional}\PY{p}{(}\PY{p}{\PYZob{}}\PY{p}{\PYZob{}}\PY{n}{choice}\PY{p}{(}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{one}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{two}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{)}\PY{p}{\PYZcb{}}\PY{p}{\PYZcb{}}\PY{p}{)} \PY{o}{==} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{two}\PY{l+s+s1}{\PYZsq{}}\PY{p}{:}
                \PY{c+c1}{\PYZsh{} Configuring the parameters}
                \PY{n}{model}\PY{o}{.}\PY{n}{add}\PY{p}{(}\PY{n}{LSTM}\PY{p}{(}\PY{p}{\PYZob{}}\PY{p}{\PYZob{}}\PY{n}{choice}\PY{p}{(}\PY{p}{[}\PY{l+m+mi}{28}\PY{p}{,}\PY{l+m+mi}{32}\PY{p}{,}\PY{l+m+mi}{38}\PY{p}{]}\PY{p}{)}\PY{p}{\PYZcb{}}\PY{p}{\PYZcb{}}\PY{p}{,}\PY{n}{recurrent\PYZus{}regularizer}\PY{o}{=}\PY{n}{l2}\PY{p}{(}\PY{p}{\PYZob{}}\PY{p}{\PYZob{}}\PY{n}{uniform}\PY{p}{(}\PY{l+m+mi}{0}\PY{p}{,}\PY{l+m+mf}{0.0002}\PY{p}{)}\PY{p}{\PYZcb{}}\PY{p}{\PYZcb{}}\PY{p}{)}\PY{p}{,}\PY{n}{return\PYZus{}sequences}\PY{o}{=}\PY{k+kc}{True}\PY{p}{,}\PY{n}{input\PYZus{}shape}\PY{o}{=}\PY{p}{(}\PY{l+m+mi}{128}\PY{p}{,} \PY{l+m+mi}{9}\PY{p}{)}\PY{p}{,}\PY{n}{name}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{LSTM2\PYZus{}1}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}\PY{p}{)}
                \PY{c+c1}{\PYZsh{} Adding a dropout layer}
                \PY{n}{model}\PY{o}{.}\PY{n}{add}\PY{p}{(}\PY{n}{Dropout}\PY{p}{(}\PY{p}{\PYZob{}}\PY{p}{\PYZob{}}\PY{n}{uniform}\PY{p}{(}\PY{l+m+mf}{0.35}\PY{p}{,}\PY{l+m+mf}{0.65}\PY{p}{)}\PY{p}{\PYZcb{}}\PY{p}{\PYZcb{}}\PY{p}{,}\PY{n}{name}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Dropout2\PYZus{}1}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}\PY{p}{)}
                \PY{n}{model}\PY{o}{.}\PY{n}{add}\PY{p}{(}\PY{n}{LSTM}\PY{p}{(}\PY{p}{\PYZob{}}\PY{p}{\PYZob{}}\PY{n}{choice}\PY{p}{(}\PY{p}{[}\PY{l+m+mi}{26}\PY{p}{,}\PY{l+m+mi}{32}\PY{p}{,}\PY{l+m+mi}{36}\PY{p}{]}\PY{p}{)}\PY{p}{\PYZcb{}}\PY{p}{\PYZcb{}}\PY{p}{,}\PY{n}{recurrent\PYZus{}regularizer}\PY{o}{=}\PY{n}{l2}\PY{p}{(}\PY{p}{\PYZob{}}\PY{p}{\PYZob{}}\PY{n}{uniform}\PY{p}{(}\PY{l+m+mi}{0}\PY{p}{,}\PY{l+m+mf}{0.001}\PY{p}{)}\PY{p}{\PYZcb{}}\PY{p}{\PYZcb{}}\PY{p}{)}\PY{p}{,}\PY{n}{input\PYZus{}shape}\PY{o}{=}\PY{p}{(}\PY{l+m+mi}{128}\PY{p}{,} \PY{l+m+mi}{9}\PY{p}{)}\PY{p}{,}\PY{n}{name}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{LSTM2\PYZus{}2}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}\PY{p}{)}
                \PY{n}{model}\PY{o}{.}\PY{n}{add}\PY{p}{(}\PY{n}{Dropout}\PY{p}{(}\PY{p}{\PYZob{}}\PY{p}{\PYZob{}}\PY{n}{uniform}\PY{p}{(}\PY{l+m+mf}{0.5}\PY{p}{,}\PY{l+m+mf}{0.7}\PY{p}{)}\PY{p}{\PYZcb{}}\PY{p}{\PYZcb{}}\PY{p}{,}\PY{n}{name}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Dropout2\PYZus{}2}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}\PY{p}{)}
                \PY{c+c1}{\PYZsh{} Adding a dense output layer with sigmoid activation}
                \PY{n}{model}\PY{o}{.}\PY{n}{add}\PY{p}{(}\PY{n}{Dense}\PY{p}{(}\PY{l+m+mi}{6}\PY{p}{,} \PY{n}{activation}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{sigmoid}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}\PY{p}{)}
            \PY{k}{else}\PY{p}{:}
                \PY{c+c1}{\PYZsh{} Configuring the parameters}
                \PY{n}{model}\PY{o}{.}\PY{n}{add}\PY{p}{(}\PY{n}{LSTM}\PY{p}{(}\PY{p}{\PYZob{}}\PY{p}{\PYZob{}}\PY{n}{choice}\PY{p}{(}\PY{p}{[}\PY{l+m+mi}{28}\PY{p}{,}\PY{l+m+mi}{32}\PY{p}{,}\PY{l+m+mi}{36}\PY{p}{]}\PY{p}{)}\PY{p}{\PYZcb{}}\PY{p}{\PYZcb{}}\PY{p}{,}\PY{n}{recurrent\PYZus{}regularizer}\PY{o}{=}\PY{n}{l2}\PY{p}{(}\PY{p}{\PYZob{}}\PY{p}{\PYZob{}}\PY{n}{uniform}\PY{p}{(}\PY{l+m+mi}{0}\PY{p}{,}\PY{l+m+mf}{0.001}\PY{p}{)}\PY{p}{\PYZcb{}}\PY{p}{\PYZcb{}}\PY{p}{)}\PY{p}{,}\PY{n}{input\PYZus{}shape}\PY{o}{=}\PY{p}{(}\PY{l+m+mi}{128}\PY{p}{,} \PY{l+m+mi}{9}\PY{p}{)}\PY{p}{,}\PY{n}{name}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{LSTM1\PYZus{}1}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}\PY{p}{)}
                \PY{c+c1}{\PYZsh{} Adding a dropout layer}
                \PY{n}{model}\PY{o}{.}\PY{n}{add}\PY{p}{(}\PY{n}{Dropout}\PY{p}{(}\PY{p}{\PYZob{}}\PY{p}{\PYZob{}}\PY{n}{uniform}\PY{p}{(}\PY{l+m+mf}{0.35}\PY{p}{,}\PY{l+m+mf}{0.55}\PY{p}{)}\PY{p}{\PYZcb{}}\PY{p}{\PYZcb{}}\PY{p}{,}\PY{n}{name}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Dropout1\PYZus{}1}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}\PY{p}{)}
                \PY{c+c1}{\PYZsh{} Adding a dense output layer with sigmoid activation}
                \PY{n}{model}\PY{o}{.}\PY{n}{add}\PY{p}{(}\PY{n}{Dense}\PY{p}{(}\PY{l+m+mi}{6}\PY{p}{,} \PY{n}{activation}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{sigmoid}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}\PY{p}{)}
                
            \PY{n}{adam} \PY{o}{=} \PY{n}{keras}\PY{o}{.}\PY{n}{optimizers}\PY{o}{.}\PY{n}{Adam}\PY{p}{(}\PY{n}{lr}\PY{o}{=}\PY{p}{\PYZob{}}\PY{p}{\PYZob{}}\PY{n}{uniform}\PY{p}{(}\PY{l+m+mf}{0.009}\PY{p}{,}\PY{l+m+mf}{0.025}\PY{p}{)}\PY{p}{\PYZcb{}}\PY{p}{\PYZcb{}}\PY{p}{)}
            \PY{n}{rmsprop} \PY{o}{=} \PY{n}{keras}\PY{o}{.}\PY{n}{optimizers}\PY{o}{.}\PY{n}{RMSprop}\PY{p}{(}\PY{n}{lr}\PY{o}{=}\PY{p}{\PYZob{}}\PY{p}{\PYZob{}}\PY{n}{uniform}\PY{p}{(}\PY{l+m+mf}{0.009}\PY{p}{,}\PY{l+m+mf}{0.025}\PY{p}{)}\PY{p}{\PYZcb{}}\PY{p}{\PYZcb{}}\PY{p}{)}
           
            \PY{n}{choiceval} \PY{o}{=} \PY{p}{\PYZob{}}\PY{p}{\PYZob{}}\PY{n}{choice}\PY{p}{(}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{adam}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{rmsprop}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{)}\PY{p}{\PYZcb{}}\PY{p}{\PYZcb{}}
            
            \PY{k}{if} \PY{n}{choiceval} \PY{o}{==} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{adam}\PY{l+s+s1}{\PYZsq{}}\PY{p}{:}
                \PY{n}{optim} \PY{o}{=} \PY{n}{adam}
            \PY{k}{else}\PY{p}{:}
                \PY{n}{optim} \PY{o}{=} \PY{n}{rmsprop}
            
            \PY{n+nb}{print}\PY{p}{(}\PY{n}{model}\PY{o}{.}\PY{n}{summary}\PY{p}{(}\PY{p}{)}\PY{p}{)}
                
            \PY{n}{model}\PY{o}{.}\PY{n}{compile}\PY{p}{(}\PY{n}{loss}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{categorical\PYZus{}crossentropy}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{metrics}\PY{o}{=}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{accuracy}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{,}\PY{n}{optimizer}\PY{o}{=}\PY{n}{optim}\PY{p}{)}
            
            \PY{n}{result} \PY{o}{=} \PY{n}{model}\PY{o}{.}\PY{n}{fit}\PY{p}{(}\PY{n}{X\PYZus{}train}\PY{p}{,} \PY{n}{Y\PYZus{}train}\PY{p}{,}
                      \PY{n}{batch\PYZus{}size}\PY{o}{=}\PY{l+m+mi}{16}\PY{p}{,}
                      \PY{n}{nb\PYZus{}epoch}\PY{o}{=}\PY{l+m+mi}{30}\PY{p}{,}
                      \PY{n}{verbose}\PY{o}{=}\PY{l+m+mi}{2}\PY{p}{,}
                      \PY{n}{validation\PYZus{}data}\PY{o}{=}\PY{p}{(}\PY{n}{X\PYZus{}val}\PY{p}{,} \PY{n}{Y\PYZus{}val}\PY{p}{)}\PY{p}{)}
                               
            \PY{n}{score}\PY{p}{,} \PY{n}{acc} \PY{o}{=} \PY{n}{model}\PY{o}{.}\PY{n}{evaluate}\PY{p}{(}\PY{n}{X\PYZus{}val}\PY{p}{,} \PY{n}{Y\PYZus{}val}\PY{p}{,} \PY{n}{verbose}\PY{o}{=}\PY{l+m+mi}{0}\PY{p}{)}
            \PY{n+nb}{print}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Test accuracy:}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{acc}\PY{p}{)}
            \PY{n+nb}{print}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
            \PY{k}{return} \PY{p}{\PYZob{}}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{loss}\PY{l+s+s1}{\PYZsq{}}\PY{p}{:} \PY{o}{\PYZhy{}}\PY{n}{acc}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{status}\PY{l+s+s1}{\PYZsq{}}\PY{p}{:} \PY{n}{STATUS\PYZus{}OK}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{model}\PY{l+s+s1}{\PYZsq{}}\PY{p}{:} \PY{n}{model}\PY{p}{\PYZcb{}}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor} }]:} \PY{n}{X\PYZus{}train}\PY{p}{,} \PY{n}{Y\PYZus{}train}\PY{p}{,} \PY{n}{X\PYZus{}val}\PY{p}{,} \PY{n}{Y\PYZus{}val} \PY{o}{=} \PY{n}{data}\PY{p}{(}\PY{p}{)}
        \PY{n}{trials} \PY{o}{=} \PY{n}{Trials}\PY{p}{(}\PY{p}{)}
        \PY{n}{best\PYZus{}run}\PY{p}{,} \PY{n}{best\PYZus{}model}\PY{p}{,} \PY{n}{space} \PY{o}{=} \PY{n}{optim}\PY{o}{.}\PY{n}{minimize}\PY{p}{(}\PY{n}{model}\PY{o}{=}\PY{n}{model}\PY{p}{,}
                                              \PY{n}{data}\PY{o}{=}\PY{n}{data}\PY{p}{,}
                                              \PY{n}{algo}\PY{o}{=}\PY{n}{tpe}\PY{o}{.}\PY{n}{suggest}\PY{p}{,}
                                              \PY{n}{max\PYZus{}evals}\PY{o}{=}\PY{l+m+mi}{15}\PY{p}{,}
                                              \PY{n}{trials}\PY{o}{=}\PY{n}{trials}\PY{p}{,}\PY{n}{notebook\PYZus{}name} \PY{o}{=} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Human Activity Detection}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}
                                             \PY{n}{return\PYZus{}space} \PY{o}{=} \PY{k+kc}{True}\PY{p}{)}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}48}]:} \PY{n}{total\PYZus{}trials} \PY{o}{=} \PY{n+nb}{dict}\PY{p}{(}\PY{p}{)}
         \PY{k}{for} \PY{n}{t}\PY{p}{,} \PY{n}{trial} \PY{o+ow}{in} \PY{n+nb}{enumerate}\PY{p}{(}\PY{n}{trials}\PY{p}{)}\PY{p}{:}
                 \PY{n}{vals} \PY{o}{=} \PY{n}{trial}\PY{o}{.}\PY{n}{get}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{misc}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}\PY{o}{.}\PY{n}{get}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{vals}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
                 \PY{n+nb}{print}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Model}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}\PY{n}{t}\PY{o}{+}\PY{l+m+mi}{1}\PY{p}{,}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{parameters}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
                 \PY{n+nb}{print}\PY{p}{(}\PY{n}{vals}\PY{p}{)}
                 \PY{n+nb}{print}\PY{p}{(}\PY{p}{)}
                 \PY{n}{z} \PY{o}{=} \PY{n}{eval\PYZus{}hyperopt\PYZus{}space}\PY{p}{(}\PY{n}{space}\PY{p}{,} \PY{n}{vals}\PY{p}{)}
                 \PY{n}{total\PYZus{}trials}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{M}\PY{l+s+s1}{\PYZsq{}}\PY{o}{+}\PY{n+nb}{str}\PY{p}{(}\PY{n}{t}\PY{o}{+}\PY{l+m+mi}{1}\PY{p}{)}\PY{p}{]} \PY{o}{=} \PY{n}{z}
                 \PY{n+nb}{print}\PY{p}{(}\PY{n}{z}\PY{p}{)}
                 \PY{n+nb}{print}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
Model 1 parameters
\{'Dropout': [0.36598023572757926], 'Dropout\_1': [0.6047146037530785], 'Dropout\_2': [0.5188826519950874], 'LSTM': [0], 'LSTM\_1': [1], 'LSTM\_2': [1], 'choiceval': [1], 'conditional': [0], 'l2': [0.00016900597529479822], 'l2\_1': [0.0006108763092812357], 'l2\_2': [0.0007371698374615214], 'lr': [0.01942874904782045], 'lr\_1': [0.015993860150909475]\}

\{'Dropout': 0.36598023572757926, 'Dropout\_1': 0.6047146037530785, 'Dropout\_2': 0.5188826519950874, 'LSTM': 28, 'LSTM\_1': 32, 'LSTM\_2': 32, 'choiceval': 'rmsprop', 'conditional': 'one', 'l2': 0.00016900597529479822, 'l2\_1': 0.0006108763092812357, 'l2\_2': 0.0007371698374615214, 'lr': 0.01942874904782045, 'lr\_1': 0.015993860150909475\}
------------------------------------------------
Model 2 parameters
\{'Dropout': [0.604072168386432], 'Dropout\_1': [0.5642077861572957], 'Dropout\_2': [0.4689742513688654], 'LSTM': [0], 'LSTM\_1': [1], 'LSTM\_2': [0], 'choiceval': [1], 'conditional': [1], 'l2': [2.221286943616341e-06], 'l2\_1': [0.0009770005173795487], 'l2\_2': [0.0008366666847115819], 'lr': [0.023605271151689124], 'lr\_1': [0.015140941766877332]\}

\{'Dropout': 0.604072168386432, 'Dropout\_1': 0.5642077861572957, 'Dropout\_2': 0.4689742513688654, 'LSTM': 28, 'LSTM\_1': 32, 'LSTM\_2': 28, 'choiceval': 'rmsprop', 'conditional': 'two', 'l2': 2.221286943616341e-06, 'l2\_1': 0.0009770005173795487, 'l2\_2': 0.0008366666847115819, 'lr': 0.023605271151689124, 'lr\_1': 0.015140941766877332\}
------------------------------------------------
Model 3 parameters
\{'Dropout': [0.649118836907314], 'Dropout\_1': [0.6408661828169875], 'Dropout\_2': [0.5025116318997556], 'LSTM': [2], 'LSTM\_1': [2], 'LSTM\_2': [1], 'choiceval': [1], 'conditional': [1], 'l2': [0.00011247630115130428], 'l2\_1': [0.0003949936266626689], 'l2\_2': [0.0009758185183456943], 'lr': [0.013618600574440736], 'lr\_1': [0.014402022095061829]\}

\{'Dropout': 0.649118836907314, 'Dropout\_1': 0.6408661828169875, 'Dropout\_2': 0.5025116318997556, 'LSTM': 38, 'LSTM\_1': 36, 'LSTM\_2': 32, 'choiceval': 'rmsprop', 'conditional': 'two', 'l2': 0.00011247630115130428, 'l2\_1': 0.0003949936266626689, 'l2\_2': 0.0009758185183456943, 'lr': 0.013618600574440736, 'lr\_1': 0.014402022095061829\}
------------------------------------------------
Model 4 parameters
\{'Dropout': [0.5709919477993022], 'Dropout\_1': [0.6574295784428639], 'Dropout\_2': [0.39377498664819843], 'LSTM': [1], 'LSTM\_1': [1], 'LSTM\_2': [2], 'choiceval': [0], 'conditional': [1], 'l2': [0.00019824027740992625], 'l2\_1': [0.0007646166765488501], 'l2\_2': [0.00041266207281071243], 'lr': [0.01675112837971219], 'lr\_1': [0.009417276849790152]\}

\{'Dropout': 0.5709919477993022, 'Dropout\_1': 0.6574295784428639, 'Dropout\_2': 0.39377498664819843, 'LSTM': 32, 'LSTM\_1': 32, 'LSTM\_2': 36, 'choiceval': 'adam', 'conditional': 'two', 'l2': 0.00019824027740992625, 'l2\_1': 0.0007646166765488501, 'l2\_2': 0.00041266207281071243, 'lr': 0.01675112837971219, 'lr\_1': 0.009417276849790152\}
------------------------------------------------
Model 5 parameters
\{'Dropout': [0.48051787644406624], 'Dropout\_1': [0.5744163772727372], 'Dropout\_2': [0.5086629864785656], 'LSTM': [1], 'LSTM\_1': [1], 'LSTM\_2': [0], 'choiceval': [0], 'conditional': [1], 'l2': [2.749908849077252e-05], 'l2\_1': [0.000587606728324542], 'l2\_2': [0.0003746350041674067], 'lr': [0.01834130504525777], 'lr\_1': [0.0229410270349058]\}

\{'Dropout': 0.48051787644406624, 'Dropout\_1': 0.5744163772727372, 'Dropout\_2': 0.5086629864785656, 'LSTM': 32, 'LSTM\_1': 32, 'LSTM\_2': 28, 'choiceval': 'adam', 'conditional': 'two', 'l2': 2.749908849077252e-05, 'l2\_1': 0.000587606728324542, 'l2\_2': 0.0003746350041674067, 'lr': 0.01834130504525777, 'lr\_1': 0.0229410270349058\}
------------------------------------------------
Model 6 parameters
\{'Dropout': [0.5813560517914963], 'Dropout\_1': [0.6046109124722276], 'Dropout\_2': [0.5355832635290444], 'LSTM': [0], 'LSTM\_1': [1], 'LSTM\_2': [2], 'choiceval': [1], 'conditional': [1], 'l2': [1.612769130873457e-05], 'l2\_1': [0.0009772817488940724], 'l2\_2': [0.0006883693507416478], 'lr': [0.017446396677831936], 'lr\_1': [0.015805655140931824]\}

\{'Dropout': 0.5813560517914963, 'Dropout\_1': 0.6046109124722276, 'Dropout\_2': 0.5355832635290444, 'LSTM': 28, 'LSTM\_1': 32, 'LSTM\_2': 36, 'choiceval': 'rmsprop', 'conditional': 'two', 'l2': 1.612769130873457e-05, 'l2\_1': 0.0009772817488940724, 'l2\_2': 0.0006883693507416478, 'lr': 0.017446396677831936, 'lr\_1': 0.015805655140931824\}
------------------------------------------------
Model 7 parameters
\{'Dropout': [0.5293597400197904], 'Dropout\_1': [0.5958807193410454], 'Dropout\_2': [0.42617520692074906], 'LSTM': [2], 'LSTM\_1': [1], 'LSTM\_2': [2], 'choiceval': [0], 'conditional': [1], 'l2': [4.567626225804864e-05], 'l2\_1': [0.0005422412690636627], 'l2\_2': [0.00033351393608141357], 'lr': [0.01068491666284852], 'lr\_1': [0.01643494651558678]\}

\{'Dropout': 0.5293597400197904, 'Dropout\_1': 0.5958807193410454, 'Dropout\_2': 0.42617520692074906, 'LSTM': 38, 'LSTM\_1': 32, 'LSTM\_2': 36, 'choiceval': 'adam', 'conditional': 'two', 'l2': 4.567626225804864e-05, 'l2\_1': 0.0005422412690636627, 'l2\_2': 0.00033351393608141357, 'lr': 0.01068491666284852, 'lr\_1': 0.01643494651558678\}
------------------------------------------------
Model 8 parameters
\{'Dropout': [0.5950749367948185], 'Dropout\_1': [0.5997621117444732], 'Dropout\_2': [0.4999621572265873], 'LSTM': [1], 'LSTM\_1': [0], 'LSTM\_2': [1], 'choiceval': [0], 'conditional': [1], 'l2': [5.865420439323175e-05], 'l2\_1': [0.0007302305870589934], 'l2\_2': [0.000258985915829989], 'lr': [0.010314137826059229], 'lr\_1': [0.009310543992889801]\}

\{'Dropout': 0.5950749367948185, 'Dropout\_1': 0.5997621117444732, 'Dropout\_2': 0.4999621572265873, 'LSTM': 32, 'LSTM\_1': 26, 'LSTM\_2': 32, 'choiceval': 'adam', 'conditional': 'two', 'l2': 5.865420439323175e-05, 'l2\_1': 0.0007302305870589934, 'l2\_2': 0.000258985915829989, 'lr': 0.010314137826059229, 'lr\_1': 0.009310543992889801\}
------------------------------------------------
Model 9 parameters
\{'Dropout': [0.45037579382108217], 'Dropout\_1': [0.6781762554752515], 'Dropout\_2': [0.4794831735512747], 'LSTM': [1], 'LSTM\_1': [1], 'LSTM\_2': [0], 'choiceval': [1], 'conditional': [0], 'l2': [5.201497156118029e-05], 'l2\_1': [0.0006257491042113806], 'l2\_2': [0.0004437546321946204], 'lr': [0.023536039320918772], 'lr\_1': [0.012611516495429879]\}

\{'Dropout': 0.45037579382108217, 'Dropout\_1': 0.6781762554752515, 'Dropout\_2': 0.4794831735512747, 'LSTM': 32, 'LSTM\_1': 32, 'LSTM\_2': 28, 'choiceval': 'rmsprop', 'conditional': 'one', 'l2': 5.201497156118029e-05, 'l2\_1': 0.0006257491042113806, 'l2\_2': 0.0004437546321946204, 'lr': 0.023536039320918772, 'lr\_1': 0.012611516495429879\}
------------------------------------------------
Model 10 parameters
\{'Dropout': [0.45714950357785966], 'Dropout\_1': [0.6894085538291769], 'Dropout\_2': [0.45216713875784914], 'LSTM': [0], 'LSTM\_1': [1], 'LSTM\_2': [0], 'choiceval': [1], 'conditional': [0], 'l2': [7.681307310729229e-05], 'l2\_1': [0.0004143619965361732], 'l2\_2': [9.225974322037534e-05], 'lr': [0.01235075833910319], 'lr\_1': [0.018058999803996133]\}

\{'Dropout': 0.45714950357785966, 'Dropout\_1': 0.6894085538291769, 'Dropout\_2': 0.45216713875784914, 'LSTM': 28, 'LSTM\_1': 32, 'LSTM\_2': 28, 'choiceval': 'rmsprop', 'conditional': 'one', 'l2': 7.681307310729229e-05, 'l2\_1': 0.0004143619965361732, 'l2\_2': 9.225974322037534e-05, 'lr': 0.01235075833910319, 'lr\_1': 0.018058999803996133\}
------------------------------------------------
Model 11 parameters
\{'Dropout': [0.5808002757682877], 'Dropout\_1': [0.660514929179723], 'Dropout\_2': [0.4733734305745834], 'LSTM': [1], 'LSTM\_1': [0], 'LSTM\_2': [1], 'choiceval': [1], 'conditional': [0], 'l2': [0.0001195365208222095], 'l2\_1': [0.0001849314123467004], 'l2\_2': [0.0005106207029550342], 'lr': [0.013696392786995321], 'lr\_1': [0.009420957669947726]\}

\{'Dropout': 0.5808002757682877, 'Dropout\_1': 0.660514929179723, 'Dropout\_2': 0.4733734305745834, 'LSTM': 32, 'LSTM\_1': 26, 'LSTM\_2': 32, 'choiceval': 'rmsprop', 'conditional': 'one', 'l2': 0.0001195365208222095, 'l2\_1': 0.0001849314123467004, 'l2\_2': 0.0005106207029550342, 'lr': 0.013696392786995321, 'lr\_1': 0.009420957669947726\}
------------------------------------------------
Model 12 parameters
\{'Dropout': [0.5666044972741778], 'Dropout\_1': [0.5837804766498599], 'Dropout\_2': [0.38708976069745693], 'LSTM': [1], 'LSTM\_1': [2], 'LSTM\_2': [2], 'choiceval': [0], 'conditional': [0], 'l2': [6.379888690521487e-05], 'l2\_1': [0.00013256157391301627], 'l2\_2': [0.0009457487322332761], 'lr': [0.021003723896153827], 'lr\_1': [0.014111778261744532]\}

\{'Dropout': 0.5666044972741778, 'Dropout\_1': 0.5837804766498599, 'Dropout\_2': 0.38708976069745693, 'LSTM': 32, 'LSTM\_1': 36, 'LSTM\_2': 36, 'choiceval': 'adam', 'conditional': 'one', 'l2': 6.379888690521487e-05, 'l2\_1': 0.00013256157391301627, 'l2\_2': 0.0009457487322332761, 'lr': 0.021003723896153827, 'lr\_1': 0.014111778261744532\}
------------------------------------------------
Model 13 parameters
\{'Dropout': [0.47945603666694214], 'Dropout\_1': [0.6410658485741121], 'Dropout\_2': [0.431428962525653], 'LSTM': [2], 'LSTM\_1': [1], 'LSTM\_2': [2], 'choiceval': [1], 'conditional': [1], 'l2': [0.00018573736431464218], 'l2\_1': [0.0009992918522039433], 'l2\_2': [0.000376241262719619], 'lr': [0.02028522715636994], 'lr\_1': [0.02075108210315991]\}

\{'Dropout': 0.47945603666694214, 'Dropout\_1': 0.6410658485741121, 'Dropout\_2': 0.431428962525653, 'LSTM': 38, 'LSTM\_1': 32, 'LSTM\_2': 36, 'choiceval': 'rmsprop', 'conditional': 'two', 'l2': 0.00018573736431464218, 'l2\_1': 0.0009992918522039433, 'l2\_2': 0.000376241262719619, 'lr': 0.02028522715636994, 'lr\_1': 0.02075108210315991\}
------------------------------------------------
Model 14 parameters
\{'Dropout': [0.3802031741395868], 'Dropout\_1': [0.6903389204823146], 'Dropout\_2': [0.3654341425327902], 'LSTM': [2], 'LSTM\_1': [2], 'LSTM\_2': [1], 'choiceval': [0], 'conditional': [0], 'l2': [0.00015208023802140732], 'l2\_1': [0.000643128044948208], 'l2\_2': [0.0007102309264917989], 'lr': [0.016347608866364167], 'lr\_1': [0.024543333891182614]\}

\{'Dropout': 0.3802031741395868, 'Dropout\_1': 0.6903389204823146, 'Dropout\_2': 0.3654341425327902, 'LSTM': 38, 'LSTM\_1': 36, 'LSTM\_2': 32, 'choiceval': 'adam', 'conditional': 'one', 'l2': 0.00015208023802140732, 'l2\_1': 0.000643128044948208, 'l2\_2': 0.0007102309264917989, 'lr': 0.016347608866364167, 'lr\_1': 0.024543333891182614\}
------------------------------------------------
Model 15 parameters
\{'Dropout': [0.578227610775208], 'Dropout\_1': [0.6959943282933752], 'Dropout\_2': [0.4519332465495095], 'LSTM': [1], 'LSTM\_1': [1], 'LSTM\_2': [1], 'choiceval': [0], 'conditional': [1], 'l2': [9.909767403125834e-05], 'l2\_1': [0.0004671776323322324], 'l2\_2': [0.0008869747685138522], 'lr': [0.010099240007717829], 'lr\_1': [0.024293576282946767]\}

\{'Dropout': 0.578227610775208, 'Dropout\_1': 0.6959943282933752, 'Dropout\_2': 0.4519332465495095, 'LSTM': 32, 'LSTM\_1': 32, 'LSTM\_2': 32, 'choiceval': 'adam', 'conditional': 'two', 'l2': 9.909767403125834e-05, 'l2\_1': 0.0004671776323322324, 'l2\_2': 0.0008869747685138522, 'lr': 0.010099240007717829, 'lr\_1': 0.024293576282946767\}
------------------------------------------------

    \end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}54}]:} \PY{n}{best\PYZus{}run}
\end{Verbatim}


\begin{Verbatim}[commandchars=\\\{\}]
{\color{outcolor}Out[{\color{outcolor}54}]:} \{'Dropout': 0.3802031741395868,
          'Dropout\_1': 0.6903389204823146,
          'Dropout\_2': 0.3654341425327902,
          'LSTM': 2,
          'LSTM\_1': 2,
          'LSTM\_2': 1,
          'choiceval': 0,
          'conditional': 0,
          'l2': 0.00015208023802140732,
          'l2\_1': 0.000643128044948208,
          'l2\_2': 0.0007102309264917989,
          'lr': 0.016347608866364167,
          'lr\_1': 0.024543333891182614\}
\end{Verbatim}
            
    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}55}]:} \PY{c+c1}{\PYZsh{}BEST MODEL PARAMS}
         \PY{n}{total\PYZus{}trials}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{M14}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}
\end{Verbatim}


\begin{Verbatim}[commandchars=\\\{\}]
{\color{outcolor}Out[{\color{outcolor}55}]:} \{'Dropout': 0.3802031741395868,
          'Dropout\_1': 0.6903389204823146,
          'Dropout\_2': 0.3654341425327902,
          'LSTM': 38,
          'LSTM\_1': 36,
          'LSTM\_2': 32,
          'choiceval': 'adam',
          'conditional': 'one',
          'l2': 0.00015208023802140732,
          'l2\_1': 0.000643128044948208,
          'l2\_2': 0.0007102309264917989,
          'lr': 0.016347608866364167,
          'lr\_1': 0.024543333891182614\}
\end{Verbatim}
            
    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}50}]:} \PY{c+c1}{\PYZsh{}layes of best model}
         \PY{n}{best\PYZus{}model}\PY{o}{.}\PY{n}{layers}
\end{Verbatim}


\begin{Verbatim}[commandchars=\\\{\}]
{\color{outcolor}Out[{\color{outcolor}50}]:} [<keras.layers.recurrent.LSTM at 0x146c379d2ac8>,
          <keras.layers.core.Dropout at 0x146c379d2cc0>,
          <keras.layers.core.Dense at 0x146c379d2a90>]
\end{Verbatim}
            
    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}51}]:} \PY{n}{X\PYZus{}train}\PY{p}{,} \PY{n}{Y\PYZus{}train}\PY{p}{,} \PY{n}{X\PYZus{}val}\PY{p}{,} \PY{n}{Y\PYZus{}val} \PY{o}{=} \PY{n}{data}\PY{p}{(}\PY{p}{)}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}56}]:} \PY{n}{\PYZus{}}\PY{p}{,}\PY{n}{val\PYZus{}acc} \PY{o}{=} \PY{n}{best\PYZus{}model}\PY{o}{.}\PY{n}{evaluate}\PY{p}{(}\PY{n}{X\PYZus{}val}\PY{p}{,} \PY{n}{Y\PYZus{}val}\PY{p}{,} \PY{n}{verbose}\PY{o}{=}\PY{l+m+mi}{0}\PY{p}{)}
         \PY{n}{\PYZus{}}\PY{p}{,}\PY{n}{train\PYZus{}acc} \PY{o}{=} \PY{n}{best\PYZus{}model}\PY{o}{.}\PY{n}{evaluate}\PY{p}{(}\PY{n}{X\PYZus{}train}\PY{p}{,} \PY{n}{Y\PYZus{}train}\PY{p}{,} \PY{n}{verbose}\PY{o}{=}\PY{l+m+mi}{0}\PY{p}{)}
         \PY{n+nb}{print}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Train\PYZus{}accuracy}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}\PY{n}{val\PYZus{}acc}\PY{p}{)}
         \PY{n+nb}{print}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{validation accuracy}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}\PY{n}{val\PYZus{}acc}\PY{p}{)}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
Train\_accuracy 0.94560663764961915
validation accuracy 0.9199185612487275

    \end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}15}]:} \PY{c+c1}{\PYZsh{} Activities are the class labels}
         \PY{c+c1}{\PYZsh{} It is a 6 class classification}
         \PY{n}{ACTIVITIES} \PY{o}{=} \PY{p}{\PYZob{}}
             \PY{l+m+mi}{0}\PY{p}{:} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{WALKING}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}
             \PY{l+m+mi}{1}\PY{p}{:} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{WALKING\PYZus{}UPSTAIRS}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}
             \PY{l+m+mi}{2}\PY{p}{:} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{WALKING\PYZus{}DOWNSTAIRS}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}
             \PY{l+m+mi}{3}\PY{p}{:} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{SITTING}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}
             \PY{l+m+mi}{4}\PY{p}{:} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{STANDING}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}
             \PY{l+m+mi}{5}\PY{p}{:} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{LAYING}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}
         \PY{p}{\PYZcb{}}
         
         \PY{c+c1}{\PYZsh{} Utility function to print the confusion matrix}
         \PY{k}{def} \PY{n+nf}{confusion\PYZus{}matrix\PYZus{}rnn}\PY{p}{(}\PY{n}{Y\PYZus{}true}\PY{p}{,} \PY{n}{Y\PYZus{}pred}\PY{p}{)}\PY{p}{:}
             \PY{n}{Y\PYZus{}true} \PY{o}{=} \PY{n}{pd}\PY{o}{.}\PY{n}{Series}\PY{p}{(}\PY{p}{[}\PY{n}{ACTIVITIES}\PY{p}{[}\PY{n}{y}\PY{p}{]} \PY{k}{for} \PY{n}{y} \PY{o+ow}{in} \PY{n}{np}\PY{o}{.}\PY{n}{argmax}\PY{p}{(}\PY{n}{Y\PYZus{}true}\PY{p}{,} \PY{n}{axis}\PY{o}{=}\PY{l+m+mi}{1}\PY{p}{)}\PY{p}{]}\PY{p}{)}
             \PY{n}{Y\PYZus{}pred} \PY{o}{=} \PY{n}{pd}\PY{o}{.}\PY{n}{Series}\PY{p}{(}\PY{p}{[}\PY{n}{ACTIVITIES}\PY{p}{[}\PY{n}{y}\PY{p}{]} \PY{k}{for} \PY{n}{y} \PY{o+ow}{in} \PY{n}{np}\PY{o}{.}\PY{n}{argmax}\PY{p}{(}\PY{n}{Y\PYZus{}pred}\PY{p}{,} \PY{n}{axis}\PY{o}{=}\PY{l+m+mi}{1}\PY{p}{)}\PY{p}{]}\PY{p}{)}
         
             \PY{c+c1}{\PYZsh{}return pd.crosstab(Y\PYZus{}true, Y\PYZus{}pred, rownames=[\PYZsq{}True\PYZsq{}], colnames=[\PYZsq{}Pred\PYZsq{}])}
             \PY{k}{return} \PY{n}{metrics}\PY{o}{.}\PY{n}{confusion\PYZus{}matrix}\PY{p}{(}\PY{n}{Y\PYZus{}true}\PY{p}{,} \PY{n}{Y\PYZus{}pred}\PY{p}{)}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}74}]:} \PY{c+c1}{\PYZsh{} Confusion Matrix}
         \PY{n+nb}{print}\PY{p}{(}\PY{n}{confusion\PYZus{}matrix\PYZus{}rnn}\PY{p}{(}\PY{n}{Y\PYZus{}val}\PY{p}{,} \PY{n}{best\PYZus{}model}\PY{o}{.}\PY{n}{predict}\PY{p}{(}\PY{n}{X\PYZus{}val}\PY{p}{)}\PY{p}{)}\PY{p}{)}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
[[537   0   0   0   0   0]
 [  1 412  75   0   0   3]
 [  0  88 444   0   0   0]
 [  0   0   0 464  10  22]
 [  0   0   0  15 390  15]
 [  0   4   0   2   1 464]]

    \end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}16}]:} \PY{k+kn}{from} \PY{n+nn}{sklearn} \PY{k}{import} \PY{n}{metrics}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}80}]:} \PY{n}{plt}\PY{o}{.}\PY{n}{figure}\PY{p}{(}\PY{n}{figsize}\PY{o}{=}\PY{p}{(}\PY{l+m+mi}{8}\PY{p}{,}\PY{l+m+mi}{8}\PY{p}{)}\PY{p}{)}
         \PY{n}{cm} \PY{o}{=} \PY{n}{confusion\PYZus{}matrix\PYZus{}rnn}\PY{p}{(}\PY{n}{Y\PYZus{}val}\PY{p}{,} \PY{n}{best\PYZus{}model}\PY{o}{.}\PY{n}{predict}\PY{p}{(}\PY{n}{X\PYZus{}val}\PY{p}{)}\PY{p}{)}
         \PY{n}{plot\PYZus{}confusion\PYZus{}matrix}\PY{p}{(}\PY{n}{cm}\PY{p}{,} \PY{n}{classes}\PY{o}{=}\PY{n}{labels}\PY{p}{,} \PY{n}{normalize}\PY{o}{=}\PY{k+kc}{True}\PY{p}{,} \PY{n}{title}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Normalized confusion matrix}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{cmap} \PY{o}{=} \PY{n}{plt}\PY{o}{.}\PY{n}{cm}\PY{o}{.}\PY{n}{Greens}\PY{p}{)}
         \PY{n}{plt}\PY{o}{.}\PY{n}{show}\PY{p}{(}\PY{p}{)}
\end{Verbatim}


    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{output_135_0.png}
    \end{center}
    { \hspace*{\fill} \\}
    
    \subsection{Using CNN}\label{using-cnn}

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}2}]:} \PY{k+kn}{import} \PY{n+nn}{os}
        \PY{n}{os}\PY{o}{.}\PY{n}{environ}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{PYTHONHASHSEED}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]} \PY{o}{=} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{0}\PY{l+s+s1}{\PYZsq{}}
        \PY{k+kn}{import} \PY{n+nn}{numpy} \PY{k}{as} \PY{n+nn}{np}
        \PY{k+kn}{import} \PY{n+nn}{tensorflow} \PY{k}{as} \PY{n+nn}{tf}
        \PY{k+kn}{import} \PY{n+nn}{random} \PY{k}{as} \PY{n+nn}{rn}
        \PY{n}{np}\PY{o}{.}\PY{n}{random}\PY{o}{.}\PY{n}{seed}\PY{p}{(}\PY{l+m+mi}{36}\PY{p}{)}
        \PY{n}{rn}\PY{o}{.}\PY{n}{seed}\PY{p}{(}\PY{l+m+mi}{36}\PY{p}{)}
        \PY{n}{tf}\PY{o}{.}\PY{n}{set\PYZus{}random\PYZus{}seed}\PY{p}{(}\PY{l+m+mi}{36}\PY{p}{)}
        \PY{c+c1}{\PYZsh{} Force TensorFlow to use single thread.}
        \PY{c+c1}{\PYZsh{} Multiple threads are a potential source of non\PYZhy{}reproducible results.}
        \PY{c+c1}{\PYZsh{} For further details, see: https://stackoverflow.com/questions/42022950/}
        \PY{n}{session\PYZus{}conf} \PY{o}{=} \PY{n}{tf}\PY{o}{.}\PY{n}{ConfigProto}\PY{p}{(}\PY{n}{intra\PYZus{}op\PYZus{}parallelism\PYZus{}threads}\PY{o}{=}\PY{l+m+mi}{1}\PY{p}{,}
                                      \PY{n}{inter\PYZus{}op\PYZus{}parallelism\PYZus{}threads}\PY{o}{=}\PY{l+m+mi}{1}\PY{p}{)}
        
        \PY{k+kn}{from} \PY{n+nn}{keras} \PY{k}{import} \PY{n}{backend} \PY{k}{as} \PY{n}{K}
        
        \PY{c+c1}{\PYZsh{} The below tf.set\PYZus{}random\PYZus{}seed() will make random number generation}
        \PY{c+c1}{\PYZsh{} in the TensorFlow backend have a well\PYZhy{}defined initial state.}
        \PY{c+c1}{\PYZsh{} For further details, see:}
        \PY{c+c1}{\PYZsh{} https://www.tensorflow.org/api\PYZus{}docs/python/tf/set\PYZus{}random\PYZus{}seed}
        
        \PY{n}{tf}\PY{o}{.}\PY{n}{set\PYZus{}random\PYZus{}seed}\PY{p}{(}\PY{l+m+mi}{36}\PY{p}{)}
        
        \PY{n}{sess} \PY{o}{=} \PY{n}{tf}\PY{o}{.}\PY{n}{Session}\PY{p}{(}\PY{n}{graph}\PY{o}{=}\PY{n}{tf}\PY{o}{.}\PY{n}{get\PYZus{}default\PYZus{}graph}\PY{p}{(}\PY{p}{)}\PY{p}{,} \PY{n}{config}\PY{o}{=}\PY{n}{session\PYZus{}conf}\PY{p}{)}
        \PY{n}{K}\PY{o}{.}\PY{n}{set\PYZus{}session}\PY{p}{(}\PY{n}{sess}\PY{p}{)}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
Using TensorFlow backend.

    \end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}3}]:} \PY{c+c1}{\PYZsh{} Importing libraries}
        \PY{k+kn}{import} \PY{n+nn}{pandas} \PY{k}{as} \PY{n+nn}{pd}
        \PY{k+kn}{from} \PY{n+nn}{matplotlib} \PY{k}{import} \PY{n}{pyplot}
        \PY{k+kn}{from} \PY{n+nn}{sklearn}\PY{n+nn}{.}\PY{n+nn}{preprocessing} \PY{k}{import} \PY{n}{StandardScaler}
        \PY{k+kn}{from} \PY{n+nn}{keras}\PY{n+nn}{.}\PY{n+nn}{models} \PY{k}{import} \PY{n}{Sequential}
        \PY{k+kn}{from} \PY{n+nn}{keras}\PY{n+nn}{.}\PY{n+nn}{layers} \PY{k}{import} \PY{n}{Dense}
        \PY{k+kn}{from} \PY{n+nn}{keras}\PY{n+nn}{.}\PY{n+nn}{layers} \PY{k}{import} \PY{n}{Flatten}
        \PY{k+kn}{from} \PY{n+nn}{keras}\PY{n+nn}{.}\PY{n+nn}{layers} \PY{k}{import} \PY{n}{Dropout}
        \PY{k+kn}{from} \PY{n+nn}{keras}\PY{n+nn}{.}\PY{n+nn}{layers}\PY{n+nn}{.}\PY{n+nn}{convolutional} \PY{k}{import} \PY{n}{Conv1D}
        \PY{k+kn}{from} \PY{n+nn}{keras}\PY{n+nn}{.}\PY{n+nn}{layers}\PY{n+nn}{.}\PY{n+nn}{convolutional} \PY{k}{import} \PY{n}{MaxPooling1D}
        \PY{k+kn}{from} \PY{n+nn}{keras}\PY{n+nn}{.}\PY{n+nn}{utils} \PY{k}{import} \PY{n}{to\PYZus{}categorical}
        \PY{k+kn}{from} \PY{n+nn}{keras}\PY{n+nn}{.}\PY{n+nn}{models} \PY{k}{import} \PY{n}{Sequential}
        \PY{k+kn}{from} \PY{n+nn}{keras}\PY{n+nn}{.}\PY{n+nn}{layers} \PY{k}{import} \PY{n}{LSTM}
        \PY{k+kn}{from} \PY{n+nn}{keras}\PY{n+nn}{.}\PY{n+nn}{layers}\PY{n+nn}{.}\PY{n+nn}{core} \PY{k}{import} \PY{n}{Dense}\PY{p}{,} \PY{n}{Dropout}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}18}]:} \PY{n}{X\PYZus{}train}\PY{p}{,} \PY{n}{Y\PYZus{}train}\PY{p}{,} \PY{n}{X\PYZus{}val}\PY{p}{,} \PY{n}{Y\PYZus{}val} \PY{o}{=} \PY{n}{data}\PY{p}{(}\PY{p}{)}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}19}]:} \PY{c+c1}{\PYZsh{}\PYZsh{}\PYZsh{}Scling data}
         \PY{k+kn}{from} \PY{n+nn}{sklearn}\PY{n+nn}{.}\PY{n+nn}{base} \PY{k}{import} \PY{n}{BaseEstimator}\PY{p}{,} \PY{n}{TransformerMixin}
         \PY{k}{class} \PY{n+nc}{scaling\PYZus{}tseries\PYZus{}data}\PY{p}{(}\PY{n}{BaseEstimator}\PY{p}{,} \PY{n}{TransformerMixin}\PY{p}{)}\PY{p}{:}
             \PY{k+kn}{from} \PY{n+nn}{sklearn}\PY{n+nn}{.}\PY{n+nn}{preprocessing} \PY{k}{import} \PY{n}{StandardScaler}
             \PY{k}{def} \PY{n+nf}{\PYZus{}\PYZus{}init\PYZus{}\PYZus{}}\PY{p}{(}\PY{n+nb+bp}{self}\PY{p}{)}\PY{p}{:}
                 \PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{scale} \PY{o}{=} \PY{k+kc}{None}
         
             \PY{k}{def} \PY{n+nf}{transform}\PY{p}{(}\PY{n+nb+bp}{self}\PY{p}{,} \PY{n}{X}\PY{p}{)}\PY{p}{:}
                 \PY{n}{temp\PYZus{}X1} \PY{o}{=} \PY{n}{X}\PY{o}{.}\PY{n}{reshape}\PY{p}{(}\PY{p}{(}\PY{n}{X}\PY{o}{.}\PY{n}{shape}\PY{p}{[}\PY{l+m+mi}{0}\PY{p}{]} \PY{o}{*} \PY{n}{X}\PY{o}{.}\PY{n}{shape}\PY{p}{[}\PY{l+m+mi}{1}\PY{p}{]}\PY{p}{,} \PY{n}{X}\PY{o}{.}\PY{n}{shape}\PY{p}{[}\PY{l+m+mi}{2}\PY{p}{]}\PY{p}{)}\PY{p}{)}
                 \PY{n}{temp\PYZus{}X1} \PY{o}{=} \PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{scale}\PY{o}{.}\PY{n}{transform}\PY{p}{(}\PY{n}{temp\PYZus{}X1}\PY{p}{)}
                 \PY{k}{return} \PY{n}{temp\PYZus{}X1}\PY{o}{.}\PY{n}{reshape}\PY{p}{(}\PY{n}{X}\PY{o}{.}\PY{n}{shape}\PY{p}{)}
         
             \PY{k}{def} \PY{n+nf}{fit}\PY{p}{(}\PY{n+nb+bp}{self}\PY{p}{,} \PY{n}{X}\PY{p}{)}\PY{p}{:}
                 \PY{c+c1}{\PYZsh{} remove overlaping}
                 \PY{n}{remove} \PY{o}{=} \PY{n+nb}{int}\PY{p}{(}\PY{n}{X}\PY{o}{.}\PY{n}{shape}\PY{p}{[}\PY{l+m+mi}{1}\PY{p}{]} \PY{o}{/} \PY{l+m+mi}{2}\PY{p}{)}
                 \PY{n}{temp\PYZus{}X} \PY{o}{=} \PY{n}{X}\PY{p}{[}\PY{p}{:}\PY{p}{,} \PY{o}{\PYZhy{}}\PY{n}{remove}\PY{p}{:}\PY{p}{,} \PY{p}{:}\PY{p}{]}
                 \PY{c+c1}{\PYZsh{} flatten data}
                 \PY{n}{temp\PYZus{}X} \PY{o}{=} \PY{n}{temp\PYZus{}X}\PY{o}{.}\PY{n}{reshape}\PY{p}{(}\PY{p}{(}\PY{n}{temp\PYZus{}X}\PY{o}{.}\PY{n}{shape}\PY{p}{[}\PY{l+m+mi}{0}\PY{p}{]} \PY{o}{*} \PY{n}{temp\PYZus{}X}\PY{o}{.}\PY{n}{shape}\PY{p}{[}\PY{l+m+mi}{1}\PY{p}{]}\PY{p}{,} \PY{n}{temp\PYZus{}X}\PY{o}{.}\PY{n}{shape}\PY{p}{[}\PY{l+m+mi}{2}\PY{p}{]}\PY{p}{)}\PY{p}{)}
                 \PY{n}{scale} \PY{o}{=} \PY{n}{StandardScaler}\PY{p}{(}\PY{p}{)}
                 \PY{n}{scale}\PY{o}{.}\PY{n}{fit}\PY{p}{(}\PY{n}{temp\PYZus{}X}\PY{p}{)}
                 \PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{scale} \PY{o}{=} \PY{n}{scale}
                 \PY{k}{return} \PY{n+nb+bp}{self}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}20}]:} \PY{n}{Scale} \PY{o}{=} \PY{n}{scaling\PYZus{}tseries\PYZus{}data}\PY{p}{(}\PY{p}{)}
         \PY{n}{Scale}\PY{o}{.}\PY{n}{fit}\PY{p}{(}\PY{n}{X\PYZus{}train}\PY{p}{)}
         \PY{n}{X\PYZus{}train\PYZus{}sc} \PY{o}{=} \PY{n}{Scale}\PY{o}{.}\PY{n}{transform}\PY{p}{(}\PY{n}{X\PYZus{}train}\PY{p}{)}
         \PY{n}{X\PYZus{}val\PYZus{}sc} \PY{o}{=} \PY{n}{Scale}\PY{o}{.}\PY{n}{transform}\PY{p}{(}\PY{n}{X\PYZus{}val}\PY{p}{)}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}21}]:} \PY{n+nb}{print}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Shape of scaled X train}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}\PY{n}{X\PYZus{}train\PYZus{}sc}\PY{o}{.}\PY{n}{shape}\PY{p}{)}
         \PY{n+nb}{print}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Shape of scaled X test}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}\PY{n}{X\PYZus{}val\PYZus{}sc}\PY{o}{.}\PY{n}{shape}\PY{p}{)}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
Shape of scaled X train (7352, 128, 9)
Shape of scaled X test (2947, 128, 9)

    \end{Verbatim}

    \paragraph{Base Model}\label{base-model}

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}26}]:} \PY{n}{model} \PY{o}{=} \PY{n}{Sequential}\PY{p}{(}\PY{p}{)}
         \PY{n}{model}\PY{o}{.}\PY{n}{add}\PY{p}{(}\PY{n}{Conv1D}\PY{p}{(}\PY{n}{filters}\PY{o}{=}\PY{l+m+mi}{32}\PY{p}{,} \PY{n}{kernel\PYZus{}size}\PY{o}{=}\PY{l+m+mi}{3}\PY{p}{,} \PY{n}{activation}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{relu}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}\PY{n}{kernel\PYZus{}initializer}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{he\PYZus{}uniform}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}\PY{n}{input\PYZus{}shape}\PY{o}{=}\PY{p}{(}\PY{l+m+mi}{128}\PY{p}{,}\PY{l+m+mi}{9}\PY{p}{)}\PY{p}{)}\PY{p}{)}
         \PY{n}{model}\PY{o}{.}\PY{n}{add}\PY{p}{(}\PY{n}{Conv1D}\PY{p}{(}\PY{n}{filters}\PY{o}{=}\PY{l+m+mi}{32}\PY{p}{,} \PY{n}{kernel\PYZus{}size}\PY{o}{=}\PY{l+m+mi}{3}\PY{p}{,} \PY{n}{activation}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{relu}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}\PY{n}{kernel\PYZus{}initializer}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{he\PYZus{}uniform}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}\PY{p}{)}
         \PY{n}{model}\PY{o}{.}\PY{n}{add}\PY{p}{(}\PY{n}{Dropout}\PY{p}{(}\PY{l+m+mf}{0.6}\PY{p}{)}\PY{p}{)}
         \PY{n}{model}\PY{o}{.}\PY{n}{add}\PY{p}{(}\PY{n}{MaxPooling1D}\PY{p}{(}\PY{n}{pool\PYZus{}size}\PY{o}{=}\PY{l+m+mi}{2}\PY{p}{)}\PY{p}{)}
         \PY{n}{model}\PY{o}{.}\PY{n}{add}\PY{p}{(}\PY{n}{Flatten}\PY{p}{(}\PY{p}{)}\PY{p}{)}
         \PY{n}{model}\PY{o}{.}\PY{n}{add}\PY{p}{(}\PY{n}{Dense}\PY{p}{(}\PY{l+m+mi}{50}\PY{p}{,} \PY{n}{activation}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{relu}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}\PY{p}{)}
         \PY{n}{model}\PY{o}{.}\PY{n}{add}\PY{p}{(}\PY{n}{Dense}\PY{p}{(}\PY{l+m+mi}{6}\PY{p}{,} \PY{n}{activation}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{softmax}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}\PY{p}{)}
         \PY{n}{model}\PY{o}{.}\PY{n}{summary}\PY{p}{(}\PY{p}{)}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_
Layer (type)                 Output Shape              Param \#   
=================================================================
conv1d\_1 (Conv1D)            (None, 126, 32)           896       
\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_
conv1d\_2 (Conv1D)            (None, 124, 32)           3104      
\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_
dropout\_1 (Dropout)          (None, 124, 32)           0         
\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_
max\_pooling1d\_1 (MaxPooling1 (None, 62, 32)            0         
\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_
flatten\_1 (Flatten)          (None, 1984)              0         
\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_
dense\_1 (Dense)              (None, 50)                99250     
\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_
dense\_2 (Dense)              (None, 6)                 306       
=================================================================
Total params: 103,556
Trainable params: 103,556
Non-trainable params: 0
\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_

    \end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}27}]:} \PY{n}{model}\PY{o}{.}\PY{n}{compile}\PY{p}{(}\PY{n}{loss}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{categorical\PYZus{}crossentropy}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{optimizer}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{adam}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{metrics}\PY{o}{=}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{accuracy}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{)}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}28}]:} \PY{n}{model}\PY{o}{.}\PY{n}{fit}\PY{p}{(}\PY{n}{X\PYZus{}train\PYZus{}sc}\PY{p}{,}\PY{n}{Y\PYZus{}train}\PY{p}{,} \PY{n}{epochs}\PY{o}{=}\PY{l+m+mi}{30}\PY{p}{,} \PY{n}{batch\PYZus{}size}\PY{o}{=}\PY{l+m+mi}{16}\PY{p}{,}\PY{n}{validation\PYZus{}data}\PY{o}{=}\PY{p}{(}\PY{n}{X\PYZus{}val\PYZus{}sc}\PY{p}{,} \PY{n}{Y\PYZus{}val}\PY{p}{)}\PY{p}{,} \PY{n}{verbose}\PY{o}{=}\PY{l+m+mi}{1}\PY{p}{)}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
Train on 7352 samples, validate on 2947 samples
Epoch 1/30
7352/7352 [==============================] - 6s 764us/step - loss: 0.4207 - acc: 0.8403 - val\_loss: 0.3384 - val\_acc: 0.8748
Epoch 2/30
7352/7352 [==============================] - 5s 685us/step - loss: 0.1448 - acc: 0.9411 - val\_loss: 0.3163 - val\_acc: 0.8799
Epoch 3/30
7352/7352 [==============================] - 5s 672us/step - loss: 0.1177 - acc: 0.9486 - val\_loss: 0.2963 - val\_acc: 0.9226
Epoch 4/30
7352/7352 [==============================] - 5s 686us/step - loss: 0.0912 - acc: 0.9566 - val\_loss: 0.2926 - val\_acc: 0.9097
Epoch 5/30
7352/7352 [==============================] - 5s 691us/step - loss: 0.0987 - acc: 0.9567 - val\_loss: 0.3676 - val\_acc: 0.9036
Epoch 6/30
7352/7352 [==============================] - 5s 678us/step - loss: 0.0841 - acc: 0.9619 - val\_loss: 0.3184 - val\_acc: 0.9036
Epoch 7/30
7352/7352 [==============================] - 5s 695us/step - loss: 0.0727 - acc: 0.9659 - val\_loss: 0.3215 - val\_acc: 0.9169
Epoch 8/30
7352/7352 [==============================] - 5s 671us/step - loss: 0.0827 - acc: 0.9630 - val\_loss: 0.3346 - val\_acc: 0.9199
Epoch 9/30
7352/7352 [==============================] - 5s 695us/step - loss: 0.0726 - acc: 0.9690 - val\_loss: 0.3988 - val\_acc: 0.8958
Epoch 10/30
7352/7352 [==============================] - 5s 678us/step - loss: 0.0724 - acc: 0.9694 - val\_loss: 0.4881 - val\_acc: 0.8948
Epoch 11/30
7352/7352 [==============================] - 5s 667us/step - loss: 0.0585 - acc: 0.9746 - val\_loss: 0.3294 - val\_acc: 0.9148
Epoch 12/30
7352/7352 [==============================] - 5s 669us/step - loss: 0.0529 - acc: 0.9767 - val\_loss: 0.4145 - val\_acc: 0.9074
Epoch 13/30
7352/7352 [==============================] - 5s 685us/step - loss: 0.0578 - acc: 0.9742 - val\_loss: 0.4447 - val\_acc: 0.9084
Epoch 14/30
7352/7352 [==============================] - 5s 689us/step - loss: 0.0559 - acc: 0.9751 - val\_loss: 0.4771 - val\_acc: 0.8935
Epoch 15/30
7352/7352 [==============================] - 5s 676us/step - loss: 0.0529 - acc: 0.9771 - val\_loss: 0.4165 - val\_acc: 0.9060
Epoch 16/30
7352/7352 [==============================] - 5s 663us/step - loss: 0.0498 - acc: 0.9785 - val\_loss: 0.4710 - val\_acc: 0.8979
Epoch 17/30
7352/7352 [==============================] - 5s 678us/step - loss: 0.0427 - acc: 0.9833 - val\_loss: 0.4036 - val\_acc: 0.9155
Epoch 18/30
7352/7352 [==============================] - 5s 675us/step - loss: 0.0397 - acc: 0.9841 - val\_loss: 0.4978 - val\_acc: 0.9141
Epoch 19/30
7352/7352 [==============================] - 5s 651us/step - loss: 0.0475 - acc: 0.9804 - val\_loss: 0.4573 - val\_acc: 0.9060
Epoch 20/30
7352/7352 [==============================] - 5s 699us/step - loss: 0.0378 - acc: 0.9831 - val\_loss: 0.5176 - val\_acc: 0.9111
Epoch 21/30
7352/7352 [==============================] - 5s 691us/step - loss: 0.0353 - acc: 0.9867 - val\_loss: 0.5103 - val\_acc: 0.9111
Epoch 22/30
7352/7352 [==============================] - 5s 692us/step - loss: 0.0427 - acc: 0.9827 - val\_loss: 0.5969 - val\_acc: 0.9148
Epoch 23/30
7352/7352 [==============================] - 5s 669us/step - loss: 0.0379 - acc: 0.9837 - val\_loss: 0.6271 - val\_acc: 0.9046
Epoch 24/30
7352/7352 [==============================] - 5s 674us/step - loss: 0.0331 - acc: 0.9871 - val\_loss: 0.5575 - val\_acc: 0.9152
Epoch 25/30
7352/7352 [==============================] - 5s 687us/step - loss: 0.0259 - acc: 0.9883 - val\_loss: 0.5731 - val\_acc: 0.9141
Epoch 26/30
7352/7352 [==============================] - 5s 695us/step - loss: 0.0530 - acc: 0.9834 - val\_loss: 0.5450 - val\_acc: 0.9186
Epoch 27/30
7352/7352 [==============================] - 5s 674us/step - loss: 0.0692 - acc: 0.9822 - val\_loss: 0.5904 - val\_acc: 0.9026
Epoch 28/30
7352/7352 [==============================] - 5s 676us/step - loss: 0.0664 - acc: 0.9849 - val\_loss: 0.4807 - val\_acc: 0.9250
Epoch 29/30
7352/7352 [==============================] - 5s 673us/step - loss: 0.0675 - acc: 0.9845 - val\_loss: 0.5125 - val\_acc: 0.9264
Epoch 30/30
7352/7352 [==============================] - 5s 671us/step - loss: 0.0531 - acc: 0.9897 - val\_loss: 0.6342 - val\_acc: 0.9152

    \end{Verbatim}

\begin{Verbatim}[commandchars=\\\{\}]
{\color{outcolor}Out[{\color{outcolor}28}]:} <keras.callbacks.History at 0x14761b299ac8>
\end{Verbatim}
            
    it is giving some good score in train as well as test but it is
overfitting so much. i will try some regularization in below models.

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}3}]:} \PY{k+kn}{from} \PY{n+nn}{keras}\PY{n+nn}{.}\PY{n+nn}{regularizers} \PY{k}{import} \PY{n}{l2}\PY{p}{,}\PY{n}{l1}
        \PY{k+kn}{import} \PY{n+nn}{keras}
        \PY{k+kn}{from} \PY{n+nn}{keras}\PY{n+nn}{.}\PY{n+nn}{layers} \PY{k}{import} \PY{n}{BatchNormalization}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}117}]:} \PY{n}{model} \PY{o}{=} \PY{n}{Sequential}\PY{p}{(}\PY{p}{)}
          \PY{n}{model}\PY{o}{.}\PY{n}{add}\PY{p}{(}\PY{n}{Conv1D}\PY{p}{(}\PY{n}{filters}\PY{o}{=}\PY{l+m+mi}{32}\PY{p}{,} \PY{n}{kernel\PYZus{}size}\PY{o}{=}\PY{l+m+mi}{3}\PY{p}{,} \PY{n}{activation}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{relu}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}\PY{n}{kernel\PYZus{}initializer}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{he\PYZus{}uniform}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}
                           \PY{n}{kernel\PYZus{}regularizer}\PY{o}{=}\PY{n}{l2}\PY{p}{(}\PY{l+m+mf}{0.1}\PY{p}{)}\PY{p}{,}\PY{n}{input\PYZus{}shape}\PY{o}{=}\PY{p}{(}\PY{l+m+mi}{128}\PY{p}{,}\PY{l+m+mi}{9}\PY{p}{)}\PY{p}{)}\PY{p}{)}
          \PY{n}{model}\PY{o}{.}\PY{n}{add}\PY{p}{(}\PY{n}{Conv1D}\PY{p}{(}\PY{n}{filters}\PY{o}{=}\PY{l+m+mi}{16}\PY{p}{,} \PY{n}{kernel\PYZus{}size}\PY{o}{=}\PY{l+m+mi}{3}\PY{p}{,} \PY{n}{activation}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{relu}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}\PY{n}{kernel\PYZus{}regularizer}\PY{o}{=}\PY{n}{l2}\PY{p}{(}\PY{l+m+mf}{0.06}\PY{p}{)}\PY{p}{,}\PY{n}{kernel\PYZus{}initializer}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{he\PYZus{}uniform}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}\PY{p}{)}
          \PY{n}{model}\PY{o}{.}\PY{n}{add}\PY{p}{(}\PY{n}{Dropout}\PY{p}{(}\PY{l+m+mf}{0.65}\PY{p}{)}\PY{p}{)}
          \PY{n}{model}\PY{o}{.}\PY{n}{add}\PY{p}{(}\PY{n}{MaxPooling1D}\PY{p}{(}\PY{n}{pool\PYZus{}size}\PY{o}{=}\PY{l+m+mi}{2}\PY{p}{)}\PY{p}{)}
          \PY{n}{model}\PY{o}{.}\PY{n}{add}\PY{p}{(}\PY{n}{Flatten}\PY{p}{(}\PY{p}{)}\PY{p}{)}
          \PY{n}{model}\PY{o}{.}\PY{n}{add}\PY{p}{(}\PY{n}{Dense}\PY{p}{(}\PY{l+m+mi}{32}\PY{p}{,} \PY{n}{activation}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{relu}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}\PY{p}{)}
          \PY{n}{model}\PY{o}{.}\PY{n}{add}\PY{p}{(}\PY{n}{Dense}\PY{p}{(}\PY{l+m+mi}{6}\PY{p}{,} \PY{n}{activation}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{softmax}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}\PY{p}{)}
          \PY{n}{model}\PY{o}{.}\PY{n}{summary}\PY{p}{(}\PY{p}{)}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_
Layer (type)                 Output Shape              Param \#   
=================================================================
conv1d\_67 (Conv1D)           (None, 126, 32)           896       
\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_
conv1d\_68 (Conv1D)           (None, 124, 16)           1552      
\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_
dropout\_39 (Dropout)         (None, 124, 16)           0         
\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_
max\_pooling1d\_34 (MaxPooling (None, 62, 16)            0         
\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_
flatten\_34 (Flatten)         (None, 992)               0         
\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_
dense\_67 (Dense)             (None, 32)                31776     
\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_
dense\_68 (Dense)             (None, 6)                 198       
=================================================================
Total params: 34,422
Trainable params: 34,422
Non-trainable params: 0
\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_

    \end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}118}]:} \PY{k+kn}{import} \PY{n+nn}{math}
          \PY{n}{adam} \PY{o}{=} \PY{n}{keras}\PY{o}{.}\PY{n}{optimizers}\PY{o}{.}\PY{n}{Adam}\PY{p}{(}\PY{n}{lr}\PY{o}{=}\PY{l+m+mf}{0.001}\PY{p}{)}
          \PY{n}{rmsprop} \PY{o}{=} \PY{n}{keras}\PY{o}{.}\PY{n}{optimizers}\PY{o}{.}\PY{n}{RMSprop}\PY{p}{(}\PY{n}{lr}\PY{o}{=}\PY{l+m+mf}{0.001}\PY{p}{)}
          \PY{k}{def} \PY{n+nf}{step\PYZus{}decay}\PY{p}{(}\PY{n}{epoch}\PY{p}{)}\PY{p}{:}
              \PY{k}{return} \PY{n+nb}{float}\PY{p}{(}\PY{l+m+mf}{0.001} \PY{o}{*} \PY{n}{math}\PY{o}{.}\PY{n}{pow}\PY{p}{(}\PY{l+m+mf}{0.6}\PY{p}{,} \PY{n}{math}\PY{o}{.}\PY{n}{floor}\PY{p}{(}\PY{p}{(}\PY{l+m+mi}{1}\PY{o}{+}\PY{n}{epoch}\PY{p}{)}\PY{o}{/}\PY{l+m+mi}{10}\PY{p}{)}\PY{p}{)}\PY{p}{)}
          \PY{k+kn}{from} \PY{n+nn}{keras}\PY{n+nn}{.}\PY{n+nn}{callbacks} \PY{k}{import} \PY{n}{LearningRateScheduler}
          \PY{n}{lrate} \PY{o}{=} \PY{n}{LearningRateScheduler}\PY{p}{(}\PY{n}{step\PYZus{}decay}\PY{p}{)}
          \PY{n}{callbacks\PYZus{}list} \PY{o}{=} \PY{p}{[}\PY{n}{lrate}\PY{p}{]}
          
          \PY{n}{model}\PY{o}{.}\PY{n}{compile}\PY{p}{(}\PY{n}{loss}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{categorical\PYZus{}crossentropy}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{optimizer}\PY{o}{=}\PY{n}{adam}\PY{p}{,} \PY{n}{metrics}\PY{o}{=}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{accuracy}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{)}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}119}]:} \PY{n}{model}\PY{o}{.}\PY{n}{fit}\PY{p}{(}\PY{n}{X\PYZus{}train\PYZus{}sc}\PY{p}{,}\PY{n}{Y\PYZus{}train}\PY{p}{,} \PY{n}{epochs}\PY{o}{=}\PY{l+m+mi}{30}\PY{p}{,} \PY{n}{batch\PYZus{}size}\PY{o}{=}\PY{l+m+mi}{16}\PY{p}{,}\PY{n}{validation\PYZus{}data}\PY{o}{=}\PY{p}{(}\PY{n}{X\PYZus{}val\PYZus{}sc}\PY{p}{,} \PY{n}{Y\PYZus{}val}\PY{p}{)}\PY{p}{,} \PY{n}{verbose}\PY{o}{=}\PY{l+m+mi}{1}\PY{p}{)}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
Train on 7352 samples, validate on 2947 samples
Epoch 1/30
7352/7352 [==============================] - 6s 879us/step - loss: 4.3454 - acc: 0.7266 - val\_loss: 1.5457 - val\_acc: 0.7815
Epoch 2/30
7352/7352 [==============================] - 5s 676us/step - loss: 0.7579 - acc: 0.9121 - val\_loss: 0.6360 - val\_acc: 0.8935
Epoch 3/30
7352/7352 [==============================] - 5s 668us/step - loss: 0.3876 - acc: 0.9286 - val\_loss: 0.5337 - val\_acc: 0.8772
Epoch 4/30
7352/7352 [==============================] - 5s 673us/step - loss: 0.3123 - acc: 0.9283 - val\_loss: 0.4940 - val\_acc: 0.8673
Epoch 5/30
7352/7352 [==============================] - 5s 680us/step - loss: 0.2729 - acc: 0.9336 - val\_loss: 0.4439 - val\_acc: 0.8901
Epoch 6/30
7352/7352 [==============================] - 5s 676us/step - loss: 0.2629 - acc: 0.9327 - val\_loss: 0.4330 - val\_acc: 0.8775
Epoch 7/30
7352/7352 [==============================] - 5s 664us/step - loss: 0.2423 - acc: 0.9393 - val\_loss: 0.4225 - val\_acc: 0.8711
Epoch 8/30
7352/7352 [==============================] - 5s 681us/step - loss: 0.2327 - acc: 0.9380 - val\_loss: 0.3889 - val\_acc: 0.8992
Epoch 9/30
7352/7352 [==============================] - 5s 670us/step - loss: 0.2237 - acc: 0.9372 - val\_loss: 0.3994 - val\_acc: 0.8928
Epoch 10/30
7352/7352 [==============================] - 5s 687us/step - loss: 0.2221 - acc: 0.9377 - val\_loss: 0.3850 - val\_acc: 0.8880
Epoch 11/30
7352/7352 [==============================] - 5s 676us/step - loss: 0.2216 - acc: 0.9377 - val\_loss: 0.4274 - val\_acc: 0.8914
Epoch 12/30
7352/7352 [==============================] - 5s 684us/step - loss: 0.2085 - acc: 0.9416 - val\_loss: 0.3917 - val\_acc: 0.8887
Epoch 13/30
7352/7352 [==============================] - 5s 646us/step - loss: 0.2005 - acc: 0.9448 - val\_loss: 0.3987 - val\_acc: 0.8843
Epoch 14/30
7352/7352 [==============================] - 5s 687us/step - loss: 0.2075 - acc: 0.9446 - val\_loss: 0.4501 - val\_acc: 0.8337
Epoch 15/30
7352/7352 [==============================] - 5s 678us/step - loss: 0.1980 - acc: 0.9434 - val\_loss: 0.3589 - val\_acc: 0.8860
Epoch 16/30
7352/7352 [==============================] - 5s 696us/step - loss: 0.1891 - acc: 0.9449 - val\_loss: 0.3954 - val\_acc: 0.8931
Epoch 17/30
7352/7352 [==============================] - 5s 660us/step - loss: 0.1909 - acc: 0.9434 - val\_loss: 0.4015 - val\_acc: 0.8778
Epoch 18/30
7352/7352 [==============================] - 5s 689us/step - loss: 0.1893 - acc: 0.9429 - val\_loss: 0.3641 - val\_acc: 0.8853
Epoch 19/30
7352/7352 [==============================] - 5s 661us/step - loss: 0.2002 - acc: 0.9389 - val\_loss: 0.4151 - val\_acc: 0.8728
Epoch 20/30
7352/7352 [==============================] - 5s 664us/step - loss: 0.1817 - acc: 0.9486 - val\_loss: 0.3662 - val\_acc: 0.8768
Epoch 21/30
7352/7352 [==============================] - 5s 670us/step - loss: 0.1828 - acc: 0.9472 - val\_loss: 0.3892 - val\_acc: 0.8819
Epoch 22/30
7352/7352 [==============================] - 5s 661us/step - loss: 0.1851 - acc: 0.9449 - val\_loss: 0.3684 - val\_acc: 0.8907
Epoch 23/30
7352/7352 [==============================] - 5s 672us/step - loss: 0.1841 - acc: 0.9456 - val\_loss: 0.3256 - val\_acc: 0.8924
Epoch 24/30
7352/7352 [==============================] - 5s 674us/step - loss: 0.1777 - acc: 0.9463 - val\_loss: 0.3316 - val\_acc: 0.8816
Epoch 25/30
7352/7352 [==============================] - 5s 683us/step - loss: 0.1785 - acc: 0.9448 - val\_loss: 0.4006 - val\_acc: 0.8622
Epoch 26/30
7352/7352 [==============================] - 5s 678us/step - loss: 0.1751 - acc: 0.9459 - val\_loss: 0.5416 - val\_acc: 0.8493
Epoch 27/30
7352/7352 [==============================] - 5s 697us/step - loss: 0.1773 - acc: 0.9476 - val\_loss: 0.3382 - val\_acc: 0.8989
Epoch 28/30
7352/7352 [==============================] - 5s 672us/step - loss: 0.1692 - acc: 0.9506 - val\_loss: 0.3668 - val\_acc: 0.8826
Epoch 29/30
7352/7352 [==============================] - 5s 677us/step - loss: 0.1742 - acc: 0.9478 - val\_loss: 0.3855 - val\_acc: 0.8904
Epoch 30/30
7352/7352 [==============================] - 5s 679us/step - loss: 0.1754 - acc: 0.9467 - val\_loss: 0.3478 - val\_acc: 0.8958

    \end{Verbatim}

\begin{Verbatim}[commandchars=\\\{\}]
{\color{outcolor}Out[{\color{outcolor}119}]:} <keras.callbacks.History at 0x14757856a6d8>
\end{Verbatim}
            
    \paragraph{Hyper Parameter Tuning Using
Hyperas}\label{hyper-parameter-tuning-using-hyperas}

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}4}]:} \PY{k}{def} \PY{n+nf}{data\PYZus{}scaled}\PY{p}{(}\PY{p}{)}\PY{p}{:}
            \PY{l+s+sd}{\PYZdq{}\PYZdq{}\PYZdq{}}
        \PY{l+s+sd}{    Obtain the dataset from multiple files.}
        \PY{l+s+sd}{    Returns: X\PYZus{}train, X\PYZus{}test, y\PYZus{}train, y\PYZus{}test}
        \PY{l+s+sd}{    \PYZdq{}\PYZdq{}\PYZdq{}}
            \PY{c+c1}{\PYZsh{} Data directory}
            \PY{n}{DATADIR} \PY{o}{=} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{UCI\PYZus{}HAR\PYZus{}Dataset}\PY{l+s+s1}{\PYZsq{}}
            \PY{c+c1}{\PYZsh{} Raw data signals}
            \PY{c+c1}{\PYZsh{} Signals are from Accelerometer and Gyroscope}
            \PY{c+c1}{\PYZsh{} The signals are in x,y,z directions}
            \PY{c+c1}{\PYZsh{} Sensor signals are filtered to have only body acceleration}
            \PY{c+c1}{\PYZsh{} excluding the acceleration due to gravity}
            \PY{c+c1}{\PYZsh{} Triaxial acceleration from the accelerometer is total acceleration}
            \PY{n}{SIGNALS} \PY{o}{=} \PY{p}{[}
                \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{body\PYZus{}acc\PYZus{}x}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,}
                \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{body\PYZus{}acc\PYZus{}y}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,}
                \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{body\PYZus{}acc\PYZus{}z}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,}
                \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{body\PYZus{}gyro\PYZus{}x}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,}
                \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{body\PYZus{}gyro\PYZus{}y}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,}
                \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{body\PYZus{}gyro\PYZus{}z}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,}
                \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{total\PYZus{}acc\PYZus{}x}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,}
                \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{total\PYZus{}acc\PYZus{}y}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,}
                \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{total\PYZus{}acc\PYZus{}z}\PY{l+s+s2}{\PYZdq{}}
                \PY{p}{]}
            \PY{k+kn}{from} \PY{n+nn}{sklearn}\PY{n+nn}{.}\PY{n+nn}{base} \PY{k}{import} \PY{n}{BaseEstimator}\PY{p}{,} \PY{n}{TransformerMixin}
            \PY{k}{class} \PY{n+nc}{scaling\PYZus{}tseries\PYZus{}data}\PY{p}{(}\PY{n}{BaseEstimator}\PY{p}{,} \PY{n}{TransformerMixin}\PY{p}{)}\PY{p}{:}
                \PY{k+kn}{from} \PY{n+nn}{sklearn}\PY{n+nn}{.}\PY{n+nn}{preprocessing} \PY{k}{import} \PY{n}{StandardScaler}
                \PY{k}{def} \PY{n+nf}{\PYZus{}\PYZus{}init\PYZus{}\PYZus{}}\PY{p}{(}\PY{n+nb+bp}{self}\PY{p}{)}\PY{p}{:}
                    \PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{scale} \PY{o}{=} \PY{k+kc}{None}
        
                \PY{k}{def} \PY{n+nf}{transform}\PY{p}{(}\PY{n+nb+bp}{self}\PY{p}{,} \PY{n}{X}\PY{p}{)}\PY{p}{:}
                    \PY{n}{temp\PYZus{}X1} \PY{o}{=} \PY{n}{X}\PY{o}{.}\PY{n}{reshape}\PY{p}{(}\PY{p}{(}\PY{n}{X}\PY{o}{.}\PY{n}{shape}\PY{p}{[}\PY{l+m+mi}{0}\PY{p}{]} \PY{o}{*} \PY{n}{X}\PY{o}{.}\PY{n}{shape}\PY{p}{[}\PY{l+m+mi}{1}\PY{p}{]}\PY{p}{,} \PY{n}{X}\PY{o}{.}\PY{n}{shape}\PY{p}{[}\PY{l+m+mi}{2}\PY{p}{]}\PY{p}{)}\PY{p}{)}
                    \PY{n}{temp\PYZus{}X1} \PY{o}{=} \PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{scale}\PY{o}{.}\PY{n}{transform}\PY{p}{(}\PY{n}{temp\PYZus{}X1}\PY{p}{)}
                    \PY{k}{return} \PY{n}{temp\PYZus{}X1}\PY{o}{.}\PY{n}{reshape}\PY{p}{(}\PY{n}{X}\PY{o}{.}\PY{n}{shape}\PY{p}{)}
        
                \PY{k}{def} \PY{n+nf}{fit}\PY{p}{(}\PY{n+nb+bp}{self}\PY{p}{,} \PY{n}{X}\PY{p}{)}\PY{p}{:}
                    \PY{c+c1}{\PYZsh{} remove overlaping}
                    \PY{n}{remove} \PY{o}{=} \PY{n+nb}{int}\PY{p}{(}\PY{n}{X}\PY{o}{.}\PY{n}{shape}\PY{p}{[}\PY{l+m+mi}{1}\PY{p}{]} \PY{o}{/} \PY{l+m+mi}{2}\PY{p}{)}
                    \PY{n}{temp\PYZus{}X} \PY{o}{=} \PY{n}{X}\PY{p}{[}\PY{p}{:}\PY{p}{,} \PY{o}{\PYZhy{}}\PY{n}{remove}\PY{p}{:}\PY{p}{,} \PY{p}{:}\PY{p}{]}
                    \PY{c+c1}{\PYZsh{} flatten data}
                    \PY{n}{temp\PYZus{}X} \PY{o}{=} \PY{n}{temp\PYZus{}X}\PY{o}{.}\PY{n}{reshape}\PY{p}{(}\PY{p}{(}\PY{n}{temp\PYZus{}X}\PY{o}{.}\PY{n}{shape}\PY{p}{[}\PY{l+m+mi}{0}\PY{p}{]} \PY{o}{*} \PY{n}{temp\PYZus{}X}\PY{o}{.}\PY{n}{shape}\PY{p}{[}\PY{l+m+mi}{1}\PY{p}{]}\PY{p}{,} \PY{n}{temp\PYZus{}X}\PY{o}{.}\PY{n}{shape}\PY{p}{[}\PY{l+m+mi}{2}\PY{p}{]}\PY{p}{)}\PY{p}{)}
                    \PY{n}{scale} \PY{o}{=} \PY{n}{StandardScaler}\PY{p}{(}\PY{p}{)}
                    \PY{n}{scale}\PY{o}{.}\PY{n}{fit}\PY{p}{(}\PY{n}{temp\PYZus{}X}\PY{p}{)}
                    \PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{scale} \PY{o}{=} \PY{n}{scale}
                    \PY{k}{return} \PY{n+nb+bp}{self}
                
            \PY{c+c1}{\PYZsh{} Utility function to read the data from csv file}
            \PY{k}{def} \PY{n+nf}{\PYZus{}read\PYZus{}csv}\PY{p}{(}\PY{n}{filename}\PY{p}{)}\PY{p}{:}
                \PY{k}{return} \PY{n}{pd}\PY{o}{.}\PY{n}{read\PYZus{}csv}\PY{p}{(}\PY{n}{filename}\PY{p}{,} \PY{n}{delim\PYZus{}whitespace}\PY{o}{=}\PY{k+kc}{True}\PY{p}{,} \PY{n}{header}\PY{o}{=}\PY{k+kc}{None}\PY{p}{)}
        
            \PY{c+c1}{\PYZsh{} Utility function to load the load}
            \PY{k}{def} \PY{n+nf}{load\PYZus{}signals}\PY{p}{(}\PY{n}{subset}\PY{p}{)}\PY{p}{:}
                \PY{n}{signals\PYZus{}data} \PY{o}{=} \PY{p}{[}\PY{p}{]}
        
                \PY{k}{for} \PY{n}{signal} \PY{o+ow}{in} \PY{n}{SIGNALS}\PY{p}{:}
                    \PY{n}{filename} \PY{o}{=} \PY{n}{f}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{UCI\PYZus{}HAR\PYZus{}Dataset/}\PY{l+s+si}{\PYZob{}subset\PYZcb{}}\PY{l+s+s1}{/Inertial Signals/}\PY{l+s+si}{\PYZob{}signal\PYZcb{}}\PY{l+s+s1}{\PYZus{}}\PY{l+s+si}{\PYZob{}subset\PYZcb{}}\PY{l+s+s1}{.txt}\PY{l+s+s1}{\PYZsq{}}
                    \PY{n}{signals\PYZus{}data}\PY{o}{.}\PY{n}{append}\PY{p}{(} \PY{n}{\PYZus{}read\PYZus{}csv}\PY{p}{(}\PY{n}{filename}\PY{p}{)}\PY{o}{.}\PY{n}{as\PYZus{}matrix}\PY{p}{(}\PY{p}{)}\PY{p}{)} 
        
                \PY{c+c1}{\PYZsh{} Transpose is used to change the dimensionality of the output,}
                \PY{c+c1}{\PYZsh{} aggregating the signals by combination of sample/timestep.}
                \PY{c+c1}{\PYZsh{} Resultant shape is (7352 train/2947 test samples, 128 timesteps, 9 signals)}
                \PY{k}{return} \PY{n}{np}\PY{o}{.}\PY{n}{transpose}\PY{p}{(}\PY{n}{signals\PYZus{}data}\PY{p}{,} \PY{p}{(}\PY{l+m+mi}{1}\PY{p}{,} \PY{l+m+mi}{2}\PY{p}{,} \PY{l+m+mi}{0}\PY{p}{)}\PY{p}{)}
            
            \PY{k}{def} \PY{n+nf}{load\PYZus{}y}\PY{p}{(}\PY{n}{subset}\PY{p}{)}\PY{p}{:}
                \PY{l+s+sd}{\PYZdq{}\PYZdq{}\PYZdq{}}
        \PY{l+s+sd}{        The objective that we are trying to predict is a integer, from 1 to 6,}
        \PY{l+s+sd}{        that represents a human activity. We return a binary representation of }
        \PY{l+s+sd}{        every sample objective as a 6 bits vector using One Hot Encoding}
        \PY{l+s+sd}{        (https://pandas.pydata.org/pandas\PYZhy{}docs/stable/generated/pandas.get\PYZus{}dummies.html)}
        \PY{l+s+sd}{        \PYZdq{}\PYZdq{}\PYZdq{}}
                \PY{n}{filename} \PY{o}{=} \PY{n}{f}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{UCI\PYZus{}HAR\PYZus{}Dataset/}\PY{l+s+si}{\PYZob{}subset\PYZcb{}}\PY{l+s+s1}{/y\PYZus{}}\PY{l+s+si}{\PYZob{}subset\PYZcb{}}\PY{l+s+s1}{.txt}\PY{l+s+s1}{\PYZsq{}}
                \PY{n}{y} \PY{o}{=} \PY{n}{\PYZus{}read\PYZus{}csv}\PY{p}{(}\PY{n}{filename}\PY{p}{)}\PY{p}{[}\PY{l+m+mi}{0}\PY{p}{]}
                \PY{k}{return} \PY{n}{pd}\PY{o}{.}\PY{n}{get\PYZus{}dummies}\PY{p}{(}\PY{n}{y}\PY{p}{)}\PY{o}{.}\PY{n}{as\PYZus{}matrix}\PY{p}{(}\PY{p}{)}
            
            \PY{n}{X\PYZus{}train}\PY{p}{,} \PY{n}{X\PYZus{}val} \PY{o}{=} \PY{n}{load\PYZus{}signals}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{train}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}\PY{p}{,} \PY{n}{load\PYZus{}signals}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{test}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
            \PY{n}{Y\PYZus{}train}\PY{p}{,} \PY{n}{Y\PYZus{}val} \PY{o}{=} \PY{n}{load\PYZus{}y}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{train}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}\PY{p}{,} \PY{n}{load\PYZus{}y}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{test}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
            \PY{c+c1}{\PYZsh{}\PYZsh{}\PYZsh{}Scling data}
            \PY{n}{Scale} \PY{o}{=} \PY{n}{scaling\PYZus{}tseries\PYZus{}data}\PY{p}{(}\PY{p}{)}
            \PY{n}{Scale}\PY{o}{.}\PY{n}{fit}\PY{p}{(}\PY{n}{X\PYZus{}train}\PY{p}{)}
            \PY{n}{X\PYZus{}train} \PY{o}{=} \PY{n}{Scale}\PY{o}{.}\PY{n}{transform}\PY{p}{(}\PY{n}{X\PYZus{}train}\PY{p}{)}
            \PY{n}{X\PYZus{}val} \PY{o}{=} \PY{n}{Scale}\PY{o}{.}\PY{n}{transform}\PY{p}{(}\PY{n}{X\PYZus{}val}\PY{p}{)}
        
            \PY{k}{return} \PY{n}{X\PYZus{}train}\PY{p}{,} \PY{n}{Y\PYZus{}train}\PY{p}{,} \PY{n}{X\PYZus{}val}\PY{p}{,}  \PY{n}{Y\PYZus{}val}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}5}]:} \PY{n}{X\PYZus{}train}\PY{p}{,} \PY{n}{Y\PYZus{}train}\PY{p}{,} \PY{n}{X\PYZus{}val}\PY{p}{,}  \PY{n}{Y\PYZus{}val} \PY{o}{=} \PY{n}{data\PYZus{}scaled}\PY{p}{(}\PY{p}{)}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}6}]:} \PY{k}{def} \PY{n+nf}{model\PYZus{}cnn}\PY{p}{(}\PY{n}{X\PYZus{}train}\PY{p}{,} \PY{n}{Y\PYZus{}train}\PY{p}{,} \PY{n}{X\PYZus{}val}\PY{p}{,} \PY{n}{Y\PYZus{}val}\PY{p}{)}\PY{p}{:}
            \PY{c+c1}{\PYZsh{} Importing tensorflow}
            \PY{n}{np}\PY{o}{.}\PY{n}{random}\PY{o}{.}\PY{n}{seed}\PY{p}{(}\PY{l+m+mi}{36}\PY{p}{)}
            \PY{k+kn}{import} \PY{n+nn}{tensorflow} \PY{k}{as} \PY{n+nn}{tf}
            \PY{n}{tf}\PY{o}{.}\PY{n}{set\PYZus{}random\PYZus{}seed}\PY{p}{(}\PY{l+m+mi}{36}\PY{p}{)}
            \PY{c+c1}{\PYZsh{} Initiliazing the sequential model}
            \PY{n}{model} \PY{o}{=} \PY{n}{Sequential}\PY{p}{(}\PY{p}{)}
            
            \PY{n}{model}\PY{o}{.}\PY{n}{add}\PY{p}{(}\PY{n}{Conv1D}\PY{p}{(}\PY{n}{filters}\PY{o}{=}\PY{p}{\PYZob{}}\PY{p}{\PYZob{}}\PY{n}{choice}\PY{p}{(}\PY{p}{[}\PY{l+m+mi}{28}\PY{p}{,}\PY{l+m+mi}{32}\PY{p}{,}\PY{l+m+mi}{42}\PY{p}{]}\PY{p}{)}\PY{p}{\PYZcb{}}\PY{p}{\PYZcb{}}\PY{p}{,} \PY{n}{kernel\PYZus{}size}\PY{o}{=}\PY{p}{\PYZob{}}\PY{p}{\PYZob{}}\PY{n}{choice}\PY{p}{(}\PY{p}{[}\PY{l+m+mi}{3}\PY{p}{,}\PY{l+m+mi}{5}\PY{p}{,}\PY{l+m+mi}{7}\PY{p}{]}\PY{p}{)}\PY{p}{\PYZcb{}}\PY{p}{\PYZcb{}}\PY{p}{,}\PY{n}{activation}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{relu}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}\PY{n}{kernel\PYZus{}initializer}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{he\PYZus{}uniform}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}
                         \PY{n}{kernel\PYZus{}regularizer}\PY{o}{=}\PY{n}{l2}\PY{p}{(}\PY{p}{\PYZob{}}\PY{p}{\PYZob{}}\PY{n}{uniform}\PY{p}{(}\PY{l+m+mi}{0}\PY{p}{,}\PY{l+m+mf}{2.5}\PY{p}{)}\PY{p}{\PYZcb{}}\PY{p}{\PYZcb{}}\PY{p}{)}\PY{p}{,}\PY{n}{input\PYZus{}shape}\PY{o}{=}\PY{p}{(}\PY{l+m+mi}{128}\PY{p}{,}\PY{l+m+mi}{9}\PY{p}{)}\PY{p}{)}\PY{p}{)}
            
            \PY{n}{model}\PY{o}{.}\PY{n}{add}\PY{p}{(}\PY{n}{Conv1D}\PY{p}{(}\PY{n}{filters}\PY{o}{=}\PY{p}{\PYZob{}}\PY{p}{\PYZob{}}\PY{n}{choice}\PY{p}{(}\PY{p}{[}\PY{l+m+mi}{16}\PY{p}{,}\PY{l+m+mi}{24}\PY{p}{,}\PY{l+m+mi}{32}\PY{p}{]}\PY{p}{)}\PY{p}{\PYZcb{}}\PY{p}{\PYZcb{}}\PY{p}{,} \PY{n}{kernel\PYZus{}size}\PY{o}{=}\PY{p}{\PYZob{}}\PY{p}{\PYZob{}}\PY{n}{choice}\PY{p}{(}\PY{p}{[}\PY{l+m+mi}{3}\PY{p}{,}\PY{l+m+mi}{5}\PY{p}{,}\PY{l+m+mi}{7}\PY{p}{]}\PY{p}{)}\PY{p}{\PYZcb{}}\PY{p}{\PYZcb{}}\PY{p}{,} 
                             \PY{n}{activation}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{relu}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}\PY{n}{kernel\PYZus{}regularizer}\PY{o}{=}\PY{n}{l2}\PY{p}{(}\PY{p}{\PYZob{}}\PY{p}{\PYZob{}}\PY{n}{uniform}\PY{p}{(}\PY{l+m+mi}{0}\PY{p}{,}\PY{l+m+mf}{1.5}\PY{p}{)}\PY{p}{\PYZcb{}}\PY{p}{\PYZcb{}}\PY{p}{)}\PY{p}{,}\PY{n}{kernel\PYZus{}initializer}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{he\PYZus{}uniform}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}\PY{p}{)}
            \PY{n}{model}\PY{o}{.}\PY{n}{add}\PY{p}{(}\PY{n}{Dropout}\PY{p}{(}\PY{p}{\PYZob{}}\PY{p}{\PYZob{}}\PY{n}{uniform}\PY{p}{(}\PY{l+m+mf}{0.45}\PY{p}{,}\PY{l+m+mf}{0.7}\PY{p}{)}\PY{p}{\PYZcb{}}\PY{p}{\PYZcb{}}\PY{p}{)}\PY{p}{)}
            \PY{n}{model}\PY{o}{.}\PY{n}{add}\PY{p}{(}\PY{n}{MaxPooling1D}\PY{p}{(}\PY{n}{pool\PYZus{}size}\PY{o}{=}\PY{p}{\PYZob{}}\PY{p}{\PYZob{}}\PY{n}{choice}\PY{p}{(}\PY{p}{[}\PY{l+m+mi}{2}\PY{p}{,}\PY{l+m+mi}{3}\PY{p}{]}\PY{p}{)}\PY{p}{\PYZcb{}}\PY{p}{\PYZcb{}}\PY{p}{)}\PY{p}{)}
            \PY{n}{model}\PY{o}{.}\PY{n}{add}\PY{p}{(}\PY{n}{Flatten}\PY{p}{(}\PY{p}{)}\PY{p}{)}
            \PY{n}{model}\PY{o}{.}\PY{n}{add}\PY{p}{(}\PY{n}{Dense}\PY{p}{(}\PY{p}{\PYZob{}}\PY{p}{\PYZob{}}\PY{n}{choice}\PY{p}{(}\PY{p}{[}\PY{l+m+mi}{32}\PY{p}{,}\PY{l+m+mi}{64}\PY{p}{]}\PY{p}{)}\PY{p}{\PYZcb{}}\PY{p}{\PYZcb{}}\PY{p}{,} \PY{n}{activation}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{relu}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}\PY{p}{)}
            \PY{n}{model}\PY{o}{.}\PY{n}{add}\PY{p}{(}\PY{n}{Dense}\PY{p}{(}\PY{l+m+mi}{6}\PY{p}{,} \PY{n}{activation}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{softmax}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}\PY{p}{)}
                
            \PY{n}{adam} \PY{o}{=} \PY{n}{keras}\PY{o}{.}\PY{n}{optimizers}\PY{o}{.}\PY{n}{Adam}\PY{p}{(}\PY{n}{lr}\PY{o}{=}\PY{p}{\PYZob{}}\PY{p}{\PYZob{}}\PY{n}{uniform}\PY{p}{(}\PY{l+m+mf}{0.00065}\PY{p}{,}\PY{l+m+mf}{0.004}\PY{p}{)}\PY{p}{\PYZcb{}}\PY{p}{\PYZcb{}}\PY{p}{)}
            \PY{n}{rmsprop} \PY{o}{=} \PY{n}{keras}\PY{o}{.}\PY{n}{optimizers}\PY{o}{.}\PY{n}{RMSprop}\PY{p}{(}\PY{n}{lr}\PY{o}{=}\PY{p}{\PYZob{}}\PY{p}{\PYZob{}}\PY{n}{uniform}\PY{p}{(}\PY{l+m+mf}{0.00065}\PY{p}{,}\PY{l+m+mf}{0.004}\PY{p}{)}\PY{p}{\PYZcb{}}\PY{p}{\PYZcb{}}\PY{p}{)}
           
            \PY{n}{choiceval} \PY{o}{=} \PY{p}{\PYZob{}}\PY{p}{\PYZob{}}\PY{n}{choice}\PY{p}{(}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{adam}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{rmsprop}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{)}\PY{p}{\PYZcb{}}\PY{p}{\PYZcb{}}
            
            \PY{k}{if} \PY{n}{choiceval} \PY{o}{==} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{adam}\PY{l+s+s1}{\PYZsq{}}\PY{p}{:}
                \PY{n}{optim} \PY{o}{=} \PY{n}{adam}
            \PY{k}{else}\PY{p}{:}
                \PY{n}{optim} \PY{o}{=} \PY{n}{rmsprop}
            
            \PY{n+nb}{print}\PY{p}{(}\PY{n}{model}\PY{o}{.}\PY{n}{summary}\PY{p}{(}\PY{p}{)}\PY{p}{)}
                
            \PY{n}{model}\PY{o}{.}\PY{n}{compile}\PY{p}{(}\PY{n}{loss}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{categorical\PYZus{}crossentropy}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{metrics}\PY{o}{=}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{accuracy}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{,}\PY{n}{optimizer}\PY{o}{=}\PY{n}{optim}\PY{p}{)}
            
            \PY{n}{result} \PY{o}{=} \PY{n}{model}\PY{o}{.}\PY{n}{fit}\PY{p}{(}\PY{n}{X\PYZus{}train}\PY{p}{,} \PY{n}{Y\PYZus{}train}\PY{p}{,}
                      \PY{n}{batch\PYZus{}size}\PY{o}{=}\PY{p}{\PYZob{}}\PY{p}{\PYZob{}}\PY{n}{choice}\PY{p}{(}\PY{p}{[}\PY{l+m+mi}{16}\PY{p}{,}\PY{l+m+mi}{32}\PY{p}{,}\PY{l+m+mi}{64}\PY{p}{]}\PY{p}{)}\PY{p}{\PYZcb{}}\PY{p}{\PYZcb{}}\PY{p}{,}
                      \PY{n}{nb\PYZus{}epoch}\PY{o}{=}\PY{p}{\PYZob{}}\PY{p}{\PYZob{}}\PY{n}{choice}\PY{p}{(}\PY{p}{[}\PY{l+m+mi}{25}\PY{p}{,}\PY{l+m+mi}{30}\PY{p}{,}\PY{l+m+mi}{35}\PY{p}{]}\PY{p}{)}\PY{p}{\PYZcb{}}\PY{p}{\PYZcb{}}\PY{p}{,}
                      \PY{n}{verbose}\PY{o}{=}\PY{l+m+mi}{2}\PY{p}{,}
                      \PY{n}{validation\PYZus{}data}\PY{o}{=}\PY{p}{(}\PY{n}{X\PYZus{}val}\PY{p}{,} \PY{n}{Y\PYZus{}val}\PY{p}{)}\PY{p}{)}
                               
            \PY{n}{score}\PY{p}{,} \PY{n}{acc} \PY{o}{=} \PY{n}{model}\PY{o}{.}\PY{n}{evaluate}\PY{p}{(}\PY{n}{X\PYZus{}val}\PY{p}{,} \PY{n}{Y\PYZus{}val}\PY{p}{,} \PY{n}{verbose}\PY{o}{=}\PY{l+m+mi}{0}\PY{p}{)}
            \PY{n}{score1}\PY{p}{,} \PY{n}{acc1} \PY{o}{=} \PY{n}{model}\PY{o}{.}\PY{n}{evaluate}\PY{p}{(}\PY{n}{X\PYZus{}train}\PY{p}{,} \PY{n}{Y\PYZus{}train}\PY{p}{,} \PY{n}{verbose}\PY{o}{=}\PY{l+m+mi}{0}\PY{p}{)}
            \PY{n+nb}{print}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Train accuracy}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}\PY{n}{acc1}\PY{p}{,}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Test accuracy:}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{acc}\PY{p}{)}
            \PY{n+nb}{print}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
            \PY{k}{return} \PY{p}{\PYZob{}}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{loss}\PY{l+s+s1}{\PYZsq{}}\PY{p}{:} \PY{o}{\PYZhy{}}\PY{n}{acc}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{status}\PY{l+s+s1}{\PYZsq{}}\PY{p}{:} \PY{n}{STATUS\PYZus{}OK}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{model}\PY{l+s+s1}{\PYZsq{}}\PY{p}{:} \PY{n}{model}\PY{p}{,}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{train\PYZus{}acc}\PY{l+s+s1}{\PYZsq{}}\PY{p}{:}\PY{n}{acc1}\PY{p}{\PYZcb{}}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor} }]:} \PY{n}{X\PYZus{}train}\PY{p}{,} \PY{n}{Y\PYZus{}train}\PY{p}{,} \PY{n}{X\PYZus{}val}\PY{p}{,} \PY{n}{Y\PYZus{}val} \PY{o}{=} \PY{n}{data\PYZus{}scaled}\PY{p}{(}\PY{p}{)}
        \PY{n}{trials} \PY{o}{=} \PY{n}{Trials}\PY{p}{(}\PY{p}{)}
        \PY{n}{best\PYZus{}run}\PY{p}{,} \PY{n}{best\PYZus{}model}\PY{p}{,} \PY{n}{space} \PY{o}{=} \PY{n}{optim}\PY{o}{.}\PY{n}{minimize}\PY{p}{(}\PY{n}{model}\PY{o}{=}\PY{n}{model\PYZus{}cnn}\PY{p}{,}
                                              \PY{n}{data}\PY{o}{=}\PY{n}{data\PYZus{}scaled}\PY{p}{,}
                                              \PY{n}{algo}\PY{o}{=}\PY{n}{tpe}\PY{o}{.}\PY{n}{suggest}\PY{p}{,}
                                              \PY{n}{max\PYZus{}evals}\PY{o}{=}\PY{l+m+mi}{100}\PY{p}{,}
                                              \PY{n}{trials}\PY{o}{=}\PY{n}{trials}\PY{p}{,}\PY{n}{notebook\PYZus{}name} \PY{o}{=} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Human Activity Detection}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}
                                              \PY{n}{return\PYZus{}space} \PY{o}{=} \PY{k+kc}{True}\PY{p}{)}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}10}]:} \PY{k+kn}{from} \PY{n+nn}{hyperas}\PY{n+nn}{.}\PY{n+nn}{utils} \PY{k}{import} \PY{n}{eval\PYZus{}hyperopt\PYZus{}space}
         \PY{n}{total\PYZus{}trials} \PY{o}{=} \PY{n+nb}{dict}\PY{p}{(}\PY{p}{)}
         \PY{n}{total\PYZus{}list} \PY{o}{=} \PY{p}{[}\PY{p}{]}
         \PY{k}{for} \PY{n}{t}\PY{p}{,} \PY{n}{trial} \PY{o+ow}{in} \PY{n+nb}{enumerate}\PY{p}{(}\PY{n}{trials}\PY{p}{)}\PY{p}{:}
                 \PY{n}{vals} \PY{o}{=} \PY{n}{trial}\PY{o}{.}\PY{n}{get}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{misc}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}\PY{o}{.}\PY{n}{get}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{vals}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
                 \PY{n}{z} \PY{o}{=} \PY{n}{eval\PYZus{}hyperopt\PYZus{}space}\PY{p}{(}\PY{n}{space}\PY{p}{,} \PY{n}{vals}\PY{p}{)}
                 \PY{n}{total\PYZus{}trials}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{M}\PY{l+s+s1}{\PYZsq{}}\PY{o}{+}\PY{n+nb}{str}\PY{p}{(}\PY{n}{t}\PY{o}{+}\PY{l+m+mi}{1}\PY{p}{)}\PY{p}{]} \PY{o}{=} \PY{n}{z}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}11}]:} \PY{n}{best\PYZus{}run}
\end{Verbatim}


\begin{Verbatim}[commandchars=\\\{\}]
{\color{outcolor}Out[{\color{outcolor}11}]:} \{'Dense': 1,
          'Dropout': 0.6397045095598795,
          'batch\_size': 2,
          'choiceval': 0,
          'filters': 1,
          'filters\_1': 1,
          'kernel\_size': 2,
          'kernel\_size\_1': 0,
          'l2': 0.07999281751224634,
          'l2\_1': 0.0012673510937627475,
          'lr': 0.0011215010543928203,
          'lr\_1': 0.0021517590741381726,
          'nb\_epoch': 0,
          'pool\_size': 1\}
\end{Verbatim}
            
    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}12}]:} \PY{c+c1}{\PYZsh{}best Hyper params from hyperas}
         \PY{n}{eval\PYZus{}hyperopt\PYZus{}space}\PY{p}{(}\PY{n}{space}\PY{p}{,} \PY{n}{best\PYZus{}run}\PY{p}{)}
\end{Verbatim}


\begin{Verbatim}[commandchars=\\\{\}]
{\color{outcolor}Out[{\color{outcolor}12}]:} \{'Dense': 64,
          'Dropout': 0.6397045095598795,
          'batch\_size': 64,
          'choiceval': 'adam',
          'filters': 32,
          'filters\_1': 24,
          'kernel\_size': 7,
          'kernel\_size\_1': 3,
          'l2': 0.07999281751224634,
          'l2\_1': 0.0012673510937627475,
          'lr': 0.0011215010543928203,
          'lr\_1': 0.0021517590741381726,
          'nb\_epoch': 25,
          'pool\_size': 3\}
\end{Verbatim}
            
    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}13}]:} \PY{n}{best\PYZus{}model}\PY{o}{.}\PY{n}{summary}\PY{p}{(}\PY{p}{)}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_
Layer (type)                 Output Shape              Param \#   
=================================================================
conv1d\_119 (Conv1D)          (None, 122, 32)           2048      
\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_
conv1d\_120 (Conv1D)          (None, 120, 24)           2328      
\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_
dropout\_60 (Dropout)         (None, 120, 24)           0         
\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_
max\_pooling1d\_60 (MaxPooling (None, 40, 24)            0         
\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_
flatten\_60 (Flatten)         (None, 960)               0         
\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_
dense\_119 (Dense)            (None, 64)                61504     
\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_
dense\_120 (Dense)            (None, 6)                 390       
=================================================================
Total params: 66,270
Trainable params: 66,270
Non-trainable params: 0
\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_

    \end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}14}]:} \PY{n}{\PYZus{}}\PY{p}{,}\PY{n}{acc\PYZus{}val} \PY{o}{=} \PY{n}{best\PYZus{}model}\PY{o}{.}\PY{n}{evaluate}\PY{p}{(}\PY{n}{X\PYZus{}val}\PY{p}{,}\PY{n}{Y\PYZus{}val}\PY{p}{,}\PY{n}{verbose}\PY{o}{=}\PY{l+m+mi}{0}\PY{p}{)}
         \PY{n}{\PYZus{}}\PY{p}{,}\PY{n}{acc\PYZus{}train} \PY{o}{=} \PY{n}{best\PYZus{}model}\PY{o}{.}\PY{n}{evaluate}\PY{p}{(}\PY{n}{X\PYZus{}train}\PY{p}{,}\PY{n}{Y\PYZus{}train}\PY{p}{,}\PY{n}{verbose}\PY{o}{=}\PY{l+m+mi}{0}\PY{p}{)}
         \PY{n+nb}{print}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Train\PYZus{}accuracy}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}\PY{n}{acc\PYZus{}train}\PY{p}{,}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{test\PYZus{}accuracy}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}\PY{n}{acc\PYZus{}val}\PY{p}{)}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
Train\_accuracy 0.963139281828074 test\_accuracy 0.9229725144214456

    \end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}35}]:} \PY{c+c1}{\PYZsh{} Confusion Matrix}
         \PY{n+nb}{print}\PY{p}{(}\PY{n}{confusion\PYZus{}matrix\PYZus{}rnn}\PY{p}{(}\PY{n}{Y\PYZus{}val}\PY{p}{,} \PY{n}{best\PYZus{}model}\PY{o}{.}\PY{n}{predict}\PY{p}{(}\PY{n}{X\PYZus{}val}\PY{p}{)}\PY{p}{)}\PY{p}{)}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
[[537   0   0   0   0   0]
 [  0 385  81   0   0  25]
 [  0  80 452   0   0   0]
 [  0   0   0 484  10   2]
 [  0   0   0   0 415   5]
 [  0   1   0   0  23 447]]

    \end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}44}]:} \PY{k+kn}{import} \PY{n+nn}{matplotlib}\PY{n+nn}{.}\PY{n+nn}{pyplot} \PY{k}{as} \PY{n+nn}{plt}
         \PY{n}{plt}\PY{o}{.}\PY{n}{figure}\PY{p}{(}\PY{n}{figsize}\PY{o}{=}\PY{p}{(}\PY{l+m+mi}{8}\PY{p}{,}\PY{l+m+mi}{8}\PY{p}{)}\PY{p}{)}
         \PY{n}{cm} \PY{o}{=} \PY{n}{confusion\PYZus{}matrix\PYZus{}rnn}\PY{p}{(}\PY{n}{Y\PYZus{}val}\PY{p}{,} \PY{n}{best\PYZus{}model}\PY{o}{.}\PY{n}{predict}\PY{p}{(}\PY{n}{X\PYZus{}val}\PY{p}{)}\PY{p}{)}
         \PY{n}{plot\PYZus{}confusion\PYZus{}matrix}\PY{p}{(}\PY{n}{cm}\PY{p}{,} \PY{n}{classes}\PY{o}{=}\PY{n}{labels}\PY{p}{,} \PY{n}{normalize}\PY{o}{=}\PY{k+kc}{True}\PY{p}{,} \PY{n}{title}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Normalized confusion matrix}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{cmap} \PY{o}{=} \PY{n}{plt}\PY{o}{.}\PY{n}{cm}\PY{o}{.}\PY{n}{Greens}\PY{p}{)}
         \PY{n}{plt}\PY{o}{.}\PY{n}{show}\PY{p}{(}\PY{p}{)}
\end{Verbatim}


    
    \begin{verbatim}
<matplotlib.figure.Figure at 0x14f2465d4da0>
    \end{verbatim}

    
    
    \begin{verbatim}
<matplotlib.figure.Figure at 0x14f24226c4a8>
    \end{verbatim}

    
    
    \begin{verbatim}
<matplotlib.figure.Figure at 0x14f234cbe860>
    \end{verbatim}

    
    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{output_163_3.png}
    \end{center}
    { \hspace*{\fill} \\}
    
    We can observe some overfitting in the model. and it is also giving some
good results and error is mainly due to static activities. so below
model came up wit some different approch to overcome this problem.

    \subsubsection{Divide and
Conquer-Based:}\label{divide-and-conquer-based}

    In the dataset, Y\_labels are represented as numbers from 1 to 6 as
their identifiers.\\
WALKING as 1\\
WALKING\_UPSTAIRS as 2\\
WALKING\_DOWNSTAIRS as 3\\
SITTING as 4\\
STANDING as 5\\
LAYING as 6\\
- in Data exploration section we observed that we can divide the data
into dynamic and static type so devided
walking,waling\_upstairs,walking\_downstairs into category 0 i.e
Dynamic, sitting, standing, laying into category 1 i.e. static. - Will
use 2 more classifiers seperatly for classifying classes of dynamic and
static activities. so that model can learn differnt features for static
and dynamic activities

referred below paper\\
Divide and Conquer-Based 1D CNN Human Activity Recognition Using Test
Data Sharpening ( https://www.mdpi.com/1424-8220/18/4/1055/pdf )

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}2}]:} \PY{k+kn}{import} \PY{n+nn}{os}
        \PY{n}{os}\PY{o}{.}\PY{n}{environ}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{PYTHONHASHSEED}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]} \PY{o}{=} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{0}\PY{l+s+s1}{\PYZsq{}}
        \PY{k+kn}{import} \PY{n+nn}{numpy} \PY{k}{as} \PY{n+nn}{np}
        \PY{k+kn}{import} \PY{n+nn}{tensorflow} \PY{k}{as} \PY{n+nn}{tf}
        \PY{k+kn}{import} \PY{n+nn}{random} \PY{k}{as} \PY{n+nn}{rn}
        \PY{n}{np}\PY{o}{.}\PY{n}{random}\PY{o}{.}\PY{n}{seed}\PY{p}{(}\PY{l+m+mi}{0}\PY{p}{)}
        \PY{n}{rn}\PY{o}{.}\PY{n}{seed}\PY{p}{(}\PY{l+m+mi}{0}\PY{p}{)}
        \PY{n}{tf}\PY{o}{.}\PY{n}{set\PYZus{}random\PYZus{}seed}\PY{p}{(}\PY{l+m+mi}{0}\PY{p}{)}
        \PY{n}{session\PYZus{}conf} \PY{o}{=} \PY{n}{tf}\PY{o}{.}\PY{n}{ConfigProto}\PY{p}{(}\PY{n}{intra\PYZus{}op\PYZus{}parallelism\PYZus{}threads}\PY{o}{=}\PY{l+m+mi}{1}\PY{p}{,}
                                      \PY{n}{inter\PYZus{}op\PYZus{}parallelism\PYZus{}threads}\PY{o}{=}\PY{l+m+mi}{1}\PY{p}{)}
        
        \PY{k+kn}{from} \PY{n+nn}{keras} \PY{k}{import} \PY{n}{backend} \PY{k}{as} \PY{n}{K}
        
        \PY{c+c1}{\PYZsh{} The below tf.set\PYZus{}random\PYZus{}seed() will make random number generation}
        \PY{c+c1}{\PYZsh{} in the TensorFlow backend have a well\PYZhy{}defined initial state.}
        \PY{c+c1}{\PYZsh{} For further details, see:}
        \PY{c+c1}{\PYZsh{} https://www.tensorflow.org/api\PYZus{}docs/python/tf/set\PYZus{}random\PYZus{}seed}
        
        \PY{n}{tf}\PY{o}{.}\PY{n}{set\PYZus{}random\PYZus{}seed}\PY{p}{(}\PY{l+m+mi}{0}\PY{p}{)}
        
        \PY{n}{sess} \PY{o}{=} \PY{n}{tf}\PY{o}{.}\PY{n}{Session}\PY{p}{(}\PY{n}{graph}\PY{o}{=}\PY{n}{tf}\PY{o}{.}\PY{n}{get\PYZus{}default\PYZus{}graph}\PY{p}{(}\PY{p}{)}\PY{p}{,} \PY{n}{config}\PY{o}{=}\PY{n}{session\PYZus{}conf}\PY{p}{)}
        \PY{n}{K}\PY{o}{.}\PY{n}{set\PYZus{}session}\PY{p}{(}\PY{n}{sess}\PY{p}{)}
        
        \PY{c+c1}{\PYZsh{} Importing libraries}
        \PY{k+kn}{import} \PY{n+nn}{pandas} \PY{k}{as} \PY{n+nn}{pd}
        \PY{k+kn}{from} \PY{n+nn}{matplotlib} \PY{k}{import} \PY{n}{pyplot}
        \PY{k+kn}{from} \PY{n+nn}{sklearn}\PY{n+nn}{.}\PY{n+nn}{preprocessing} \PY{k}{import} \PY{n}{StandardScaler}
        \PY{k+kn}{from} \PY{n+nn}{keras}\PY{n+nn}{.}\PY{n+nn}{models} \PY{k}{import} \PY{n}{Sequential}
        \PY{k+kn}{from} \PY{n+nn}{keras}\PY{n+nn}{.}\PY{n+nn}{layers} \PY{k}{import} \PY{n}{Dense}
        \PY{k+kn}{from} \PY{n+nn}{keras}\PY{n+nn}{.}\PY{n+nn}{layers} \PY{k}{import} \PY{n}{Flatten}
        \PY{k+kn}{from} \PY{n+nn}{keras}\PY{n+nn}{.}\PY{n+nn}{layers} \PY{k}{import} \PY{n}{Dropout}
        \PY{k+kn}{from} \PY{n+nn}{keras}\PY{n+nn}{.}\PY{n+nn}{layers}\PY{n+nn}{.}\PY{n+nn}{convolutional} \PY{k}{import} \PY{n}{Conv1D}
        \PY{k+kn}{from} \PY{n+nn}{keras}\PY{n+nn}{.}\PY{n+nn}{layers}\PY{n+nn}{.}\PY{n+nn}{convolutional} \PY{k}{import} \PY{n}{MaxPooling1D}
        \PY{k+kn}{from} \PY{n+nn}{keras}\PY{n+nn}{.}\PY{n+nn}{utils} \PY{k}{import} \PY{n}{to\PYZus{}categorical}
        \PY{k+kn}{from} \PY{n+nn}{keras}\PY{n+nn}{.}\PY{n+nn}{models} \PY{k}{import} \PY{n}{Sequential}
        \PY{k+kn}{from} \PY{n+nn}{keras}\PY{n+nn}{.}\PY{n+nn}{layers} \PY{k}{import} \PY{n}{LSTM}
        \PY{k+kn}{from} \PY{n+nn}{keras}\PY{n+nn}{.}\PY{n+nn}{layers}\PY{n+nn}{.}\PY{n+nn}{core} \PY{k}{import} \PY{n}{Dense}\PY{p}{,} \PY{n}{Dropout}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
Using TensorFlow backend.

    \end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}145}]:} \PY{c+c1}{\PYZsh{}\PYZsh{} Classifying data as 2 class dynamic vs static }
          \PY{c+c1}{\PYZsh{}\PYZsh{}data preparation}
          \PY{k}{def} \PY{n+nf}{data\PYZus{}scaled\PYZus{}2class}\PY{p}{(}\PY{p}{)}\PY{p}{:}
              \PY{l+s+sd}{\PYZdq{}\PYZdq{}\PYZdq{}}
          \PY{l+s+sd}{    Obtain the dataset from multiple files.}
          \PY{l+s+sd}{    Returns: X\PYZus{}train, X\PYZus{}test, y\PYZus{}train, y\PYZus{}test}
          \PY{l+s+sd}{    \PYZdq{}\PYZdq{}\PYZdq{}}
              \PY{c+c1}{\PYZsh{} Data directory}
              \PY{n}{DATADIR} \PY{o}{=} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{UCI\PYZus{}HAR\PYZus{}Dataset}\PY{l+s+s1}{\PYZsq{}}
              \PY{c+c1}{\PYZsh{} Raw data signals}
              \PY{c+c1}{\PYZsh{} Signals are from Accelerometer and Gyroscope}
              \PY{c+c1}{\PYZsh{} The signals are in x,y,z directions}
              \PY{c+c1}{\PYZsh{} Sensor signals are filtered to have only body acceleration}
              \PY{c+c1}{\PYZsh{} excluding the acceleration due to gravity}
              \PY{c+c1}{\PYZsh{} Triaxial acceleration from the accelerometer is total acceleration}
              \PY{n}{SIGNALS} \PY{o}{=} \PY{p}{[}
                  \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{body\PYZus{}acc\PYZus{}x}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,}
                  \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{body\PYZus{}acc\PYZus{}y}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,}
                  \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{body\PYZus{}acc\PYZus{}z}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,}
                  \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{body\PYZus{}gyro\PYZus{}x}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,}
                  \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{body\PYZus{}gyro\PYZus{}y}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,}
                  \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{body\PYZus{}gyro\PYZus{}z}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,}
                  \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{total\PYZus{}acc\PYZus{}x}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,}
                  \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{total\PYZus{}acc\PYZus{}y}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,}
                  \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{total\PYZus{}acc\PYZus{}z}\PY{l+s+s2}{\PYZdq{}}
                  \PY{p}{]}
              \PY{k+kn}{from} \PY{n+nn}{sklearn}\PY{n+nn}{.}\PY{n+nn}{base} \PY{k}{import} \PY{n}{BaseEstimator}\PY{p}{,} \PY{n}{TransformerMixin}
              \PY{k}{class} \PY{n+nc}{scaling\PYZus{}tseries\PYZus{}data}\PY{p}{(}\PY{n}{BaseEstimator}\PY{p}{,} \PY{n}{TransformerMixin}\PY{p}{)}\PY{p}{:}
                  \PY{k+kn}{from} \PY{n+nn}{sklearn}\PY{n+nn}{.}\PY{n+nn}{preprocessing} \PY{k}{import} \PY{n}{StandardScaler}
                  \PY{k}{def} \PY{n+nf}{\PYZus{}\PYZus{}init\PYZus{}\PYZus{}}\PY{p}{(}\PY{n+nb+bp}{self}\PY{p}{)}\PY{p}{:}
                      \PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{scale} \PY{o}{=} \PY{k+kc}{None}
          
                  \PY{k}{def} \PY{n+nf}{transform}\PY{p}{(}\PY{n+nb+bp}{self}\PY{p}{,} \PY{n}{X}\PY{p}{)}\PY{p}{:}
                      \PY{n}{temp\PYZus{}X1} \PY{o}{=} \PY{n}{X}\PY{o}{.}\PY{n}{reshape}\PY{p}{(}\PY{p}{(}\PY{n}{X}\PY{o}{.}\PY{n}{shape}\PY{p}{[}\PY{l+m+mi}{0}\PY{p}{]} \PY{o}{*} \PY{n}{X}\PY{o}{.}\PY{n}{shape}\PY{p}{[}\PY{l+m+mi}{1}\PY{p}{]}\PY{p}{,} \PY{n}{X}\PY{o}{.}\PY{n}{shape}\PY{p}{[}\PY{l+m+mi}{2}\PY{p}{]}\PY{p}{)}\PY{p}{)}
                      \PY{n}{temp\PYZus{}X1} \PY{o}{=} \PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{scale}\PY{o}{.}\PY{n}{transform}\PY{p}{(}\PY{n}{temp\PYZus{}X1}\PY{p}{)}
                      \PY{k}{return} \PY{n}{temp\PYZus{}X1}\PY{o}{.}\PY{n}{reshape}\PY{p}{(}\PY{n}{X}\PY{o}{.}\PY{n}{shape}\PY{p}{)}
          
                  \PY{k}{def} \PY{n+nf}{fit}\PY{p}{(}\PY{n+nb+bp}{self}\PY{p}{,} \PY{n}{X}\PY{p}{)}\PY{p}{:}
                      \PY{c+c1}{\PYZsh{} remove overlaping}
                      \PY{n}{remove} \PY{o}{=} \PY{n+nb}{int}\PY{p}{(}\PY{n}{X}\PY{o}{.}\PY{n}{shape}\PY{p}{[}\PY{l+m+mi}{1}\PY{p}{]} \PY{o}{/} \PY{l+m+mi}{2}\PY{p}{)}
                      \PY{n}{temp\PYZus{}X} \PY{o}{=} \PY{n}{X}\PY{p}{[}\PY{p}{:}\PY{p}{,} \PY{o}{\PYZhy{}}\PY{n}{remove}\PY{p}{:}\PY{p}{,} \PY{p}{:}\PY{p}{]}
                      \PY{c+c1}{\PYZsh{} flatten data}
                      \PY{n}{temp\PYZus{}X} \PY{o}{=} \PY{n}{temp\PYZus{}X}\PY{o}{.}\PY{n}{reshape}\PY{p}{(}\PY{p}{(}\PY{n}{temp\PYZus{}X}\PY{o}{.}\PY{n}{shape}\PY{p}{[}\PY{l+m+mi}{0}\PY{p}{]} \PY{o}{*} \PY{n}{temp\PYZus{}X}\PY{o}{.}\PY{n}{shape}\PY{p}{[}\PY{l+m+mi}{1}\PY{p}{]}\PY{p}{,} \PY{n}{temp\PYZus{}X}\PY{o}{.}\PY{n}{shape}\PY{p}{[}\PY{l+m+mi}{2}\PY{p}{]}\PY{p}{)}\PY{p}{)}
                      \PY{n}{scale} \PY{o}{=} \PY{n}{StandardScaler}\PY{p}{(}\PY{p}{)}
                      \PY{n}{scale}\PY{o}{.}\PY{n}{fit}\PY{p}{(}\PY{n}{temp\PYZus{}X}\PY{p}{)}
                      \PY{c+c1}{\PYZsh{}\PYZsh{}saving for furter usage}
                      \PY{c+c1}{\PYZsh{}\PYZsh{} will use in predicton pipeline}
                      \PY{n}{pickle}\PY{o}{.}\PY{n}{dump}\PY{p}{(}\PY{n}{scale}\PY{p}{,}\PY{n+nb}{open}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Scale\PYZus{}2class.p}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{wb}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}\PY{p}{)}
                      \PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{scale} \PY{o}{=} \PY{n}{scale}
                      \PY{k}{return} \PY{n+nb+bp}{self}
                  
              \PY{c+c1}{\PYZsh{} Utility function to read the data from csv file}
              \PY{k}{def} \PY{n+nf}{\PYZus{}read\PYZus{}csv}\PY{p}{(}\PY{n}{filename}\PY{p}{)}\PY{p}{:}
                  \PY{k}{return} \PY{n}{pd}\PY{o}{.}\PY{n}{read\PYZus{}csv}\PY{p}{(}\PY{n}{filename}\PY{p}{,} \PY{n}{delim\PYZus{}whitespace}\PY{o}{=}\PY{k+kc}{True}\PY{p}{,} \PY{n}{header}\PY{o}{=}\PY{k+kc}{None}\PY{p}{)}
          
              \PY{c+c1}{\PYZsh{} Utility function to load the load}
              \PY{k}{def} \PY{n+nf}{load\PYZus{}signals}\PY{p}{(}\PY{n}{subset}\PY{p}{)}\PY{p}{:}
                  \PY{n}{signals\PYZus{}data} \PY{o}{=} \PY{p}{[}\PY{p}{]}
          
                  \PY{k}{for} \PY{n}{signal} \PY{o+ow}{in} \PY{n}{SIGNALS}\PY{p}{:}
                      \PY{n}{filename} \PY{o}{=} \PY{n}{f}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{UCI\PYZus{}HAR\PYZus{}Dataset/}\PY{l+s+si}{\PYZob{}subset\PYZcb{}}\PY{l+s+s1}{/Inertial Signals/}\PY{l+s+si}{\PYZob{}signal\PYZcb{}}\PY{l+s+s1}{\PYZus{}}\PY{l+s+si}{\PYZob{}subset\PYZcb{}}\PY{l+s+s1}{.txt}\PY{l+s+s1}{\PYZsq{}}
                      \PY{n}{signals\PYZus{}data}\PY{o}{.}\PY{n}{append}\PY{p}{(} \PY{n}{\PYZus{}read\PYZus{}csv}\PY{p}{(}\PY{n}{filename}\PY{p}{)}\PY{o}{.}\PY{n}{as\PYZus{}matrix}\PY{p}{(}\PY{p}{)}\PY{p}{)} 
          
                  \PY{c+c1}{\PYZsh{} Transpose is used to change the dimensionality of the output,}
                  \PY{c+c1}{\PYZsh{} aggregating the signals by combination of sample/timestep.}
                  \PY{c+c1}{\PYZsh{} Resultant shape is (7352 train/2947 test samples, 128 timesteps, 9 signals)}
                  \PY{k}{return} \PY{n}{np}\PY{o}{.}\PY{n}{transpose}\PY{p}{(}\PY{n}{signals\PYZus{}data}\PY{p}{,} \PY{p}{(}\PY{l+m+mi}{1}\PY{p}{,} \PY{l+m+mi}{2}\PY{p}{,} \PY{l+m+mi}{0}\PY{p}{)}\PY{p}{)}
              
              \PY{k}{def} \PY{n+nf}{load\PYZus{}y}\PY{p}{(}\PY{n}{subset}\PY{p}{)}\PY{p}{:}
                  \PY{l+s+sd}{\PYZdq{}\PYZdq{}\PYZdq{}}
          \PY{l+s+sd}{        The objective that we are trying to predict is a integer, from 1 to 6,}
          \PY{l+s+sd}{        that represents a human activity. We return a binary representation of }
          \PY{l+s+sd}{        every sample objective as a 6 bits vector using One Hot Encoding}
          \PY{l+s+sd}{        (https://pandas.pydata.org/pandas\PYZhy{}docs/stable/generated/pandas.get\PYZus{}dummies.html)}
          \PY{l+s+sd}{        \PYZdq{}\PYZdq{}\PYZdq{}}
                  \PY{n}{filename} \PY{o}{=} \PY{n}{f}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{UCI\PYZus{}HAR\PYZus{}Dataset/}\PY{l+s+si}{\PYZob{}subset\PYZcb{}}\PY{l+s+s1}{/y\PYZus{}}\PY{l+s+si}{\PYZob{}subset\PYZcb{}}\PY{l+s+s1}{.txt}\PY{l+s+s1}{\PYZsq{}}
                  \PY{n}{y} \PY{o}{=} \PY{n}{\PYZus{}read\PYZus{}csv}\PY{p}{(}\PY{n}{filename}\PY{p}{)}\PY{p}{[}\PY{l+m+mi}{0}\PY{p}{]}
                  \PY{n}{y}\PY{p}{[}\PY{n}{y}\PY{o}{\PYZlt{}}\PY{o}{=}\PY{l+m+mi}{3}\PY{p}{]} \PY{o}{=} \PY{l+m+mi}{0}
                  \PY{n}{y}\PY{p}{[}\PY{n}{y}\PY{o}{\PYZgt{}}\PY{l+m+mi}{3}\PY{p}{]} \PY{o}{=} \PY{l+m+mi}{1}
                  \PY{k}{return} \PY{n}{pd}\PY{o}{.}\PY{n}{get\PYZus{}dummies}\PY{p}{(}\PY{n}{y}\PY{p}{)}\PY{o}{.}\PY{n}{as\PYZus{}matrix}\PY{p}{(}\PY{p}{)}
              
              \PY{n}{X\PYZus{}train\PYZus{}2c}\PY{p}{,} \PY{n}{X\PYZus{}val\PYZus{}2c} \PY{o}{=} \PY{n}{load\PYZus{}signals}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{train}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}\PY{p}{,} \PY{n}{load\PYZus{}signals}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{test}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
              \PY{n}{Y\PYZus{}train\PYZus{}2c}\PY{p}{,} \PY{n}{Y\PYZus{}val\PYZus{}2c} \PY{o}{=} \PY{n}{load\PYZus{}y}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{train}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}\PY{p}{,} \PY{n}{load\PYZus{}y}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{test}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
              \PY{c+c1}{\PYZsh{}\PYZsh{}\PYZsh{}Scling data}
              \PY{n}{Scale} \PY{o}{=} \PY{n}{scaling\PYZus{}tseries\PYZus{}data}\PY{p}{(}\PY{p}{)}
              \PY{n}{Scale}\PY{o}{.}\PY{n}{fit}\PY{p}{(}\PY{n}{X\PYZus{}train\PYZus{}2c}\PY{p}{)}
              \PY{n}{X\PYZus{}train\PYZus{}2c} \PY{o}{=} \PY{n}{Scale}\PY{o}{.}\PY{n}{transform}\PY{p}{(}\PY{n}{X\PYZus{}train\PYZus{}2c}\PY{p}{)}
              \PY{n}{X\PYZus{}val\PYZus{}2c} \PY{o}{=} \PY{n}{Scale}\PY{o}{.}\PY{n}{transform}\PY{p}{(}\PY{n}{X\PYZus{}val\PYZus{}2c}\PY{p}{)}
              \PY{k}{return} \PY{n}{X\PYZus{}train\PYZus{}2c}\PY{p}{,} \PY{n}{Y\PYZus{}train\PYZus{}2c}\PY{p}{,} \PY{n}{X\PYZus{}val\PYZus{}2c}\PY{p}{,}  \PY{n}{Y\PYZus{}val\PYZus{}2c}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}144}]:} \PY{n}{X\PYZus{}train\PYZus{}2c}\PY{p}{,} \PY{n}{Y\PYZus{}train\PYZus{}2c}\PY{p}{,} \PY{n}{X\PYZus{}val\PYZus{}2c}\PY{p}{,}  \PY{n}{Y\PYZus{}val\PYZus{}2c} \PY{o}{=} \PY{n}{data\PYZus{}scaled\PYZus{}2class}\PY{p}{(}\PY{p}{)}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}68}]:} \PY{n+nb}{print}\PY{p}{(}\PY{n}{Y\PYZus{}train\PYZus{}2c}\PY{o}{.}\PY{n}{shape}\PY{p}{)}
         \PY{n+nb}{print}\PY{p}{(}\PY{n}{Y\PYZus{}val\PYZus{}2c}\PY{o}{.}\PY{n}{shape}\PY{p}{)}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
(7352, 2)
(2947, 2)

    \end{Verbatim}

    \paragraph{Model for classifying data into Static and Dynamic
activities}\label{model-for-classifying-data-into-static-and-dynamic-activities}

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}72}]:} \PY{n}{K}\PY{o}{.}\PY{n}{clear\PYZus{}session}\PY{p}{(}\PY{p}{)}
         \PY{n}{np}\PY{o}{.}\PY{n}{random}\PY{o}{.}\PY{n}{seed}\PY{p}{(}\PY{l+m+mi}{0}\PY{p}{)}
         \PY{n}{tf}\PY{o}{.}\PY{n}{set\PYZus{}random\PYZus{}seed}\PY{p}{(}\PY{l+m+mi}{0}\PY{p}{)}
         \PY{n}{sess} \PY{o}{=} \PY{n}{tf}\PY{o}{.}\PY{n}{Session}\PY{p}{(}\PY{n}{graph}\PY{o}{=}\PY{n}{tf}\PY{o}{.}\PY{n}{get\PYZus{}default\PYZus{}graph}\PY{p}{(}\PY{p}{)}\PY{p}{)}
         \PY{n}{K}\PY{o}{.}\PY{n}{set\PYZus{}session}\PY{p}{(}\PY{n}{sess}\PY{p}{)}
         \PY{n}{model} \PY{o}{=} \PY{n}{Sequential}\PY{p}{(}\PY{p}{)}
         \PY{n}{model}\PY{o}{.}\PY{n}{add}\PY{p}{(}\PY{n}{Conv1D}\PY{p}{(}\PY{n}{filters}\PY{o}{=}\PY{l+m+mi}{32}\PY{p}{,} \PY{n}{kernel\PYZus{}size}\PY{o}{=}\PY{l+m+mi}{3}\PY{p}{,} \PY{n}{activation}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{relu}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}\PY{n}{kernel\PYZus{}initializer}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{he\PYZus{}uniform}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}\PY{n}{input\PYZus{}shape}\PY{o}{=}\PY{p}{(}\PY{l+m+mi}{128}\PY{p}{,}\PY{l+m+mi}{9}\PY{p}{)}\PY{p}{)}\PY{p}{)}
         \PY{n}{model}\PY{o}{.}\PY{n}{add}\PY{p}{(}\PY{n}{Conv1D}\PY{p}{(}\PY{n}{filters}\PY{o}{=}\PY{l+m+mi}{32}\PY{p}{,} \PY{n}{kernel\PYZus{}size}\PY{o}{=}\PY{l+m+mi}{3}\PY{p}{,} \PY{n}{activation}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{relu}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}\PY{n}{kernel\PYZus{}initializer}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{he\PYZus{}uniform}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}\PY{p}{)}
         \PY{n}{model}\PY{o}{.}\PY{n}{add}\PY{p}{(}\PY{n}{Dropout}\PY{p}{(}\PY{l+m+mf}{0.6}\PY{p}{)}\PY{p}{)}
         \PY{n}{model}\PY{o}{.}\PY{n}{add}\PY{p}{(}\PY{n}{MaxPooling1D}\PY{p}{(}\PY{n}{pool\PYZus{}size}\PY{o}{=}\PY{l+m+mi}{2}\PY{p}{)}\PY{p}{)}
         \PY{n}{model}\PY{o}{.}\PY{n}{add}\PY{p}{(}\PY{n}{Flatten}\PY{p}{(}\PY{p}{)}\PY{p}{)}
         \PY{n}{model}\PY{o}{.}\PY{n}{add}\PY{p}{(}\PY{n}{Dense}\PY{p}{(}\PY{l+m+mi}{50}\PY{p}{,} \PY{n}{activation}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{relu}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}\PY{p}{)}
         \PY{n}{model}\PY{o}{.}\PY{n}{add}\PY{p}{(}\PY{n}{Dense}\PY{p}{(}\PY{l+m+mi}{2}\PY{p}{,} \PY{n}{activation}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{softmax}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}\PY{p}{)}
         \PY{n}{model}\PY{o}{.}\PY{n}{summary}\PY{p}{(}\PY{p}{)}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_
Layer (type)                 Output Shape              Param \#   
=================================================================
conv1d\_1 (Conv1D)            (None, 126, 32)           896       
\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_
conv1d\_2 (Conv1D)            (None, 124, 32)           3104      
\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_
dropout\_1 (Dropout)          (None, 124, 32)           0         
\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_
max\_pooling1d\_1 (MaxPooling1 (None, 62, 32)            0         
\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_
flatten\_1 (Flatten)          (None, 1984)              0         
\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_
dense\_1 (Dense)              (None, 50)                99250     
\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_
dense\_2 (Dense)              (None, 2)                 102       
=================================================================
Total params: 103,352
Trainable params: 103,352
Non-trainable params: 0
\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_

    \end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}73}]:} \PY{k+kn}{import} \PY{n+nn}{math}
         \PY{n}{adam} \PY{o}{=} \PY{n}{keras}\PY{o}{.}\PY{n}{optimizers}\PY{o}{.}\PY{n}{Adam}\PY{p}{(}\PY{n}{lr}\PY{o}{=}\PY{l+m+mf}{0.001}\PY{p}{)}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}74}]:} \PY{n}{model}\PY{o}{.}\PY{n}{compile}\PY{p}{(}\PY{n}{loss}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{categorical\PYZus{}crossentropy}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{optimizer}\PY{o}{=}\PY{n}{adam}\PY{p}{,} \PY{n}{metrics}\PY{o}{=}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{accuracy}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{)}
         \PY{n}{model}\PY{o}{.}\PY{n}{fit}\PY{p}{(}\PY{n}{X\PYZus{}train\PYZus{}2c}\PY{p}{,}\PY{n}{Y\PYZus{}train\PYZus{}2c}\PY{p}{,} \PY{n}{epochs}\PY{o}{=}\PY{l+m+mi}{20}\PY{p}{,} \PY{n}{batch\PYZus{}size}\PY{o}{=}\PY{l+m+mi}{16}\PY{p}{,}\PY{n}{validation\PYZus{}data}\PY{o}{=}\PY{p}{(}\PY{n}{X\PYZus{}val\PYZus{}2c}\PY{p}{,} \PY{n}{Y\PYZus{}val\PYZus{}2c}\PY{p}{)}\PY{p}{,} \PY{n}{verbose}\PY{o}{=}\PY{l+m+mi}{1}\PY{p}{)}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
Train on 7352 samples, validate on 2947 samples
Epoch 1/20
7352/7352 [==============================] - 4s 580us/step - loss: 0.0549 - acc: 0.9791 - val\_loss: 0.0127 - val\_acc: 0.9973
Epoch 2/20
7352/7352 [==============================] - 4s 482us/step - loss: 0.0021 - acc: 0.9995 - val\_loss: 0.0120 - val\_acc: 0.9969
Epoch 3/20
7352/7352 [==============================] - 4s 484us/step - loss: 7.9422e-04 - acc: 0.9997 - val\_loss: 0.0122 - val\_acc: 0.9936
Epoch 4/20
7352/7352 [==============================] - 4s 483us/step - loss: 0.0029 - acc: 0.9990 - val\_loss: 0.0168 - val\_acc: 0.9963
Epoch 5/20
7352/7352 [==============================] - 4s 481us/step - loss: 1.3106e-04 - acc: 1.0000 - val\_loss: 0.0102 - val\_acc: 0.9986
Epoch 6/20
7352/7352 [==============================] - 4s 480us/step - loss: 1.7091e-05 - acc: 1.0000 - val\_loss: 0.0124 - val\_acc: 0.9983
Epoch 7/20
7352/7352 [==============================] - 4s 480us/step - loss: 0.0022 - acc: 0.9997 - val\_loss: 0.0162 - val\_acc: 0.9932
Epoch 8/20
7352/7352 [==============================] - 4s 481us/step - loss: 0.0051 - acc: 0.9989 - val\_loss: 0.0063 - val\_acc: 0.9993
Epoch 9/20
7352/7352 [==============================] - 4s 480us/step - loss: 3.4291e-05 - acc: 1.0000 - val\_loss: 0.0101 - val\_acc: 0.9966
Epoch 10/20
7352/7352 [==============================] - 4s 478us/step - loss: 2.1046e-04 - acc: 0.9999 - val\_loss: 0.0056 - val\_acc: 0.9993
Epoch 11/20
7352/7352 [==============================] - 4s 482us/step - loss: 3.0157e-05 - acc: 1.0000 - val\_loss: 0.0079 - val\_acc: 0.9986
Epoch 12/20
7352/7352 [==============================] - 4s 482us/step - loss: 5.7799e-06 - acc: 1.0000 - val\_loss: 0.0070 - val\_acc: 0.9990
Epoch 13/20
7352/7352 [==============================] - 4s 481us/step - loss: 1.4363e-06 - acc: 1.0000 - val\_loss: 0.0071 - val\_acc: 0.9990
Epoch 14/20
7352/7352 [==============================] - 4s 480us/step - loss: 1.1018e-06 - acc: 1.0000 - val\_loss: 0.0071 - val\_acc: 0.9990
Epoch 15/20
7352/7352 [==============================] - 4s 483us/step - loss: 7.5717e-07 - acc: 1.0000 - val\_loss: 0.0070 - val\_acc: 0.9990
Epoch 16/20
7352/7352 [==============================] - 4s 480us/step - loss: 4.7786e-07 - acc: 1.0000 - val\_loss: 0.0071 - val\_acc: 0.9990
Epoch 17/20
7352/7352 [==============================] - 4s 480us/step - loss: 1.0220e-06 - acc: 1.0000 - val\_loss: 0.0071 - val\_acc: 0.9990
Epoch 18/20
7352/7352 [==============================] - 4s 480us/step - loss: 1.7438e-06 - acc: 1.0000 - val\_loss: 0.0066 - val\_acc: 0.9990
Epoch 19/20
7352/7352 [==============================] - 4s 487us/step - loss: 6.3406e-07 - acc: 1.0000 - val\_loss: 0.0069 - val\_acc: 0.9990
Epoch 20/20
7352/7352 [==============================] - 4s 480us/step - loss: 5.5710e-07 - acc: 1.0000 - val\_loss: 0.0072 - val\_acc: 0.9990

    \end{Verbatim}

\begin{Verbatim}[commandchars=\\\{\}]
{\color{outcolor}Out[{\color{outcolor}74}]:} <keras.callbacks.History at 0x1474816b9358>
\end{Verbatim}
            
    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}75}]:} \PY{n}{\PYZus{}}\PY{p}{,}\PY{n}{acc\PYZus{}val} \PY{o}{=} \PY{n}{model}\PY{o}{.}\PY{n}{evaluate}\PY{p}{(}\PY{n}{X\PYZus{}val\PYZus{}2c}\PY{p}{,}\PY{n}{Y\PYZus{}val\PYZus{}2c}\PY{p}{,}\PY{n}{verbose}\PY{o}{=}\PY{l+m+mi}{0}\PY{p}{)}
         \PY{n}{\PYZus{}}\PY{p}{,}\PY{n}{acc\PYZus{}train} \PY{o}{=} \PY{n}{model}\PY{o}{.}\PY{n}{evaluate}\PY{p}{(}\PY{n}{X\PYZus{}train\PYZus{}2c}\PY{p}{,}\PY{n}{Y\PYZus{}train\PYZus{}2c}\PY{p}{,}\PY{n}{verbose}\PY{o}{=}\PY{l+m+mi}{0}\PY{p}{)}
         \PY{n+nb}{print}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Train\PYZus{}accuracy}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}\PY{n}{acc\PYZus{}train}\PY{p}{,}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{test\PYZus{}accuracy}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}\PY{n}{acc\PYZus{}val}\PY{p}{)}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
Train\_accuracy 1.0 test\_accuracy 0.9989820156090939

    \end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}76}]:} \PY{c+c1}{\PYZsh{}\PYZsh{}saving model}
         \PY{n}{model}\PY{o}{.}\PY{n}{save}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{final\PYZus{}model\PYZus{}2class.h5}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
\end{Verbatim}


    This model is almost classifying data into dynammic or static correctly
with very hig accuracy.

    \subsubsection{Classificaton of Static
activities}\label{classificaton-of-static-activities}

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}149}]:} \PY{c+c1}{\PYZsh{}\PYZsh{}data preparation}
          \PY{k}{def} \PY{n+nf}{data\PYZus{}scaled\PYZus{}static}\PY{p}{(}\PY{p}{)}\PY{p}{:}
              \PY{l+s+sd}{\PYZdq{}\PYZdq{}\PYZdq{}}
          \PY{l+s+sd}{    Obtain the dataset from multiple files.}
          \PY{l+s+sd}{    Returns: X\PYZus{}train, X\PYZus{}test, y\PYZus{}train, y\PYZus{}test}
          \PY{l+s+sd}{    \PYZdq{}\PYZdq{}\PYZdq{}}
              \PY{c+c1}{\PYZsh{} Data directory}
              \PY{n}{DATADIR} \PY{o}{=} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{UCI\PYZus{}HAR\PYZus{}Dataset}\PY{l+s+s1}{\PYZsq{}}
              \PY{c+c1}{\PYZsh{} Raw data signals}
              \PY{c+c1}{\PYZsh{} Signals are from Accelerometer and Gyroscope}
              \PY{c+c1}{\PYZsh{} The signals are in x,y,z directions}
              \PY{c+c1}{\PYZsh{} Sensor signals are filtered to have only body acceleration}
              \PY{c+c1}{\PYZsh{} excluding the acceleration due to gravity}
              \PY{c+c1}{\PYZsh{} Triaxial acceleration from the accelerometer is total acceleration}
              \PY{n}{SIGNALS} \PY{o}{=} \PY{p}{[}
                  \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{body\PYZus{}acc\PYZus{}x}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,}
                  \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{body\PYZus{}acc\PYZus{}y}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,}
                  \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{body\PYZus{}acc\PYZus{}z}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,}
                  \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{body\PYZus{}gyro\PYZus{}x}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,}
                  \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{body\PYZus{}gyro\PYZus{}y}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,}
                  \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{body\PYZus{}gyro\PYZus{}z}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,}
                  \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{total\PYZus{}acc\PYZus{}x}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,}
                  \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{total\PYZus{}acc\PYZus{}y}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,}
                  \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{total\PYZus{}acc\PYZus{}z}\PY{l+s+s2}{\PYZdq{}}
                  \PY{p}{]}
              \PY{k+kn}{from} \PY{n+nn}{sklearn}\PY{n+nn}{.}\PY{n+nn}{base} \PY{k}{import} \PY{n}{BaseEstimator}\PY{p}{,} \PY{n}{TransformerMixin}
              \PY{k}{class} \PY{n+nc}{scaling\PYZus{}tseries\PYZus{}data}\PY{p}{(}\PY{n}{BaseEstimator}\PY{p}{,} \PY{n}{TransformerMixin}\PY{p}{)}\PY{p}{:}
                  \PY{k+kn}{from} \PY{n+nn}{sklearn}\PY{n+nn}{.}\PY{n+nn}{preprocessing} \PY{k}{import} \PY{n}{StandardScaler}
                  \PY{k}{def} \PY{n+nf}{\PYZus{}\PYZus{}init\PYZus{}\PYZus{}}\PY{p}{(}\PY{n+nb+bp}{self}\PY{p}{)}\PY{p}{:}
                      \PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{scale} \PY{o}{=} \PY{k+kc}{None}
          
                  \PY{k}{def} \PY{n+nf}{transform}\PY{p}{(}\PY{n+nb+bp}{self}\PY{p}{,} \PY{n}{X}\PY{p}{)}\PY{p}{:}
                      \PY{n}{temp\PYZus{}X1} \PY{o}{=} \PY{n}{X}\PY{o}{.}\PY{n}{reshape}\PY{p}{(}\PY{p}{(}\PY{n}{X}\PY{o}{.}\PY{n}{shape}\PY{p}{[}\PY{l+m+mi}{0}\PY{p}{]} \PY{o}{*} \PY{n}{X}\PY{o}{.}\PY{n}{shape}\PY{p}{[}\PY{l+m+mi}{1}\PY{p}{]}\PY{p}{,} \PY{n}{X}\PY{o}{.}\PY{n}{shape}\PY{p}{[}\PY{l+m+mi}{2}\PY{p}{]}\PY{p}{)}\PY{p}{)}
                      \PY{n}{temp\PYZus{}X1} \PY{o}{=} \PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{scale}\PY{o}{.}\PY{n}{transform}\PY{p}{(}\PY{n}{temp\PYZus{}X1}\PY{p}{)}
                      \PY{k}{return} \PY{n}{temp\PYZus{}X1}\PY{o}{.}\PY{n}{reshape}\PY{p}{(}\PY{n}{X}\PY{o}{.}\PY{n}{shape}\PY{p}{)}
          
                  \PY{k}{def} \PY{n+nf}{fit}\PY{p}{(}\PY{n+nb+bp}{self}\PY{p}{,} \PY{n}{X}\PY{p}{)}\PY{p}{:}
                      \PY{c+c1}{\PYZsh{} remove overlaping}
                      \PY{n}{remove} \PY{o}{=} \PY{n+nb}{int}\PY{p}{(}\PY{n}{X}\PY{o}{.}\PY{n}{shape}\PY{p}{[}\PY{l+m+mi}{1}\PY{p}{]} \PY{o}{/} \PY{l+m+mi}{2}\PY{p}{)}
                      \PY{n}{temp\PYZus{}X} \PY{o}{=} \PY{n}{X}\PY{p}{[}\PY{p}{:}\PY{p}{,} \PY{o}{\PYZhy{}}\PY{n}{remove}\PY{p}{:}\PY{p}{,} \PY{p}{:}\PY{p}{]}
                      \PY{c+c1}{\PYZsh{} flatten data}
                      \PY{n}{temp\PYZus{}X} \PY{o}{=} \PY{n}{temp\PYZus{}X}\PY{o}{.}\PY{n}{reshape}\PY{p}{(}\PY{p}{(}\PY{n}{temp\PYZus{}X}\PY{o}{.}\PY{n}{shape}\PY{p}{[}\PY{l+m+mi}{0}\PY{p}{]} \PY{o}{*} \PY{n}{temp\PYZus{}X}\PY{o}{.}\PY{n}{shape}\PY{p}{[}\PY{l+m+mi}{1}\PY{p}{]}\PY{p}{,} \PY{n}{temp\PYZus{}X}\PY{o}{.}\PY{n}{shape}\PY{p}{[}\PY{l+m+mi}{2}\PY{p}{]}\PY{p}{)}\PY{p}{)}
                      \PY{n}{scale} \PY{o}{=} \PY{n}{StandardScaler}\PY{p}{(}\PY{p}{)}
                      \PY{n}{scale}\PY{o}{.}\PY{n}{fit}\PY{p}{(}\PY{n}{temp\PYZus{}X}\PY{p}{)}
                      \PY{c+c1}{\PYZsh{}for furter use at prediction pipeline}
                      \PY{n}{pickle}\PY{o}{.}\PY{n}{dump}\PY{p}{(}\PY{n}{scale}\PY{p}{,}\PY{n+nb}{open}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Scale\PYZus{}static.p}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{wb}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}\PY{p}{)}
                      \PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{scale} \PY{o}{=} \PY{n}{scale}
                      \PY{k}{return} \PY{n+nb+bp}{self}
                  
              \PY{c+c1}{\PYZsh{} Utility function to read the data from csv file}
              \PY{k}{def} \PY{n+nf}{\PYZus{}read\PYZus{}csv}\PY{p}{(}\PY{n}{filename}\PY{p}{)}\PY{p}{:}
                  \PY{k}{return} \PY{n}{pd}\PY{o}{.}\PY{n}{read\PYZus{}csv}\PY{p}{(}\PY{n}{filename}\PY{p}{,} \PY{n}{delim\PYZus{}whitespace}\PY{o}{=}\PY{k+kc}{True}\PY{p}{,} \PY{n}{header}\PY{o}{=}\PY{k+kc}{None}\PY{p}{)}
          
              \PY{c+c1}{\PYZsh{} Utility function to load the load}
              \PY{k}{def} \PY{n+nf}{load\PYZus{}signals}\PY{p}{(}\PY{n}{subset}\PY{p}{)}\PY{p}{:}
                  \PY{n}{signals\PYZus{}data} \PY{o}{=} \PY{p}{[}\PY{p}{]}
          
                  \PY{k}{for} \PY{n}{signal} \PY{o+ow}{in} \PY{n}{SIGNALS}\PY{p}{:}
                      \PY{n}{filename} \PY{o}{=} \PY{n}{f}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{UCI\PYZus{}HAR\PYZus{}Dataset/}\PY{l+s+si}{\PYZob{}subset\PYZcb{}}\PY{l+s+s1}{/Inertial Signals/}\PY{l+s+si}{\PYZob{}signal\PYZcb{}}\PY{l+s+s1}{\PYZus{}}\PY{l+s+si}{\PYZob{}subset\PYZcb{}}\PY{l+s+s1}{.txt}\PY{l+s+s1}{\PYZsq{}}
                      \PY{n}{signals\PYZus{}data}\PY{o}{.}\PY{n}{append}\PY{p}{(} \PY{n}{\PYZus{}read\PYZus{}csv}\PY{p}{(}\PY{n}{filename}\PY{p}{)}\PY{o}{.}\PY{n}{as\PYZus{}matrix}\PY{p}{(}\PY{p}{)}\PY{p}{)} 
          
                  \PY{c+c1}{\PYZsh{} Transpose is used to change the dimensionality of the output,}
                  \PY{c+c1}{\PYZsh{} aggregating the signals by combination of sample/timestep.}
                  \PY{c+c1}{\PYZsh{} Resultant shape is (7352 train/2947 test samples, 128 timesteps, 9 signals)}
                  \PY{k}{return} \PY{n}{np}\PY{o}{.}\PY{n}{transpose}\PY{p}{(}\PY{n}{signals\PYZus{}data}\PY{p}{,} \PY{p}{(}\PY{l+m+mi}{1}\PY{p}{,} \PY{l+m+mi}{2}\PY{p}{,} \PY{l+m+mi}{0}\PY{p}{)}\PY{p}{)}
              
              \PY{k}{def} \PY{n+nf}{load\PYZus{}y}\PY{p}{(}\PY{n}{subset}\PY{p}{)}\PY{p}{:}
                  \PY{l+s+sd}{\PYZdq{}\PYZdq{}\PYZdq{}}
          \PY{l+s+sd}{        The objective that we are trying to predict is a integer, from 1 to 6,}
          \PY{l+s+sd}{        that represents a human activity. We return a binary representation of }
          \PY{l+s+sd}{        every sample objective as a 6 bits vector using One Hot Encoding}
          \PY{l+s+sd}{        (https://pandas.pydata.org/pandas\PYZhy{}docs/stable/generated/pandas.get\PYZus{}dummies.html)}
          \PY{l+s+sd}{        \PYZdq{}\PYZdq{}\PYZdq{}}
                  \PY{n}{filename} \PY{o}{=} \PY{n}{f}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{UCI\PYZus{}HAR\PYZus{}Dataset/}\PY{l+s+si}{\PYZob{}subset\PYZcb{}}\PY{l+s+s1}{/y\PYZus{}}\PY{l+s+si}{\PYZob{}subset\PYZcb{}}\PY{l+s+s1}{.txt}\PY{l+s+s1}{\PYZsq{}}
                  \PY{n}{y} \PY{o}{=} \PY{n}{\PYZus{}read\PYZus{}csv}\PY{p}{(}\PY{n}{filename}\PY{p}{)}\PY{p}{[}\PY{l+m+mi}{0}\PY{p}{]}
                  \PY{n}{y\PYZus{}subset} \PY{o}{=} \PY{n}{y}\PY{o}{\PYZgt{}}\PY{l+m+mi}{3}
                  \PY{n}{y} \PY{o}{=} \PY{n}{y}\PY{p}{[}\PY{n}{y\PYZus{}subset}\PY{p}{]}
                  \PY{k}{return} \PY{n}{pd}\PY{o}{.}\PY{n}{get\PYZus{}dummies}\PY{p}{(}\PY{n}{y}\PY{p}{)}\PY{o}{.}\PY{n}{as\PYZus{}matrix}\PY{p}{(}\PY{p}{)}\PY{p}{,}\PY{n}{y\PYZus{}subset}
              
              \PY{n}{Y\PYZus{}train\PYZus{}s}\PY{p}{,}\PY{n}{y\PYZus{}train\PYZus{}sub} \PY{o}{=} \PY{n}{load\PYZus{}y}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{train}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
              \PY{n}{Y\PYZus{}val\PYZus{}s}\PY{p}{,}\PY{n}{y\PYZus{}test\PYZus{}sub} \PY{o}{=} \PY{n}{load\PYZus{}y}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{test}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
              \PY{n}{X\PYZus{}train\PYZus{}s}\PY{p}{,} \PY{n}{X\PYZus{}val\PYZus{}s} \PY{o}{=} \PY{n}{load\PYZus{}signals}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{train}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}\PY{p}{,} \PY{n}{load\PYZus{}signals}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{test}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
              \PY{n}{X\PYZus{}train\PYZus{}s} \PY{o}{=} \PY{n}{X\PYZus{}train\PYZus{}s}\PY{p}{[}\PY{n}{y\PYZus{}train\PYZus{}sub}\PY{p}{]}
              \PY{n}{X\PYZus{}val\PYZus{}s} \PY{o}{=} \PY{n}{X\PYZus{}val\PYZus{}s}\PY{p}{[}\PY{n}{y\PYZus{}test\PYZus{}sub}\PY{p}{]}
              
              \PY{c+c1}{\PYZsh{}\PYZsh{}\PYZsh{}Scling data}
              \PY{n}{Scale} \PY{o}{=} \PY{n}{scaling\PYZus{}tseries\PYZus{}data}\PY{p}{(}\PY{p}{)}
              \PY{n}{Scale}\PY{o}{.}\PY{n}{fit}\PY{p}{(}\PY{n}{X\PYZus{}train\PYZus{}s}\PY{p}{)}
              \PY{n}{X\PYZus{}train\PYZus{}s} \PY{o}{=} \PY{n}{Scale}\PY{o}{.}\PY{n}{transform}\PY{p}{(}\PY{n}{X\PYZus{}train\PYZus{}s}\PY{p}{)}
              \PY{n}{X\PYZus{}val\PYZus{}s} \PY{o}{=} \PY{n}{Scale}\PY{o}{.}\PY{n}{transform}\PY{p}{(}\PY{n}{X\PYZus{}val\PYZus{}s}\PY{p}{)}
          
              \PY{k}{return} \PY{n}{X\PYZus{}train\PYZus{}s}\PY{p}{,} \PY{n}{Y\PYZus{}train\PYZus{}s}\PY{p}{,} \PY{n}{X\PYZus{}val\PYZus{}s}\PY{p}{,}  \PY{n}{Y\PYZus{}val\PYZus{}s}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}150}]:} \PY{n}{X\PYZus{}train\PYZus{}s}\PY{p}{,} \PY{n}{Y\PYZus{}train\PYZus{}s}\PY{p}{,} \PY{n}{X\PYZus{}val\PYZus{}s}\PY{p}{,}  \PY{n}{Y\PYZus{}val\PYZus{}s} \PY{o}{=} \PY{n}{data\PYZus{}scaled\PYZus{}static}\PY{p}{(}\PY{p}{)}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}7}]:} \PY{n+nb}{print}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{X Shape of train data}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}\PY{n}{X\PYZus{}train\PYZus{}s}\PY{o}{.}\PY{n}{shape}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Y shape}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{Y\PYZus{}train\PYZus{}s}\PY{o}{.}\PY{n}{shape}\PY{p}{)}
        \PY{n+nb}{print}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{X Shape of val data}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}\PY{n}{X\PYZus{}val\PYZus{}s}\PY{o}{.}\PY{n}{shape}\PY{p}{,}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Y shape}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}\PY{n}{Y\PYZus{}val\PYZus{}s}\PY{o}{.}\PY{n}{shape}\PY{p}{)}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
X Shape of train data (4067, 128, 9) Y shape (4067, 3)
X Shape of val data (1560, 128, 9) Y shape (1560, 3)

    \end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}8}]:} \PY{k+kn}{import} \PY{n+nn}{keras}
\end{Verbatim}


    \paragraph{Baseline Model}\label{baseline-model}

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}24}]:} \PY{n}{np}\PY{o}{.}\PY{n}{random}\PY{o}{.}\PY{n}{seed}\PY{p}{(}\PY{l+m+mi}{0}\PY{p}{)}
         \PY{n}{tf}\PY{o}{.}\PY{n}{set\PYZus{}random\PYZus{}seed}\PY{p}{(}\PY{l+m+mi}{0}\PY{p}{)}
         \PY{n}{sess} \PY{o}{=} \PY{n}{tf}\PY{o}{.}\PY{n}{Session}\PY{p}{(}\PY{n}{graph}\PY{o}{=}\PY{n}{tf}\PY{o}{.}\PY{n}{get\PYZus{}default\PYZus{}graph}\PY{p}{(}\PY{p}{)}\PY{p}{)}
         \PY{n}{K}\PY{o}{.}\PY{n}{set\PYZus{}session}\PY{p}{(}\PY{n}{sess}\PY{p}{)}
         \PY{n}{model} \PY{o}{=} \PY{n}{Sequential}\PY{p}{(}\PY{p}{)}
         \PY{n}{model}\PY{o}{.}\PY{n}{add}\PY{p}{(}\PY{n}{Conv1D}\PY{p}{(}\PY{n}{filters}\PY{o}{=}\PY{l+m+mi}{64}\PY{p}{,} \PY{n}{kernel\PYZus{}size}\PY{o}{=}\PY{l+m+mi}{7}\PY{p}{,} \PY{n}{activation}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{relu}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}\PY{n}{kernel\PYZus{}initializer}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{he\PYZus{}uniform}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}\PY{n}{input\PYZus{}shape}\PY{o}{=}\PY{p}{(}\PY{l+m+mi}{128}\PY{p}{,}\PY{l+m+mi}{9}\PY{p}{)}\PY{p}{)}\PY{p}{)}
         \PY{n}{model}\PY{o}{.}\PY{n}{add}\PY{p}{(}\PY{n}{Conv1D}\PY{p}{(}\PY{n}{filters}\PY{o}{=}\PY{l+m+mi}{32}\PY{p}{,} \PY{n}{kernel\PYZus{}size}\PY{o}{=}\PY{l+m+mi}{3}\PY{p}{,} \PY{n}{activation}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{relu}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}\PY{n}{kernel\PYZus{}initializer}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{he\PYZus{}uniform}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}\PY{p}{)}
         \PY{n}{model}\PY{o}{.}\PY{n}{add}\PY{p}{(}\PY{n}{Dropout}\PY{p}{(}\PY{l+m+mf}{0.6}\PY{p}{)}\PY{p}{)}
         \PY{n}{model}\PY{o}{.}\PY{n}{add}\PY{p}{(}\PY{n}{MaxPooling1D}\PY{p}{(}\PY{n}{pool\PYZus{}size}\PY{o}{=}\PY{l+m+mi}{3}\PY{p}{)}\PY{p}{)}
         \PY{n}{model}\PY{o}{.}\PY{n}{add}\PY{p}{(}\PY{n}{Flatten}\PY{p}{(}\PY{p}{)}\PY{p}{)}
         \PY{n}{model}\PY{o}{.}\PY{n}{add}\PY{p}{(}\PY{n}{Dense}\PY{p}{(}\PY{l+m+mi}{30}\PY{p}{,} \PY{n}{activation}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{relu}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}\PY{p}{)}
         \PY{n}{model}\PY{o}{.}\PY{n}{add}\PY{p}{(}\PY{n}{Dense}\PY{p}{(}\PY{l+m+mi}{3}\PY{p}{,} \PY{n}{activation}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{softmax}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}\PY{p}{)}
         \PY{n}{model}\PY{o}{.}\PY{n}{summary}\PY{p}{(}\PY{p}{)}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_
Layer (type)                 Output Shape              Param \#   
=================================================================
conv1d\_3 (Conv1D)            (None, 122, 64)           4096      
\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_
conv1d\_4 (Conv1D)            (None, 120, 32)           6176      
\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_
dropout\_2 (Dropout)          (None, 120, 32)           0         
\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_
max\_pooling1d\_2 (MaxPooling1 (None, 40, 32)            0         
\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_
flatten\_2 (Flatten)          (None, 1280)              0         
\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_
dense\_3 (Dense)              (None, 30)                38430     
\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_
dense\_4 (Dense)              (None, 3)                 93        
=================================================================
Total params: 48,795
Trainable params: 48,795
Non-trainable params: 0
\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_

    \end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}25}]:} \PY{k+kn}{import} \PY{n+nn}{math}
         \PY{n}{adam} \PY{o}{=} \PY{n}{keras}\PY{o}{.}\PY{n}{optimizers}\PY{o}{.}\PY{n}{Adam}\PY{p}{(}\PY{n}{lr}\PY{o}{=}\PY{l+m+mf}{0.004}\PY{p}{)}
         \PY{n}{model}\PY{o}{.}\PY{n}{compile}\PY{p}{(}\PY{n}{loss}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{categorical\PYZus{}crossentropy}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{optimizer}\PY{o}{=}\PY{n}{adam}\PY{p}{,} \PY{n}{metrics}\PY{o}{=}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{accuracy}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{)}
         \PY{n}{model}\PY{o}{.}\PY{n}{fit}\PY{p}{(}\PY{n}{X\PYZus{}train\PYZus{}s}\PY{p}{,}\PY{n}{Y\PYZus{}train\PYZus{}s}\PY{p}{,} \PY{n}{epochs}\PY{o}{=}\PY{l+m+mi}{20}\PY{p}{,} \PY{n}{batch\PYZus{}size}\PY{o}{=}\PY{l+m+mi}{32}\PY{p}{,}\PY{n}{validation\PYZus{}data}\PY{o}{=}\PY{p}{(}\PY{n}{X\PYZus{}val\PYZus{}s}\PY{p}{,} \PY{n}{Y\PYZus{}val\PYZus{}s}\PY{p}{)}\PY{p}{,} \PY{n}{verbose}\PY{o}{=}\PY{l+m+mi}{1}\PY{p}{)}
         \PY{n}{K}\PY{o}{.}\PY{n}{clear\PYZus{}session}\PY{p}{(}\PY{p}{)}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
Train on 4067 samples, validate on 1560 samples
Epoch 1/20
4067/4067 [==============================] - 2s 530us/step - loss: 0.4023 - acc: 0.8773 - val\_loss: 0.2665 - val\_acc: 0.8974
Epoch 2/20
4067/4067 [==============================] - 1s 352us/step - loss: 0.2302 - acc: 0.9240 - val\_loss: 0.2560 - val\_acc: 0.8942
Epoch 3/20
4067/4067 [==============================] - 1s 352us/step - loss: 0.2163 - acc: 0.9235 - val\_loss: 0.2900 - val\_acc: 0.8878
Epoch 4/20
4067/4067 [==============================] - 1s 351us/step - loss: 0.1732 - acc: 0.9348 - val\_loss: 0.3296 - val\_acc: 0.8910
Epoch 5/20
4067/4067 [==============================] - 1s 352us/step - loss: 0.1471 - acc: 0.9432 - val\_loss: 0.2661 - val\_acc: 0.9000
Epoch 6/20
4067/4067 [==============================] - 1s 354us/step - loss: 0.1296 - acc: 0.9498 - val\_loss: 0.2430 - val\_acc: 0.9109
Epoch 7/20
4067/4067 [==============================] - 1s 353us/step - loss: 0.1704 - acc: 0.9422 - val\_loss: 0.3748 - val\_acc: 0.8795
Epoch 8/20
4067/4067 [==============================] - 1s 352us/step - loss: 0.2979 - acc: 0.9171 - val\_loss: 0.2355 - val\_acc: 0.8929
Epoch 9/20
4067/4067 [==============================] - 1s 353us/step - loss: 0.2093 - acc: 0.9375 - val\_loss: 0.1853 - val\_acc: 0.9083
Epoch 10/20
4067/4067 [==============================] - 1s 353us/step - loss: 0.2048 - acc: 0.9405 - val\_loss: 0.3305 - val\_acc: 0.9218
Epoch 11/20
4067/4067 [==============================] - 1s 355us/step - loss: 0.2393 - acc: 0.9405 - val\_loss: 0.2739 - val\_acc: 0.9051
Epoch 12/20
4067/4067 [==============================] - 1s 351us/step - loss: 0.2640 - acc: 0.9299 - val\_loss: 0.1967 - val\_acc: 0.9295
Epoch 13/20
4067/4067 [==============================] - 1s 353us/step - loss: 0.2083 - acc: 0.9388 - val\_loss: 0.2722 - val\_acc: 0.9051
Epoch 14/20
4067/4067 [==============================] - 1s 353us/step - loss: 0.1886 - acc: 0.9474 - val\_loss: 0.2411 - val\_acc: 0.9122
Epoch 15/20
4067/4067 [==============================] - 1s 352us/step - loss: 0.1870 - acc: 0.9484 - val\_loss: 0.1946 - val\_acc: 0.9115
Epoch 16/20
4067/4067 [==============================] - 1s 352us/step - loss: 0.1710 - acc: 0.9552 - val\_loss: 0.2320 - val\_acc: 0.9090
Epoch 17/20
4067/4067 [==============================] - 1s 352us/step - loss: 0.1718 - acc: 0.9506 - val\_loss: 0.2120 - val\_acc: 0.9032
Epoch 18/20
4067/4067 [==============================] - 1s 352us/step - loss: 0.1699 - acc: 0.9501 - val\_loss: 0.1729 - val\_acc: 0.9282
Epoch 19/20
4067/4067 [==============================] - 1s 353us/step - loss: 0.1520 - acc: 0.9636 - val\_loss: 0.1997 - val\_acc: 0.9179
Epoch 20/20
4067/4067 [==============================] - 1s 352us/step - loss: 0.1927 - acc: 0.9592 - val\_loss: 0.2545 - val\_acc: 0.9096

    \end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}40}]:} \PY{k}{def} \PY{n+nf}{model\PYZus{}cnn}\PY{p}{(}\PY{n}{X\PYZus{}train\PYZus{}s}\PY{p}{,} \PY{n}{Y\PYZus{}train\PYZus{}s}\PY{p}{,} \PY{n}{X\PYZus{}val\PYZus{}s}\PY{p}{,} \PY{n}{Y\PYZus{}val\PYZus{}s}\PY{p}{)}\PY{p}{:}
             \PY{n}{np}\PY{o}{.}\PY{n}{random}\PY{o}{.}\PY{n}{seed}\PY{p}{(}\PY{l+m+mi}{0}\PY{p}{)}
             \PY{n}{tf}\PY{o}{.}\PY{n}{set\PYZus{}random\PYZus{}seed}\PY{p}{(}\PY{l+m+mi}{0}\PY{p}{)}
             \PY{n}{sess} \PY{o}{=} \PY{n}{tf}\PY{o}{.}\PY{n}{Session}\PY{p}{(}\PY{n}{graph}\PY{o}{=}\PY{n}{tf}\PY{o}{.}\PY{n}{get\PYZus{}default\PYZus{}graph}\PY{p}{(}\PY{p}{)}\PY{p}{)}
             \PY{n}{K}\PY{o}{.}\PY{n}{set\PYZus{}session}\PY{p}{(}\PY{n}{sess}\PY{p}{)}
             \PY{c+c1}{\PYZsh{} Initiliazing the sequential model}
             \PY{n}{model} \PY{o}{=} \PY{n}{Sequential}\PY{p}{(}\PY{p}{)}
             
             \PY{n}{model}\PY{o}{.}\PY{n}{add}\PY{p}{(}\PY{n}{Conv1D}\PY{p}{(}\PY{n}{filters}\PY{o}{=}\PY{p}{\PYZob{}}\PY{p}{\PYZob{}}\PY{n}{choice}\PY{p}{(}\PY{p}{[}\PY{l+m+mi}{28}\PY{p}{,}\PY{l+m+mi}{32}\PY{p}{,}\PY{l+m+mi}{42}\PY{p}{]}\PY{p}{)}\PY{p}{\PYZcb{}}\PY{p}{\PYZcb{}}\PY{p}{,} \PY{n}{kernel\PYZus{}size}\PY{o}{=}\PY{p}{\PYZob{}}\PY{p}{\PYZob{}}\PY{n}{choice}\PY{p}{(}\PY{p}{[}\PY{l+m+mi}{3}\PY{p}{,}\PY{l+m+mi}{5}\PY{p}{,}\PY{l+m+mi}{7}\PY{p}{]}\PY{p}{)}\PY{p}{\PYZcb{}}\PY{p}{\PYZcb{}}\PY{p}{,}\PY{n}{activation}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{relu}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}\PY{n}{kernel\PYZus{}initializer}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{he\PYZus{}uniform}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}
                          \PY{n}{kernel\PYZus{}regularizer}\PY{o}{=}\PY{n}{l2}\PY{p}{(}\PY{p}{\PYZob{}}\PY{p}{\PYZob{}}\PY{n}{uniform}\PY{p}{(}\PY{l+m+mi}{0}\PY{p}{,}\PY{l+m+mi}{3}\PY{p}{)}\PY{p}{\PYZcb{}}\PY{p}{\PYZcb{}}\PY{p}{)}\PY{p}{,}\PY{n}{input\PYZus{}shape}\PY{o}{=}\PY{p}{(}\PY{l+m+mi}{128}\PY{p}{,}\PY{l+m+mi}{9}\PY{p}{)}\PY{p}{)}\PY{p}{)}
             
             \PY{n}{model}\PY{o}{.}\PY{n}{add}\PY{p}{(}\PY{n}{Conv1D}\PY{p}{(}\PY{n}{filters}\PY{o}{=}\PY{p}{\PYZob{}}\PY{p}{\PYZob{}}\PY{n}{choice}\PY{p}{(}\PY{p}{[}\PY{l+m+mi}{16}\PY{p}{,}\PY{l+m+mi}{24}\PY{p}{,}\PY{l+m+mi}{32}\PY{p}{]}\PY{p}{)}\PY{p}{\PYZcb{}}\PY{p}{\PYZcb{}}\PY{p}{,} \PY{n}{kernel\PYZus{}size}\PY{o}{=}\PY{p}{\PYZob{}}\PY{p}{\PYZob{}}\PY{n}{choice}\PY{p}{(}\PY{p}{[}\PY{l+m+mi}{3}\PY{p}{,}\PY{l+m+mi}{5}\PY{p}{,}\PY{l+m+mi}{7}\PY{p}{]}\PY{p}{)}\PY{p}{\PYZcb{}}\PY{p}{\PYZcb{}}\PY{p}{,} 
                              \PY{n}{activation}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{relu}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}\PY{n}{kernel\PYZus{}regularizer}\PY{o}{=}\PY{n}{l2}\PY{p}{(}\PY{p}{\PYZob{}}\PY{p}{\PYZob{}}\PY{n}{uniform}\PY{p}{(}\PY{l+m+mi}{0}\PY{p}{,}\PY{l+m+mi}{2}\PY{p}{)}\PY{p}{\PYZcb{}}\PY{p}{\PYZcb{}}\PY{p}{)}\PY{p}{,}\PY{n}{kernel\PYZus{}initializer}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{he\PYZus{}uniform}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}\PY{p}{)}
             \PY{n}{model}\PY{o}{.}\PY{n}{add}\PY{p}{(}\PY{n}{Dropout}\PY{p}{(}\PY{p}{\PYZob{}}\PY{p}{\PYZob{}}\PY{n}{uniform}\PY{p}{(}\PY{l+m+mf}{0.45}\PY{p}{,}\PY{l+m+mf}{0.7}\PY{p}{)}\PY{p}{\PYZcb{}}\PY{p}{\PYZcb{}}\PY{p}{)}\PY{p}{)}
             \PY{n}{model}\PY{o}{.}\PY{n}{add}\PY{p}{(}\PY{n}{MaxPooling1D}\PY{p}{(}\PY{n}{pool\PYZus{}size}\PY{o}{=}\PY{p}{\PYZob{}}\PY{p}{\PYZob{}}\PY{n}{choice}\PY{p}{(}\PY{p}{[}\PY{l+m+mi}{2}\PY{p}{,}\PY{l+m+mi}{3}\PY{p}{,}\PY{l+m+mi}{5}\PY{p}{]}\PY{p}{)}\PY{p}{\PYZcb{}}\PY{p}{\PYZcb{}}\PY{p}{)}\PY{p}{)}
             \PY{n}{model}\PY{o}{.}\PY{n}{add}\PY{p}{(}\PY{n}{Flatten}\PY{p}{(}\PY{p}{)}\PY{p}{)}
             \PY{n}{model}\PY{o}{.}\PY{n}{add}\PY{p}{(}\PY{n}{Dense}\PY{p}{(}\PY{p}{\PYZob{}}\PY{p}{\PYZob{}}\PY{n}{choice}\PY{p}{(}\PY{p}{[}\PY{l+m+mi}{16}\PY{p}{,}\PY{l+m+mi}{32}\PY{p}{,}\PY{l+m+mi}{64}\PY{p}{]}\PY{p}{)}\PY{p}{\PYZcb{}}\PY{p}{\PYZcb{}}\PY{p}{,} \PY{n}{activation}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{relu}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}\PY{p}{)}
             \PY{n}{model}\PY{o}{.}\PY{n}{add}\PY{p}{(}\PY{n}{Dense}\PY{p}{(}\PY{l+m+mi}{3}\PY{p}{,} \PY{n}{activation}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{softmax}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}\PY{p}{)}
                 
             \PY{n}{adam} \PY{o}{=} \PY{n}{keras}\PY{o}{.}\PY{n}{optimizers}\PY{o}{.}\PY{n}{Adam}\PY{p}{(}\PY{n}{lr}\PY{o}{=}\PY{p}{\PYZob{}}\PY{p}{\PYZob{}}\PY{n}{uniform}\PY{p}{(}\PY{l+m+mf}{0.00065}\PY{p}{,}\PY{l+m+mf}{0.004}\PY{p}{)}\PY{p}{\PYZcb{}}\PY{p}{\PYZcb{}}\PY{p}{)}
             \PY{n}{rmsprop} \PY{o}{=} \PY{n}{keras}\PY{o}{.}\PY{n}{optimizers}\PY{o}{.}\PY{n}{RMSprop}\PY{p}{(}\PY{n}{lr}\PY{o}{=}\PY{p}{\PYZob{}}\PY{p}{\PYZob{}}\PY{n}{uniform}\PY{p}{(}\PY{l+m+mf}{0.00065}\PY{p}{,}\PY{l+m+mf}{0.004}\PY{p}{)}\PY{p}{\PYZcb{}}\PY{p}{\PYZcb{}}\PY{p}{)}
            
             \PY{n}{choiceval} \PY{o}{=} \PY{p}{\PYZob{}}\PY{p}{\PYZob{}}\PY{n}{choice}\PY{p}{(}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{adam}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{rmsprop}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{)}\PY{p}{\PYZcb{}}\PY{p}{\PYZcb{}}
             
             \PY{k}{if} \PY{n}{choiceval} \PY{o}{==} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{adam}\PY{l+s+s1}{\PYZsq{}}\PY{p}{:}
                 \PY{n}{optim} \PY{o}{=} \PY{n}{adam}
             \PY{k}{else}\PY{p}{:}
                 \PY{n}{optim} \PY{o}{=} \PY{n}{rmsprop}
             
             \PY{n+nb}{print}\PY{p}{(}\PY{n}{model}\PY{o}{.}\PY{n}{summary}\PY{p}{(}\PY{p}{)}\PY{p}{)}
                 
             \PY{n}{model}\PY{o}{.}\PY{n}{compile}\PY{p}{(}\PY{n}{loss}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{categorical\PYZus{}crossentropy}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{metrics}\PY{o}{=}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{accuracy}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{,}\PY{n}{optimizer}\PY{o}{=}\PY{n}{optim}\PY{p}{)}
             
             \PY{n}{result} \PY{o}{=} \PY{n}{model}\PY{o}{.}\PY{n}{fit}\PY{p}{(}\PY{n}{X\PYZus{}train\PYZus{}s}\PY{p}{,} \PY{n}{Y\PYZus{}train\PYZus{}s}\PY{p}{,}
                       \PY{n}{batch\PYZus{}size}\PY{o}{=}\PY{p}{\PYZob{}}\PY{p}{\PYZob{}}\PY{n}{choice}\PY{p}{(}\PY{p}{[}\PY{l+m+mi}{16}\PY{p}{,}\PY{l+m+mi}{32}\PY{p}{,}\PY{l+m+mi}{64}\PY{p}{]}\PY{p}{)}\PY{p}{\PYZcb{}}\PY{p}{\PYZcb{}}\PY{p}{,}
                       \PY{n}{nb\PYZus{}epoch}\PY{o}{=}\PY{p}{\PYZob{}}\PY{p}{\PYZob{}}\PY{n}{choice}\PY{p}{(}\PY{p}{[}\PY{l+m+mi}{25}\PY{p}{,}\PY{l+m+mi}{30}\PY{p}{,}\PY{l+m+mi}{35}\PY{p}{]}\PY{p}{)}\PY{p}{\PYZcb{}}\PY{p}{\PYZcb{}}\PY{p}{,}
                       \PY{n}{verbose}\PY{o}{=}\PY{l+m+mi}{2}\PY{p}{,}
                       \PY{n}{validation\PYZus{}data}\PY{o}{=}\PY{p}{(}\PY{n}{X\PYZus{}val\PYZus{}s}\PY{p}{,} \PY{n}{Y\PYZus{}val\PYZus{}s}\PY{p}{)}\PY{p}{)}
                                
             \PY{n}{score}\PY{p}{,} \PY{n}{acc} \PY{o}{=} \PY{n}{model}\PY{o}{.}\PY{n}{evaluate}\PY{p}{(}\PY{n}{X\PYZus{}val\PYZus{}s}\PY{p}{,} \PY{n}{Y\PYZus{}val\PYZus{}s}\PY{p}{,} \PY{n}{verbose}\PY{o}{=}\PY{l+m+mi}{0}\PY{p}{)}
             \PY{n}{score1}\PY{p}{,} \PY{n}{acc1} \PY{o}{=} \PY{n}{model}\PY{o}{.}\PY{n}{evaluate}\PY{p}{(}\PY{n}{X\PYZus{}train\PYZus{}s}\PY{p}{,} \PY{n}{Y\PYZus{}train\PYZus{}s}\PY{p}{,} \PY{n}{verbose}\PY{o}{=}\PY{l+m+mi}{0}\PY{p}{)}
             \PY{n+nb}{print}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Train accuracy}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}\PY{n}{acc1}\PY{p}{,}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Test accuracy:}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{acc}\PY{p}{)}
             \PY{n+nb}{print}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
             \PY{n}{K}\PY{o}{.}\PY{n}{clear\PYZus{}session}\PY{p}{(}\PY{p}{)}
             \PY{k}{return} \PY{p}{\PYZob{}}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{loss}\PY{l+s+s1}{\PYZsq{}}\PY{p}{:} \PY{o}{\PYZhy{}}\PY{n}{acc}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{status}\PY{l+s+s1}{\PYZsq{}}\PY{p}{:} \PY{n}{STATUS\PYZus{}OK}\PY{p}{,}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{train\PYZus{}acc}\PY{l+s+s1}{\PYZsq{}}\PY{p}{:}\PY{n}{acc1}\PY{p}{\PYZcb{}}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor} }]:} \PY{n}{X\PYZus{}train}\PY{p}{,} \PY{n}{Y\PYZus{}train}\PY{p}{,} \PY{n}{X\PYZus{}val}\PY{p}{,} \PY{n}{Y\PYZus{}val} \PY{o}{=} \PY{n}{data\PYZus{}scaled\PYZus{}static}\PY{p}{(}\PY{p}{)}
        \PY{n}{trials} \PY{o}{=} \PY{n}{Trials}\PY{p}{(}\PY{p}{)}
        \PY{n}{best\PYZus{}run}\PY{p}{,} \PY{n}{best\PYZus{}model}\PY{p}{,} \PY{n}{space} \PY{o}{=} \PY{n}{optim}\PY{o}{.}\PY{n}{minimize}\PY{p}{(}\PY{n}{model}\PY{o}{=}\PY{n}{model\PYZus{}cnn}\PY{p}{,}
                                              \PY{n}{data}\PY{o}{=}\PY{n}{data\PYZus{}scaled\PYZus{}static}\PY{p}{,}
                                              \PY{n}{algo}\PY{o}{=}\PY{n}{tpe}\PY{o}{.}\PY{n}{suggest}\PY{p}{,}
                                              \PY{n}{max\PYZus{}evals}\PY{o}{=}\PY{l+m+mi}{120}\PY{p}{,}\PY{n}{rseed} \PY{o}{=} \PY{l+m+mi}{0}\PY{p}{,}                                           
                                              \PY{n}{trials}\PY{o}{=}\PY{n}{trials}\PY{p}{,}\PY{n}{notebook\PYZus{}name} \PY{o}{=} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Human Activity Detection}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}
                                              \PY{n}{return\PYZus{}space} \PY{o}{=} \PY{k+kc}{True}\PY{p}{)}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}12}]:} \PY{n}{best\PYZus{}run}
\end{Verbatim}


\begin{Verbatim}[commandchars=\\\{\}]
{\color{outcolor}Out[{\color{outcolor}12}]:} \{'Dense': 2,
          'Dense\_1': 2,
          'Dropout': 0.45377377480700615,
          'choiceval': 1,
          'filters': 1,
          'filters\_1': 0,
          'kernel\_size': 1,
          'kernel\_size\_1': 0,
          'l2': 0.0019801221163149862,
          'l2\_1': 0.8236255110533577,
          'lr': 0.003918784585237195,
          'lr\_1': 0.002237071747066137,
          'nb\_epoch': 1,
          'pool\_size': 0\}
\end{Verbatim}
            
    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}21}]:} \PY{k+kn}{from} \PY{n+nn}{hyperas}\PY{n+nn}{.}\PY{n+nn}{utils} \PY{k}{import} \PY{n}{eval\PYZus{}hyperopt\PYZus{}space}
         \PY{n}{total\PYZus{}trials} \PY{o}{=} \PY{n+nb}{dict}\PY{p}{(}\PY{p}{)}
         \PY{n}{total\PYZus{}list} \PY{o}{=} \PY{p}{[}\PY{p}{]}
         \PY{k}{for} \PY{n}{t}\PY{p}{,} \PY{n}{trial} \PY{o+ow}{in} \PY{n+nb}{enumerate}\PY{p}{(}\PY{n}{trials}\PY{p}{)}\PY{p}{:}
                 \PY{n}{vals} \PY{o}{=} \PY{n}{trial}\PY{o}{.}\PY{n}{get}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{misc}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}\PY{o}{.}\PY{n}{get}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{vals}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
                 \PY{n}{z} \PY{o}{=} \PY{n}{eval\PYZus{}hyperopt\PYZus{}space}\PY{p}{(}\PY{n}{space}\PY{p}{,} \PY{n}{vals}\PY{p}{)}
                 \PY{n}{total\PYZus{}trials}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{M}\PY{l+s+s1}{\PYZsq{}}\PY{o}{+}\PY{n+nb}{str}\PY{p}{(}\PY{n}{t}\PY{o}{+}\PY{l+m+mi}{1}\PY{p}{)}\PY{p}{]} \PY{o}{=} \PY{n}{z}
         
         
         \PY{c+c1}{\PYZsh{}best Hyper params from hyperas}
         \PY{n}{best\PYZus{}params} \PY{o}{=} \PY{n}{eval\PYZus{}hyperopt\PYZus{}space}\PY{p}{(}\PY{n}{space}\PY{p}{,} \PY{n}{best\PYZus{}run}\PY{p}{)}
         \PY{n}{best\PYZus{}params}
\end{Verbatim}


\begin{Verbatim}[commandchars=\\\{\}]
{\color{outcolor}Out[{\color{outcolor}21}]:} \{'Dense': 64,
          'Dense\_1': 64,
          'Dropout': 0.45377377480700615,
          'choiceval': 'rmsprop',
          'filters': 32,
          'filters\_1': 16,
          'kernel\_size': 5,
          'kernel\_size\_1': 3,
          'l2': 0.0019801221163149862,
          'l2\_1': 0.8236255110533577,
          'lr': 0.003918784585237195,
          'lr\_1': 0.002237071747066137,
          'nb\_epoch': 30,
          'pool\_size': 2\}
\end{Verbatim}
            
    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}3}]:} \PY{k+kn}{from} \PY{n+nn}{keras}\PY{n+nn}{.}\PY{n+nn}{regularizers} \PY{k}{import} \PY{n}{l2}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}71}]:} \PY{c+c1}{\PYZsh{}\PYZsh{}model from hyperas}
         \PY{k}{def} \PY{n+nf}{keras\PYZus{}fmin\PYZus{}fnct}\PY{p}{(}\PY{n}{space}\PY{p}{,}\PY{n}{verbose}\PY{o}{=}\PY{l+m+mi}{1}\PY{p}{)}\PY{p}{:}   
             \PY{n}{np}\PY{o}{.}\PY{n}{random}\PY{o}{.}\PY{n}{seed}\PY{p}{(}\PY{l+m+mi}{0}\PY{p}{)}
             \PY{n}{tf}\PY{o}{.}\PY{n}{set\PYZus{}random\PYZus{}seed}\PY{p}{(}\PY{l+m+mi}{0}\PY{p}{)}
             \PY{n}{sess} \PY{o}{=} \PY{n}{tf}\PY{o}{.}\PY{n}{Session}\PY{p}{(}\PY{n}{graph}\PY{o}{=}\PY{n}{tf}\PY{o}{.}\PY{n}{get\PYZus{}default\PYZus{}graph}\PY{p}{(}\PY{p}{)}\PY{p}{)}
             \PY{n}{K}\PY{o}{.}\PY{n}{set\PYZus{}session}\PY{p}{(}\PY{n}{sess}\PY{p}{)}
             \PY{c+c1}{\PYZsh{} Initiliazing the sequential model}
             \PY{n}{model} \PY{o}{=} \PY{n}{Sequential}\PY{p}{(}\PY{p}{)}
             \PY{n}{model}\PY{o}{.}\PY{n}{add}\PY{p}{(}\PY{n}{Conv1D}\PY{p}{(}\PY{n}{filters}\PY{o}{=}\PY{n}{space}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{filters}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{,} \PY{n}{kernel\PYZus{}size}\PY{o}{=}\PY{n}{space}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{kernel\PYZus{}size}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{,}\PY{n}{activation}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{relu}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}
                             \PY{n}{kernel\PYZus{}initializer}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{he\PYZus{}uniform}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}
                             \PY{n}{kernel\PYZus{}regularizer}\PY{o}{=}\PY{n}{l2}\PY{p}{(}\PY{n}{space}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{l2}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{)}\PY{p}{,}\PY{n}{input\PYZus{}shape}\PY{o}{=}\PY{p}{(}\PY{l+m+mi}{128}\PY{p}{,}\PY{l+m+mi}{9}\PY{p}{)}\PY{p}{)}\PY{p}{)}
             \PY{n}{model}\PY{o}{.}\PY{n}{add}\PY{p}{(}\PY{n}{Conv1D}\PY{p}{(}\PY{n}{filters}\PY{o}{=}\PY{n}{space}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{filters\PYZus{}1}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{,} \PY{n}{kernel\PYZus{}size}\PY{o}{=}\PY{n}{space}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{kernel\PYZus{}size\PYZus{}1}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{,} 
                         \PY{n}{activation}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{relu}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}\PY{n}{kernel\PYZus{}regularizer}\PY{o}{=}\PY{n}{l2}\PY{p}{(}\PY{n}{space}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{l2\PYZus{}1}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{)}\PY{p}{,}\PY{n}{kernel\PYZus{}initializer}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{he\PYZus{}uniform}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}\PY{p}{)}
             \PY{n}{model}\PY{o}{.}\PY{n}{add}\PY{p}{(}\PY{n}{Dropout}\PY{p}{(}\PY{n}{space}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Dropout}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{)}\PY{p}{)}
             \PY{n}{model}\PY{o}{.}\PY{n}{add}\PY{p}{(}\PY{n}{MaxPooling1D}\PY{p}{(}\PY{n}{pool\PYZus{}size}\PY{o}{=}\PY{n}{space}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{pool\PYZus{}size}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{)}\PY{p}{)}
             \PY{n}{model}\PY{o}{.}\PY{n}{add}\PY{p}{(}\PY{n}{Flatten}\PY{p}{(}\PY{p}{)}\PY{p}{)}
             \PY{n}{model}\PY{o}{.}\PY{n}{add}\PY{p}{(}\PY{n}{Dense}\PY{p}{(}\PY{n}{space}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Dense}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{,} \PY{n}{activation}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{relu}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}\PY{p}{)}
             \PY{n}{model}\PY{o}{.}\PY{n}{add}\PY{p}{(}\PY{n}{Dense}\PY{p}{(}\PY{l+m+mi}{3}\PY{p}{,} \PY{n}{activation}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{softmax}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}\PY{p}{)}
             \PY{n}{adam} \PY{o}{=} \PY{n}{keras}\PY{o}{.}\PY{n}{optimizers}\PY{o}{.}\PY{n}{Adam}\PY{p}{(}\PY{n}{lr}\PY{o}{=}\PY{n}{space}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{lr}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{)}
             \PY{n}{rmsprop} \PY{o}{=} \PY{n}{keras}\PY{o}{.}\PY{n}{optimizers}\PY{o}{.}\PY{n}{RMSprop}\PY{p}{(}\PY{n}{lr}\PY{o}{=}\PY{n}{space}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{lr\PYZus{}1}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{)}
             \PY{n}{choiceval} \PY{o}{=} \PY{n}{space}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{choiceval}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}
             \PY{k}{if} \PY{n}{choiceval} \PY{o}{==} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{adam}\PY{l+s+s1}{\PYZsq{}}\PY{p}{:}
                 \PY{n}{optim} \PY{o}{=} \PY{n}{adam}
             \PY{k}{else}\PY{p}{:}
                 \PY{n}{optim} \PY{o}{=} \PY{n}{rmsprop}
             \PY{n+nb}{print}\PY{p}{(}\PY{n}{model}\PY{o}{.}\PY{n}{summary}\PY{p}{(}\PY{p}{)}\PY{p}{)}
             \PY{n}{model}\PY{o}{.}\PY{n}{compile}\PY{p}{(}\PY{n}{loss}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{categorical\PYZus{}crossentropy}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{metrics}\PY{o}{=}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{accuracy}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{,}\PY{n}{optimizer}\PY{o}{=}\PY{n}{optim}\PY{p}{)}
             \PY{n}{result} \PY{o}{=} \PY{n}{model}\PY{o}{.}\PY{n}{fit}\PY{p}{(}\PY{n}{X\PYZus{}train\PYZus{}s}\PY{p}{,} \PY{n}{Y\PYZus{}train\PYZus{}s}\PY{p}{,}
                             \PY{n}{batch\PYZus{}size}\PY{o}{=}\PY{n}{space}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Dense\PYZus{}1}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{,}
                             \PY{n}{nb\PYZus{}epoch}\PY{o}{=}\PY{n}{space}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{nb\PYZus{}epoch}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{,}
                             \PY{n}{verbose}\PY{o}{=}\PY{n}{verbose}\PY{p}{,}
                             \PY{n}{validation\PYZus{}data}\PY{o}{=}\PY{p}{(}\PY{n}{X\PYZus{}val\PYZus{}s}\PY{p}{,} \PY{n}{Y\PYZus{}val\PYZus{}s}\PY{p}{)}\PY{p}{)}
             \PY{c+c1}{\PYZsh{}K.clear\PYZus{}session()}
             \PY{k}{return} \PY{n}{model}\PY{p}{,}\PY{n}{result}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}28}]:} \PY{n}{best\PYZus{}model}\PY{p}{,}\PY{n}{result} \PY{o}{=} \PY{n}{keras\PYZus{}fmin\PYZus{}fnct}\PY{p}{(}\PY{n}{best\PYZus{}params}\PY{p}{)}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_
Layer (type)                 Output Shape              Param \#   
=================================================================
conv1d\_3 (Conv1D)            (None, 124, 32)           1472      
\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_
conv1d\_4 (Conv1D)            (None, 122, 16)           1552      
\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_
dropout\_2 (Dropout)          (None, 122, 16)           0         
\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_
max\_pooling1d\_2 (MaxPooling1 (None, 61, 16)            0         
\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_
flatten\_2 (Flatten)          (None, 976)               0         
\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_
dense\_3 (Dense)              (None, 64)                62528     
\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_
dense\_4 (Dense)              (None, 3)                 195       
=================================================================
Total params: 65,747
Trainable params: 65,747
Non-trainable params: 0
\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_
None

    \end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]
/glob/intel-python/versions/2018u2/intelpython3/lib/python3.6/site-packages/ipykernel\_launcher.py:31: UserWarning: The `nb\_epoch` argument in `fit` has been renamed `epochs`.

    \end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]
Train on 4067 samples, validate on 1560 samples
Epoch 1/30
4067/4067 [==============================] - 1s 350us/step - loss: 10.6708 - acc: 0.8375 - val\_loss: 3.0312 - val\_acc: 0.8923
Epoch 2/30
4067/4067 [==============================] - 1s 184us/step - loss: 1.2846 - acc: 0.8960 - val\_loss: 0.6160 - val\_acc: 0.8788
Epoch 3/30
4067/4067 [==============================] - 1s 184us/step - loss: 0.4912 - acc: 0.8943 - val\_loss: 0.4795 - val\_acc: 0.8628
Epoch 4/30
4067/4067 [==============================] - 1s 184us/step - loss: 0.3866 - acc: 0.9053 - val\_loss: 0.4627 - val\_acc: 0.8506
Epoch 5/30
4067/4067 [==============================] - 1s 184us/step - loss: 0.3421 - acc: 0.9098 - val\_loss: 0.4827 - val\_acc: 0.8724
Epoch 6/30
4067/4067 [==============================] - 1s 184us/step - loss: 0.3151 - acc: 0.9166 - val\_loss: 0.3515 - val\_acc: 0.8968
Epoch 7/30
4067/4067 [==============================] - 1s 183us/step - loss: 0.3091 - acc: 0.9154 - val\_loss: 0.3364 - val\_acc: 0.8853
Epoch 8/30
4067/4067 [==============================] - 1s 183us/step - loss: 0.2749 - acc: 0.9312 - val\_loss: 0.4064 - val\_acc: 0.8718
Epoch 9/30
4067/4067 [==============================] - 1s 184us/step - loss: 0.2743 - acc: 0.9272 - val\_loss: 0.3227 - val\_acc: 0.9122
Epoch 10/30
4067/4067 [==============================] - 1s 184us/step - loss: 0.2576 - acc: 0.9292 - val\_loss: 0.2934 - val\_acc: 0.9083
Epoch 11/30
4067/4067 [==============================] - 1s 183us/step - loss: 0.2791 - acc: 0.9302 - val\_loss: 0.3982 - val\_acc: 0.8712
Epoch 12/30
4067/4067 [==============================] - 1s 185us/step - loss: 0.2315 - acc: 0.9346 - val\_loss: 0.3192 - val\_acc: 0.9186
Epoch 13/30
4067/4067 [==============================] - 1s 184us/step - loss: 0.2301 - acc: 0.9410 - val\_loss: 0.3427 - val\_acc: 0.8821
Epoch 14/30
4067/4067 [==============================] - 1s 184us/step - loss: 0.2294 - acc: 0.9368 - val\_loss: 0.2628 - val\_acc: 0.9327
Epoch 15/30
4067/4067 [==============================] - 1s 184us/step - loss: 0.2371 - acc: 0.9353 - val\_loss: 0.2884 - val\_acc: 0.9071
Epoch 16/30
4067/4067 [==============================] - 1s 183us/step - loss: 0.2146 - acc: 0.9449 - val\_loss: 0.3369 - val\_acc: 0.8865
Epoch 17/30
4067/4067 [==============================] - 1s 184us/step - loss: 0.2065 - acc: 0.9447 - val\_loss: 0.2776 - val\_acc: 0.9019
Epoch 18/30
4067/4067 [==============================] - 1s 184us/step - loss: 0.2056 - acc: 0.9420 - val\_loss: 0.3021 - val\_acc: 0.8891
Epoch 19/30
4067/4067 [==============================] - 1s 185us/step - loss: 0.2223 - acc: 0.9398 - val\_loss: 0.2380 - val\_acc: 0.9205
Epoch 20/30
4067/4067 [==============================] - 1s 183us/step - loss: 0.1979 - acc: 0.9442 - val\_loss: 2.4294 - val\_acc: 0.6051
Epoch 21/30
4067/4067 [==============================] - 1s 183us/step - loss: 0.2421 - acc: 0.9432 - val\_loss: 0.2461 - val\_acc: 0.9109
Epoch 22/30
4067/4067 [==============================] - 1s 183us/step - loss: 0.1836 - acc: 0.9498 - val\_loss: 0.2768 - val\_acc: 0.9115
Epoch 23/30
4067/4067 [==============================] - 1s 184us/step - loss: 0.1963 - acc: 0.9457 - val\_loss: 0.2667 - val\_acc: 0.9077
Epoch 24/30
4067/4067 [==============================] - 1s 183us/step - loss: 0.1863 - acc: 0.9462 - val\_loss: 0.2308 - val\_acc: 0.9128
Epoch 25/30
4067/4067 [==============================] - 1s 184us/step - loss: 0.1844 - acc: 0.9462 - val\_loss: 0.2726 - val\_acc: 0.9038
Epoch 26/30
4067/4067 [==============================] - 1s 183us/step - loss: 0.1754 - acc: 0.9525 - val\_loss: 0.2099 - val\_acc: 0.9417
Epoch 27/30
4067/4067 [==============================] - 1s 183us/step - loss: 0.1793 - acc: 0.9511 - val\_loss: 0.2814 - val\_acc: 0.9077
Epoch 28/30
4067/4067 [==============================] - 1s 183us/step - loss: 0.1665 - acc: 0.9555 - val\_loss: 0.2140 - val\_acc: 0.9378
Epoch 29/30
4067/4067 [==============================] - 1s 183us/step - loss: 0.1705 - acc: 0.9575 - val\_loss: 0.2413 - val\_acc: 0.9359
Epoch 30/30
4067/4067 [==============================] - 1s 183us/step - loss: 0.1712 - acc: 0.9577 - val\_loss: 0.2297 - val\_acc: 0.9391

    \end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}32}]:} \PY{n}{\PYZus{}}\PY{p}{,}\PY{n}{acc\PYZus{}val} \PY{o}{=} \PY{n}{best\PYZus{}model}\PY{o}{.}\PY{n}{evaluate}\PY{p}{(}\PY{n}{X\PYZus{}val\PYZus{}s}\PY{p}{,}\PY{n}{Y\PYZus{}val\PYZus{}s}\PY{p}{,}\PY{n}{verbose}\PY{o}{=}\PY{l+m+mi}{0}\PY{p}{)}
         \PY{n}{\PYZus{}}\PY{p}{,}\PY{n}{acc\PYZus{}train} \PY{o}{=} \PY{n}{best\PYZus{}model}\PY{o}{.}\PY{n}{evaluate}\PY{p}{(}\PY{n}{X\PYZus{}train\PYZus{}s}\PY{p}{,}\PY{n}{Y\PYZus{}train\PYZus{}s}\PY{p}{,}\PY{n}{verbose}\PY{o}{=}\PY{l+m+mi}{0}\PY{p}{)}
         \PY{n+nb}{print}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Train\PYZus{}accuracy}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}\PY{n}{acc\PYZus{}train}\PY{p}{,}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{test\PYZus{}accuracy}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}\PY{n}{acc\PYZus{}val}\PY{p}{)}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
Train\_accuracy 0.9628718957462503 test\_accuracy 0.9391025641025641

    \end{Verbatim}

    i can observe that 23rd model is also giving good scores in runtime so
will try once wit that params.

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}38}]:} \PY{n}{runtime\PYZus{}param} \PY{o}{=} \PY{n}{total\PYZus{}trials}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{M23}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}
         \PY{n}{runtime\PYZus{}param}
\end{Verbatim}


\begin{Verbatim}[commandchars=\\\{\}]
{\color{outcolor}Out[{\color{outcolor}38}]:} \{'Dense': 64,
          'Dense\_1': 64,
          'Dropout': 0.45377377480700615,
          'choiceval': 'rmsprop',
          'filters': 32,
          'filters\_1': 16,
          'kernel\_size': 5,
          'kernel\_size\_1': 3,
          'l2': 0.0019801221163149862,
          'l2\_1': 0.8236255110533577,
          'lr': 0.003918784585237195,
          'lr\_1': 0.002237071747066137,
          'nb\_epoch': 30,
          'pool\_size': 2\}
\end{Verbatim}
            
    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}63}]:} \PY{n}{runtime\PYZus{}param}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{nb\PYZus{}epoch}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]} \PY{o}{=} \PY{l+m+mi}{150}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}64}]:} \PY{n}{runtime\PYZus{}best\PYZus{}model}\PY{p}{,}\PY{n}{result} \PY{o}{=} \PY{n}{keras\PYZus{}fmin\PYZus{}fnct}\PY{p}{(}\PY{n}{runtime\PYZus{}param}\PY{p}{)}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_
Layer (type)                 Output Shape              Param \#   
=================================================================
conv1d\_1 (Conv1D)            (None, 124, 32)           1472      
\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_
conv1d\_2 (Conv1D)            (None, 122, 16)           1552      
\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_
dropout\_1 (Dropout)          (None, 122, 16)           0         
\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_
max\_pooling1d\_1 (MaxPooling1 (None, 61, 16)            0         
\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_
flatten\_1 (Flatten)          (None, 976)               0         
\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_
dense\_1 (Dense)              (None, 64)                62528     
\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_
dense\_2 (Dense)              (None, 3)                 195       
=================================================================
Total params: 65,747
Trainable params: 65,747
Non-trainable params: 0
\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_
None

    \end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]
/glob/intel-python/versions/2018u2/intelpython3/lib/python3.6/site-packages/ipykernel\_launcher.py:31: UserWarning: The `nb\_epoch` argument in `fit` has been renamed `epochs`.

    \end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]
Train on 4067 samples, validate on 1560 samples
Epoch 1/150
4067/4067 [==============================] - 1s 344us/step - loss: 10.6708 - acc: 0.8375 - val\_loss: 3.0312 - val\_acc: 0.8923
Epoch 2/150
4067/4067 [==============================] - 1s 186us/step - loss: 1.2846 - acc: 0.8960 - val\_loss: 0.6160 - val\_acc: 0.8788
Epoch 3/150
4067/4067 [==============================] - 1s 184us/step - loss: 0.4912 - acc: 0.8943 - val\_loss: 0.4795 - val\_acc: 0.8628
Epoch 4/150
4067/4067 [==============================] - 1s 185us/step - loss: 0.3866 - acc: 0.9053 - val\_loss: 0.4627 - val\_acc: 0.8506
Epoch 5/150
4067/4067 [==============================] - 1s 183us/step - loss: 0.3421 - acc: 0.9098 - val\_loss: 0.4827 - val\_acc: 0.8724
Epoch 6/150
4067/4067 [==============================] - 1s 183us/step - loss: 0.3151 - acc: 0.9166 - val\_loss: 0.3515 - val\_acc: 0.8968
Epoch 7/150
4067/4067 [==============================] - 1s 183us/step - loss: 0.3091 - acc: 0.9154 - val\_loss: 0.3364 - val\_acc: 0.8853
Epoch 8/150
4067/4067 [==============================] - 1s 183us/step - loss: 0.2749 - acc: 0.9312 - val\_loss: 0.4064 - val\_acc: 0.8718
Epoch 9/150
4067/4067 [==============================] - 1s 183us/step - loss: 0.2743 - acc: 0.9272 - val\_loss: 0.3227 - val\_acc: 0.9122
Epoch 10/150
4067/4067 [==============================] - 1s 184us/step - loss: 0.2576 - acc: 0.9292 - val\_loss: 0.2934 - val\_acc: 0.9083
Epoch 11/150
4067/4067 [==============================] - 1s 183us/step - loss: 0.2791 - acc: 0.9302 - val\_loss: 0.3982 - val\_acc: 0.8712
Epoch 12/150
4067/4067 [==============================] - 1s 183us/step - loss: 0.2315 - acc: 0.9346 - val\_loss: 0.3192 - val\_acc: 0.9186
Epoch 13/150
4067/4067 [==============================] - 1s 183us/step - loss: 0.2301 - acc: 0.9410 - val\_loss: 0.3427 - val\_acc: 0.8821
Epoch 14/150
4067/4067 [==============================] - 1s 183us/step - loss: 0.2294 - acc: 0.9368 - val\_loss: 0.2628 - val\_acc: 0.9327
Epoch 15/150
4067/4067 [==============================] - 1s 183us/step - loss: 0.2371 - acc: 0.9353 - val\_loss: 0.2884 - val\_acc: 0.9071
Epoch 16/150
4067/4067 [==============================] - 1s 183us/step - loss: 0.2146 - acc: 0.9449 - val\_loss: 0.3369 - val\_acc: 0.8865
Epoch 17/150
4067/4067 [==============================] - 1s 183us/step - loss: 0.2065 - acc: 0.9447 - val\_loss: 0.2776 - val\_acc: 0.9019
Epoch 18/150
4067/4067 [==============================] - 1s 184us/step - loss: 0.2056 - acc: 0.9420 - val\_loss: 0.3021 - val\_acc: 0.8891
Epoch 19/150
4067/4067 [==============================] - 1s 183us/step - loss: 0.2223 - acc: 0.9398 - val\_loss: 0.2380 - val\_acc: 0.9205
Epoch 20/150
4067/4067 [==============================] - 1s 183us/step - loss: 0.1979 - acc: 0.9442 - val\_loss: 2.4294 - val\_acc: 0.6051
Epoch 21/150
4067/4067 [==============================] - 1s 183us/step - loss: 0.2421 - acc: 0.9432 - val\_loss: 0.2461 - val\_acc: 0.9109
Epoch 22/150
4067/4067 [==============================] - 1s 183us/step - loss: 0.1836 - acc: 0.9498 - val\_loss: 0.2768 - val\_acc: 0.9115
Epoch 23/150
4067/4067 [==============================] - 1s 183us/step - loss: 0.1963 - acc: 0.9457 - val\_loss: 0.2667 - val\_acc: 0.9077
Epoch 24/150
4067/4067 [==============================] - 1s 183us/step - loss: 0.1863 - acc: 0.9462 - val\_loss: 0.2308 - val\_acc: 0.9128
Epoch 25/150
4067/4067 [==============================] - 1s 183us/step - loss: 0.1844 - acc: 0.9462 - val\_loss: 0.2726 - val\_acc: 0.9038
Epoch 26/150
4067/4067 [==============================] - 1s 183us/step - loss: 0.1754 - acc: 0.9525 - val\_loss: 0.2099 - val\_acc: 0.9417
Epoch 27/150
4067/4067 [==============================] - 1s 183us/step - loss: 0.1793 - acc: 0.9511 - val\_loss: 0.2814 - val\_acc: 0.9077
Epoch 28/150
4067/4067 [==============================] - 1s 183us/step - loss: 0.1665 - acc: 0.9555 - val\_loss: 0.2140 - val\_acc: 0.9378
Epoch 29/150
4067/4067 [==============================] - 1s 183us/step - loss: 0.1705 - acc: 0.9575 - val\_loss: 0.2413 - val\_acc: 0.9359
Epoch 30/150
4067/4067 [==============================] - 1s 183us/step - loss: 0.1712 - acc: 0.9577 - val\_loss: 0.2297 - val\_acc: 0.9391
Epoch 31/150
4067/4067 [==============================] - 1s 183us/step - loss: 0.1698 - acc: 0.9565 - val\_loss: 0.2055 - val\_acc: 0.9417
Epoch 32/150
4067/4067 [==============================] - 1s 183us/step - loss: 0.1621 - acc: 0.9580 - val\_loss: 0.2441 - val\_acc: 0.9109
Epoch 33/150
4067/4067 [==============================] - 1s 196us/step - loss: 0.1537 - acc: 0.9557 - val\_loss: 0.4118 - val\_acc: 0.8808
Epoch 34/150
4067/4067 [==============================] - 1s 185us/step - loss: 0.1592 - acc: 0.9552 - val\_loss: 0.2546 - val\_acc: 0.9109
Epoch 35/150
4067/4067 [==============================] - 1s 183us/step - loss: 0.1598 - acc: 0.9570 - val\_loss: 0.2582 - val\_acc: 0.9244
Epoch 36/150
4067/4067 [==============================] - 1s 183us/step - loss: 0.1561 - acc: 0.9570 - val\_loss: 0.2554 - val\_acc: 0.9128
Epoch 37/150
4067/4067 [==============================] - 1s 183us/step - loss: 0.1612 - acc: 0.9555 - val\_loss: 0.2365 - val\_acc: 0.9250
Epoch 38/150
4067/4067 [==============================] - 1s 183us/step - loss: 0.1535 - acc: 0.9577 - val\_loss: 0.2300 - val\_acc: 0.9179
Epoch 39/150
4067/4067 [==============================] - 1s 183us/step - loss: 0.1490 - acc: 0.9562 - val\_loss: 0.2189 - val\_acc: 0.9417
Epoch 40/150
4067/4067 [==============================] - 1s 183us/step - loss: 0.1476 - acc: 0.9604 - val\_loss: 0.2207 - val\_acc: 0.9346
Epoch 41/150
4067/4067 [==============================] - 1s 182us/step - loss: 0.1772 - acc: 0.9577 - val\_loss: 0.2618 - val\_acc: 0.9071
Epoch 42/150
4067/4067 [==============================] - 1s 183us/step - loss: 0.1421 - acc: 0.9609 - val\_loss: 0.2477 - val\_acc: 0.9410
Epoch 43/150
4067/4067 [==============================] - 1s 183us/step - loss: 0.1492 - acc: 0.9639 - val\_loss: 0.2982 - val\_acc: 0.9032
Epoch 44/150
4067/4067 [==============================] - 1s 183us/step - loss: 0.1643 - acc: 0.9575 - val\_loss: 0.2250 - val\_acc: 0.9359
Epoch 45/150
4067/4067 [==============================] - 1s 183us/step - loss: 0.1510 - acc: 0.9643 - val\_loss: 0.2813 - val\_acc: 0.9122
Epoch 46/150
4067/4067 [==============================] - 1s 183us/step - loss: 0.1519 - acc: 0.9639 - val\_loss: 0.2296 - val\_acc: 0.9474
Epoch 47/150
4067/4067 [==============================] - 1s 183us/step - loss: 0.1437 - acc: 0.9621 - val\_loss: 0.2104 - val\_acc: 0.9468
Epoch 48/150
4067/4067 [==============================] - 1s 183us/step - loss: 0.1351 - acc: 0.9636 - val\_loss: 0.3534 - val\_acc: 0.8942
Epoch 49/150
4067/4067 [==============================] - 1s 183us/step - loss: 0.1476 - acc: 0.9621 - val\_loss: 0.2574 - val\_acc: 0.9135
Epoch 50/150
4067/4067 [==============================] - 1s 183us/step - loss: 0.1399 - acc: 0.9634 - val\_loss: 0.2293 - val\_acc: 0.9378
Epoch 51/150
4067/4067 [==============================] - 1s 183us/step - loss: 0.1425 - acc: 0.9599 - val\_loss: 0.2763 - val\_acc: 0.9090
Epoch 52/150
4067/4067 [==============================] - 1s 183us/step - loss: 0.1390 - acc: 0.9641 - val\_loss: 0.2954 - val\_acc: 0.9083
Epoch 53/150
4067/4067 [==============================] - 1s 185us/step - loss: 0.1492 - acc: 0.9636 - val\_loss: 0.2367 - val\_acc: 0.9199
Epoch 54/150
4067/4067 [==============================] - 1s 183us/step - loss: 0.1344 - acc: 0.9656 - val\_loss: 0.2476 - val\_acc: 0.9256
Epoch 55/150
4067/4067 [==============================] - 1s 183us/step - loss: 0.1410 - acc: 0.9648 - val\_loss: 0.3849 - val\_acc: 0.8846
Epoch 56/150
4067/4067 [==============================] - 1s 183us/step - loss: 0.1417 - acc: 0.9636 - val\_loss: 0.2411 - val\_acc: 0.9340
Epoch 57/150
4067/4067 [==============================] - 1s 183us/step - loss: 0.1436 - acc: 0.9624 - val\_loss: 0.3697 - val\_acc: 0.9147
Epoch 58/150
4067/4067 [==============================] - 1s 183us/step - loss: 0.1390 - acc: 0.9675 - val\_loss: 0.2298 - val\_acc: 0.9442
Epoch 59/150
4067/4067 [==============================] - 1s 183us/step - loss: 0.1400 - acc: 0.9658 - val\_loss: 0.2142 - val\_acc: 0.9545
Epoch 60/150
4067/4067 [==============================] - 1s 183us/step - loss: 0.1312 - acc: 0.9666 - val\_loss: 0.2589 - val\_acc: 0.9276
Epoch 61/150
4067/4067 [==============================] - 1s 183us/step - loss: 0.1295 - acc: 0.9668 - val\_loss: 0.3615 - val\_acc: 0.8885
Epoch 62/150
4067/4067 [==============================] - 1s 183us/step - loss: 0.1288 - acc: 0.9673 - val\_loss: 0.2591 - val\_acc: 0.9256
Epoch 63/150
4067/4067 [==============================] - 1s 185us/step - loss: 0.1601 - acc: 0.9658 - val\_loss: 0.2101 - val\_acc: 0.9526
Epoch 64/150
4067/4067 [==============================] - 1s 185us/step - loss: 0.1275 - acc: 0.9702 - val\_loss: 0.3392 - val\_acc: 0.8987
Epoch 65/150
4067/4067 [==============================] - 1s 185us/step - loss: 0.1365 - acc: 0.9648 - val\_loss: 0.3122 - val\_acc: 0.9038
Epoch 66/150
4067/4067 [==============================] - 1s 183us/step - loss: 0.1385 - acc: 0.9671 - val\_loss: 0.4001 - val\_acc: 0.8904
Epoch 67/150
4067/4067 [==============================] - 1s 183us/step - loss: 0.1444 - acc: 0.9683 - val\_loss: 0.2269 - val\_acc: 0.9353
Epoch 68/150
4067/4067 [==============================] - 1s 183us/step - loss: 0.1374 - acc: 0.9661 - val\_loss: 0.3215 - val\_acc: 0.9032
Epoch 69/150
4067/4067 [==============================] - 1s 183us/step - loss: 0.1310 - acc: 0.9712 - val\_loss: 0.3101 - val\_acc: 0.9064
Epoch 70/150
4067/4067 [==============================] - 1s 183us/step - loss: 0.1302 - acc: 0.9666 - val\_loss: 0.2763 - val\_acc: 0.9173
Epoch 71/150
4067/4067 [==============================] - 1s 183us/step - loss: 0.1283 - acc: 0.9698 - val\_loss: 0.3334 - val\_acc: 0.9038
Epoch 72/150
4067/4067 [==============================] - 1s 183us/step - loss: 0.1256 - acc: 0.9705 - val\_loss: 0.3798 - val\_acc: 0.8821
Epoch 73/150
4067/4067 [==============================] - 1s 183us/step - loss: 0.1311 - acc: 0.9668 - val\_loss: 0.3486 - val\_acc: 0.8981
Epoch 74/150
4067/4067 [==============================] - 1s 183us/step - loss: 0.1244 - acc: 0.9715 - val\_loss: 0.4297 - val\_acc: 0.8776
Epoch 75/150
4067/4067 [==============================] - 1s 183us/step - loss: 0.1321 - acc: 0.9671 - val\_loss: 0.2557 - val\_acc: 0.9218
Epoch 76/150
4067/4067 [==============================] - 1s 183us/step - loss: 0.1217 - acc: 0.9700 - val\_loss: 0.2208 - val\_acc: 0.9404
Epoch 77/150
4067/4067 [==============================] - 1s 182us/step - loss: 0.1246 - acc: 0.9720 - val\_loss: 0.2340 - val\_acc: 0.9417
Epoch 78/150
4067/4067 [==============================] - 1s 185us/step - loss: 0.1424 - acc: 0.9705 - val\_loss: 0.2994 - val\_acc: 0.9064
Epoch 79/150
4067/4067 [==============================] - 1s 183us/step - loss: 0.1402 - acc: 0.9688 - val\_loss: 0.2305 - val\_acc: 0.9333
Epoch 80/150
4067/4067 [==============================] - 1s 183us/step - loss: 0.1284 - acc: 0.9722 - val\_loss: 0.2668 - val\_acc: 0.9212
Epoch 81/150
4067/4067 [==============================] - 1s 183us/step - loss: 0.1396 - acc: 0.9693 - val\_loss: 0.3135 - val\_acc: 0.9109
Epoch 82/150
4067/4067 [==============================] - 1s 183us/step - loss: 0.1281 - acc: 0.9700 - val\_loss: 0.2462 - val\_acc: 0.9353
Epoch 83/150
4067/4067 [==============================] - 1s 183us/step - loss: 0.1311 - acc: 0.9705 - val\_loss: 0.2575 - val\_acc: 0.9205
Epoch 84/150
4067/4067 [==============================] - 1s 183us/step - loss: 0.1373 - acc: 0.9680 - val\_loss: 0.2305 - val\_acc: 0.9449
Epoch 85/150
4067/4067 [==============================] - 1s 183us/step - loss: 0.1213 - acc: 0.9722 - val\_loss: 0.2131 - val\_acc: 0.9532
Epoch 86/150
4067/4067 [==============================] - 1s 183us/step - loss: 0.1316 - acc: 0.9707 - val\_loss: 0.2447 - val\_acc: 0.9314
Epoch 87/150
4067/4067 [==============================] - 1s 183us/step - loss: 0.1110 - acc: 0.9730 - val\_loss: 0.2427 - val\_acc: 0.9372
Epoch 88/150
4067/4067 [==============================] - 1s 183us/step - loss: 0.1190 - acc: 0.9712 - val\_loss: 0.2731 - val\_acc: 0.9250
Epoch 89/150
4067/4067 [==============================] - 1s 183us/step - loss: 0.1252 - acc: 0.9717 - val\_loss: 0.2310 - val\_acc: 0.9436
Epoch 90/150
4067/4067 [==============================] - 1s 185us/step - loss: 0.1225 - acc: 0.9702 - val\_loss: 0.2172 - val\_acc: 0.9532
Epoch 91/150
4067/4067 [==============================] - 1s 183us/step - loss: 0.1260 - acc: 0.9725 - val\_loss: 0.2889 - val\_acc: 0.9179
Epoch 92/150
4067/4067 [==============================] - 1s 183us/step - loss: 0.1554 - acc: 0.9651 - val\_loss: 0.2373 - val\_acc: 0.9462
Epoch 93/150
4067/4067 [==============================] - 1s 183us/step - loss: 0.1225 - acc: 0.9761 - val\_loss: 0.2510 - val\_acc: 0.9340
Epoch 94/150
4067/4067 [==============================] - 1s 183us/step - loss: 0.1249 - acc: 0.9712 - val\_loss: 0.2228 - val\_acc: 0.9526
Epoch 95/150
4067/4067 [==============================] - 1s 183us/step - loss: 0.1170 - acc: 0.9727 - val\_loss: 0.3167 - val\_acc: 0.9205
Epoch 96/150
4067/4067 [==============================] - 1s 184us/step - loss: 0.1245 - acc: 0.9742 - val\_loss: 0.2997 - val\_acc: 0.9237
Epoch 97/150
4067/4067 [==============================] - 1s 183us/step - loss: 0.1176 - acc: 0.9717 - val\_loss: 0.2330 - val\_acc: 0.9365
Epoch 98/150
4067/4067 [==============================] - 1s 182us/step - loss: 0.1084 - acc: 0.9737 - val\_loss: 0.2235 - val\_acc: 0.9449
Epoch 99/150
4067/4067 [==============================] - 1s 183us/step - loss: 0.1301 - acc: 0.9715 - val\_loss: 0.2373 - val\_acc: 0.9487
Epoch 100/150
4067/4067 [==============================] - 1s 183us/step - loss: 0.1204 - acc: 0.9678 - val\_loss: 0.2362 - val\_acc: 0.9333
Epoch 101/150
4067/4067 [==============================] - 1s 183us/step - loss: 0.1241 - acc: 0.9715 - val\_loss: 0.2289 - val\_acc: 0.9494
Epoch 102/150
4067/4067 [==============================] - 1s 183us/step - loss: 0.1080 - acc: 0.9771 - val\_loss: 0.2370 - val\_acc: 0.9449
Epoch 103/150
4067/4067 [==============================] - 1s 183us/step - loss: 0.1394 - acc: 0.9678 - val\_loss: 0.3265 - val\_acc: 0.9071
Epoch 104/150
4067/4067 [==============================] - 1s 183us/step - loss: 0.1248 - acc: 0.9757 - val\_loss: 0.2884 - val\_acc: 0.9154
Epoch 105/150
4067/4067 [==============================] - 1s 184us/step - loss: 0.1148 - acc: 0.9734 - val\_loss: 0.2845 - val\_acc: 0.9205
Epoch 106/150
4067/4067 [==============================] - 1s 183us/step - loss: 0.1267 - acc: 0.9705 - val\_loss: 0.2627 - val\_acc: 0.9353
Epoch 107/150
4067/4067 [==============================] - 1s 183us/step - loss: 0.1139 - acc: 0.9749 - val\_loss: 0.2368 - val\_acc: 0.9449
Epoch 108/150
4067/4067 [==============================] - 1s 183us/step - loss: 0.1211 - acc: 0.9688 - val\_loss: 0.2644 - val\_acc: 0.9269
Epoch 109/150
4067/4067 [==============================] - 1s 183us/step - loss: 0.1279 - acc: 0.9715 - val\_loss: 0.2368 - val\_acc: 0.9462
Epoch 110/150
4067/4067 [==============================] - 1s 183us/step - loss: 0.1206 - acc: 0.9710 - val\_loss: 0.2238 - val\_acc: 0.9346
Epoch 111/150
4067/4067 [==============================] - 1s 183us/step - loss: 0.1085 - acc: 0.9766 - val\_loss: 0.2590 - val\_acc: 0.9359
Epoch 112/150
4067/4067 [==============================] - 1s 183us/step - loss: 0.1028 - acc: 0.9779 - val\_loss: 0.2303 - val\_acc: 0.9404
Epoch 113/150
4067/4067 [==============================] - 1s 183us/step - loss: 0.1205 - acc: 0.9734 - val\_loss: 0.2659 - val\_acc: 0.9231
Epoch 114/150
4067/4067 [==============================] - 1s 192us/step - loss: 0.1214 - acc: 0.9732 - val\_loss: 0.2675 - val\_acc: 0.9288
Epoch 115/150
4067/4067 [==============================] - 1s 183us/step - loss: 0.1396 - acc: 0.9754 - val\_loss: 0.2180 - val\_acc: 0.9481
Epoch 116/150
4067/4067 [==============================] - 1s 183us/step - loss: 0.1134 - acc: 0.9734 - val\_loss: 0.2532 - val\_acc: 0.9327
Epoch 117/150
4067/4067 [==============================] - 1s 182us/step - loss: 0.1283 - acc: 0.9744 - val\_loss: 0.2144 - val\_acc: 0.9558
Epoch 118/150
4067/4067 [==============================] - 1s 183us/step - loss: 0.1112 - acc: 0.9761 - val\_loss: 0.2478 - val\_acc: 0.9314
Epoch 119/150
4067/4067 [==============================] - 1s 183us/step - loss: 0.1104 - acc: 0.9730 - val\_loss: 0.2215 - val\_acc: 0.9506
Epoch 120/150
4067/4067 [==============================] - 1s 183us/step - loss: 0.1208 - acc: 0.9749 - val\_loss: 0.3212 - val\_acc: 0.9141
Epoch 121/150
4067/4067 [==============================] - 1s 183us/step - loss: 0.1047 - acc: 0.9786 - val\_loss: 0.2165 - val\_acc: 0.9500
Epoch 122/150
4067/4067 [==============================] - 1s 184us/step - loss: 0.1258 - acc: 0.9761 - val\_loss: 0.2484 - val\_acc: 0.9429
Epoch 123/150
4067/4067 [==============================] - 1s 183us/step - loss: 0.1092 - acc: 0.9761 - val\_loss: 0.2362 - val\_acc: 0.9410
Epoch 124/150
4067/4067 [==============================] - 1s 183us/step - loss: 0.1156 - acc: 0.9771 - val\_loss: 0.2684 - val\_acc: 0.9410
Epoch 125/150
4067/4067 [==============================] - 1s 184us/step - loss: 0.1174 - acc: 0.9725 - val\_loss: 0.2645 - val\_acc: 0.9333
Epoch 126/150
4067/4067 [==============================] - 1s 183us/step - loss: 0.1259 - acc: 0.9749 - val\_loss: 0.2623 - val\_acc: 0.9372
Epoch 127/150
4067/4067 [==============================] - 1s 183us/step - loss: 0.1037 - acc: 0.9774 - val\_loss: 0.2289 - val\_acc: 0.9474
Epoch 128/150
4067/4067 [==============================] - 1s 183us/step - loss: 0.1121 - acc: 0.9757 - val\_loss: 0.2813 - val\_acc: 0.9321
Epoch 129/150
4067/4067 [==============================] - 1s 183us/step - loss: 0.1411 - acc: 0.9734 - val\_loss: 0.3860 - val\_acc: 0.9077
Epoch 130/150
4067/4067 [==============================] - 1s 183us/step - loss: 0.1013 - acc: 0.9811 - val\_loss: 0.2585 - val\_acc: 0.9487
Epoch 131/150
4067/4067 [==============================] - 1s 183us/step - loss: 0.1160 - acc: 0.9764 - val\_loss: 0.2923 - val\_acc: 0.9288
Epoch 132/150
4067/4067 [==============================] - 1s 183us/step - loss: 0.1540 - acc: 0.9705 - val\_loss: 0.2367 - val\_acc: 0.9506
Epoch 133/150
4067/4067 [==============================] - 1s 184us/step - loss: 0.1229 - acc: 0.9747 - val\_loss: 0.2756 - val\_acc: 0.9346
Epoch 134/150
4067/4067 [==============================] - 1s 183us/step - loss: 0.1112 - acc: 0.9779 - val\_loss: 0.2657 - val\_acc: 0.9436
Epoch 135/150
4067/4067 [==============================] - 1s 182us/step - loss: 0.1277 - acc: 0.9757 - val\_loss: 0.3435 - val\_acc: 0.9179
Epoch 136/150
4067/4067 [==============================] - 1s 183us/step - loss: 0.1165 - acc: 0.9769 - val\_loss: 0.2628 - val\_acc: 0.9423
Epoch 137/150
4067/4067 [==============================] - 1s 183us/step - loss: 0.1170 - acc: 0.9784 - val\_loss: 0.2763 - val\_acc: 0.9353
Epoch 138/150
4067/4067 [==============================] - 1s 183us/step - loss: 0.1261 - acc: 0.9747 - val\_loss: 0.2810 - val\_acc: 0.9359
Epoch 139/150
4067/4067 [==============================] - 1s 184us/step - loss: 0.1050 - acc: 0.9764 - val\_loss: 0.4305 - val\_acc: 0.9173
Epoch 140/150
4067/4067 [==============================] - 1s 183us/step - loss: 0.1088 - acc: 0.9774 - val\_loss: 0.3077 - val\_acc: 0.9212
Epoch 141/150
4067/4067 [==============================] - 1s 182us/step - loss: 0.1082 - acc: 0.9749 - val\_loss: 0.2747 - val\_acc: 0.9237
Epoch 142/150
4067/4067 [==============================] - 1s 185us/step - loss: 0.1251 - acc: 0.9727 - val\_loss: 0.2616 - val\_acc: 0.9269
Epoch 143/150
4067/4067 [==============================] - 1s 183us/step - loss: 0.1217 - acc: 0.9759 - val\_loss: 0.2994 - val\_acc: 0.9224
Epoch 144/150
4067/4067 [==============================] - 1s 183us/step - loss: 0.1080 - acc: 0.9801 - val\_loss: 0.5078 - val\_acc: 0.8667
Epoch 145/150
4067/4067 [==============================] - 1s 183us/step - loss: 0.1048 - acc: 0.9798 - val\_loss: 0.2911 - val\_acc: 0.9282
Epoch 146/150
4067/4067 [==============================] - 1s 185us/step - loss: 0.1175 - acc: 0.9779 - val\_loss: 0.3130 - val\_acc: 0.9199
Epoch 147/150
4067/4067 [==============================] - 1s 185us/step - loss: 0.1047 - acc: 0.9798 - val\_loss: 0.3355 - val\_acc: 0.9141
Epoch 148/150
4067/4067 [==============================] - 1s 183us/step - loss: 0.1140 - acc: 0.9766 - val\_loss: 0.2574 - val\_acc: 0.9449
Epoch 149/150
4067/4067 [==============================] - 1s 183us/step - loss: 0.1539 - acc: 0.9720 - val\_loss: 0.3084 - val\_acc: 0.9231
Epoch 150/150
4067/4067 [==============================] - 1s 185us/step - loss: 0.1189 - acc: 0.9744 - val\_loss: 0.2738 - val\_acc: 0.9321

    \end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}66}]:} \PY{n}{plt}\PY{o}{.}\PY{n}{figure}\PY{p}{(}\PY{n}{figsize}\PY{o}{=}\PY{p}{(}\PY{l+m+mi}{12}\PY{p}{,}\PY{l+m+mi}{8}\PY{p}{)}\PY{p}{)}
         \PY{n}{plt}\PY{o}{.}\PY{n}{plot}\PY{p}{(}\PY{n}{result}\PY{o}{.}\PY{n}{history}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{loss}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{,}\PY{n}{label}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Train loss}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
         \PY{n}{plt}\PY{o}{.}\PY{n}{plot}\PY{p}{(}\PY{n}{result}\PY{o}{.}\PY{n}{history}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{val\PYZus{}loss}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{,}\PY{n}{label} \PY{o}{=} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Validation Loss}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
         \PY{n}{plt}\PY{o}{.}\PY{n}{xlabel}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{epoch no}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
         \PY{n}{plt}\PY{o}{.}\PY{n}{ylabel}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{loss}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
         \PY{n}{plt}\PY{o}{.}\PY{n}{legend}\PY{p}{(}\PY{p}{)}
         \PY{n}{plt}\PY{o}{.}\PY{n}{show}\PY{p}{(}\PY{p}{)}
\end{Verbatim}


    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{output_198_0.png}
    \end{center}
    { \hspace*{\fill} \\}
    
    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}67}]:} \PY{n}{plt}\PY{o}{.}\PY{n}{figure}\PY{p}{(}\PY{n}{figsize}\PY{o}{=}\PY{p}{(}\PY{l+m+mi}{14}\PY{p}{,}\PY{l+m+mi}{8}\PY{p}{)}\PY{p}{)}
         \PY{n}{plt}\PY{o}{.}\PY{n}{plot}\PY{p}{(}\PY{n}{result}\PY{o}{.}\PY{n}{history}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{loss}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{,}\PY{n}{label}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Train loss}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
         \PY{n}{plt}\PY{o}{.}\PY{n}{plot}\PY{p}{(}\PY{n}{result}\PY{o}{.}\PY{n}{history}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{val\PYZus{}loss}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{,}\PY{n}{label} \PY{o}{=} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Validation Loss}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
         \PY{n}{plt}\PY{o}{.}\PY{n}{ylim}\PY{p}{(}\PY{l+m+mi}{0}\PY{p}{,}\PY{l+m+mi}{1}\PY{p}{)}
         \PY{n}{plt}\PY{o}{.}\PY{n}{xlabel}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{epoch no}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
         \PY{n}{plt}\PY{o}{.}\PY{n}{ylabel}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{loss}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
         \PY{n}{plt}\PY{o}{.}\PY{n}{legend}\PY{p}{(}\PY{p}{)}
         \PY{n}{plt}\PY{o}{.}\PY{n}{show}\PY{p}{(}\PY{p}{)}
\end{Verbatim}


    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{output_199_0.png}
    \end{center}
    { \hspace*{\fill} \\}
    
    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}68}]:} \PY{n}{plt}\PY{o}{.}\PY{n}{figure}\PY{p}{(}\PY{n}{figsize}\PY{o}{=}\PY{p}{(}\PY{l+m+mi}{12}\PY{p}{,}\PY{l+m+mi}{8}\PY{p}{)}\PY{p}{)}
         \PY{n}{plt}\PY{o}{.}\PY{n}{plot}\PY{p}{(}\PY{n}{result}\PY{o}{.}\PY{n}{history}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{acc}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{,}\PY{n}{label}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Train acc}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
         \PY{n}{plt}\PY{o}{.}\PY{n}{plot}\PY{p}{(}\PY{n}{result}\PY{o}{.}\PY{n}{history}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{val\PYZus{}acc}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{,}\PY{n}{label} \PY{o}{=} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Validation acc}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
         \PY{n}{plt}\PY{o}{.}\PY{n}{xlabel}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{epoch no}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
         \PY{n}{plt}\PY{o}{.}\PY{n}{ylabel}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{acc}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
         \PY{n}{plt}\PY{o}{.}\PY{n}{legend}\PY{p}{(}\PY{p}{)}
         \PY{n}{plt}\PY{o}{.}\PY{n}{show}\PY{p}{(}\PY{p}{)}
\end{Verbatim}


    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{output_200_0.png}
    \end{center}
    { \hspace*{\fill} \\}
    
    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}69}]:} \PY{n}{plt}\PY{o}{.}\PY{n}{figure}\PY{p}{(}\PY{n}{figsize}\PY{o}{=}\PY{p}{(}\PY{l+m+mi}{12}\PY{p}{,}\PY{l+m+mi}{8}\PY{p}{)}\PY{p}{)}
         \PY{n}{plt}\PY{o}{.}\PY{n}{plot}\PY{p}{(}\PY{n}{result}\PY{o}{.}\PY{n}{history}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{acc}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{,}\PY{n}{label}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Train acc}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
         \PY{n}{plt}\PY{o}{.}\PY{n}{plot}\PY{p}{(}\PY{n}{result}\PY{o}{.}\PY{n}{history}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{val\PYZus{}acc}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{,}\PY{n}{label} \PY{o}{=} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Validation acc}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
         \PY{n}{plt}\PY{o}{.}\PY{n}{xlabel}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{epoch no}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
         \PY{n}{plt}\PY{o}{.}\PY{n}{ylabel}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{acc}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
         \PY{n}{plt}\PY{o}{.}\PY{n}{ylim}\PY{p}{(}\PY{l+m+mf}{0.90}\PY{p}{,}\PY{l+m+mi}{1}\PY{p}{)}
         \PY{n}{plt}\PY{o}{.}\PY{n}{legend}\PY{p}{(}\PY{p}{)}
         \PY{n}{plt}\PY{o}{.}\PY{n}{show}\PY{p}{(}\PY{p}{)}
\end{Verbatim}


    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{output_201_0.png}
    \end{center}
    { \hspace*{\fill} \\}
    
    around 57-59 score is giving good accuracy wit less overfitting

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}77}]:} \PY{n}{runtime\PYZus{}param}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{nb\PYZus{}epoch}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]} \PY{o}{=} \PY{l+m+mi}{59}
         \PY{n}{best\PYZus{}model}\PY{p}{,}\PY{n}{result} \PY{o}{=} \PY{n}{keras\PYZus{}fmin\PYZus{}fnct}\PY{p}{(}\PY{n}{runtime\PYZus{}param}\PY{p}{)}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
Exception ignored in: <bound method BaseSession.\_Callable.\_\_del\_\_ of <tensorflow.python.client.session.BaseSession.\_Callable object at 0x148471f420b8>>
Traceback (most recent call last):
  File "/glob/intel-python/versions/2018u2/intelpython3/lib/python3.6/site-packages/tensorflow/python/client/session.py", line 1398, in \_\_del\_\_
    self.\_session.\_session, self.\_handle, status)
  File "/glob/intel-python/versions/2018u2/intelpython3/lib/python3.6/site-packages/tensorflow/python/framework/errors\_impl.py", line 519, in \_\_exit\_\_
    c\_api.TF\_GetCode(self.status.status))
tensorflow.python.framework.errors\_impl.InvalidArgumentError: No such callable handle: 149842480
/glob/intel-python/versions/2018u2/intelpython3/lib/python3.6/site-packages/ipykernel\_launcher.py:31: UserWarning: The `nb\_epoch` argument in `fit` has been renamed `epochs`.

    \end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]
\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_
Layer (type)                 Output Shape              Param \#   
=================================================================
conv1d\_1 (Conv1D)            (None, 124, 32)           1472      
\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_
conv1d\_2 (Conv1D)            (None, 122, 16)           1552      
\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_
dropout\_1 (Dropout)          (None, 122, 16)           0         
\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_
max\_pooling1d\_1 (MaxPooling1 (None, 61, 16)            0         
\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_
flatten\_1 (Flatten)          (None, 976)               0         
\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_
dense\_1 (Dense)              (None, 64)                62528     
\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_
dense\_2 (Dense)              (None, 3)                 195       
=================================================================
Total params: 65,747
Trainable params: 65,747
Non-trainable params: 0
\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_
None
Train on 4067 samples, validate on 1560 samples
Epoch 1/59
4067/4067 [==============================] - 2s 383us/step - loss: 10.6708 - acc: 0.8375 - val\_loss: 3.0312 - val\_acc: 0.8923
Epoch 2/59
4067/4067 [==============================] - 1s 184us/step - loss: 1.2846 - acc: 0.8960 - val\_loss: 0.6160 - val\_acc: 0.8788
Epoch 3/59
4067/4067 [==============================] - 1s 184us/step - loss: 0.4912 - acc: 0.8943 - val\_loss: 0.4795 - val\_acc: 0.8628
Epoch 4/59
4067/4067 [==============================] - 1s 183us/step - loss: 0.3866 - acc: 0.9053 - val\_loss: 0.4627 - val\_acc: 0.8506
Epoch 5/59
4067/4067 [==============================] - 1s 184us/step - loss: 0.3421 - acc: 0.9098 - val\_loss: 0.4827 - val\_acc: 0.8724
Epoch 6/59
4067/4067 [==============================] - 1s 184us/step - loss: 0.3151 - acc: 0.9166 - val\_loss: 0.3515 - val\_acc: 0.8968
Epoch 7/59
4067/4067 [==============================] - 1s 184us/step - loss: 0.3091 - acc: 0.9154 - val\_loss: 0.3364 - val\_acc: 0.8853
Epoch 8/59
4067/4067 [==============================] - 1s 183us/step - loss: 0.2749 - acc: 0.9312 - val\_loss: 0.4064 - val\_acc: 0.8718
Epoch 9/59
4067/4067 [==============================] - 1s 184us/step - loss: 0.2743 - acc: 0.9272 - val\_loss: 0.3227 - val\_acc: 0.9122
Epoch 10/59
4067/4067 [==============================] - 1s 183us/step - loss: 0.2576 - acc: 0.9292 - val\_loss: 0.2934 - val\_acc: 0.9083
Epoch 11/59
4067/4067 [==============================] - 1s 184us/step - loss: 0.2791 - acc: 0.9302 - val\_loss: 0.3982 - val\_acc: 0.8712
Epoch 12/59
4067/4067 [==============================] - 1s 184us/step - loss: 0.2315 - acc: 0.9346 - val\_loss: 0.3192 - val\_acc: 0.9186
Epoch 13/59
4067/4067 [==============================] - 1s 183us/step - loss: 0.2301 - acc: 0.9410 - val\_loss: 0.3427 - val\_acc: 0.8821
Epoch 14/59
4067/4067 [==============================] - 1s 183us/step - loss: 0.2294 - acc: 0.9368 - val\_loss: 0.2628 - val\_acc: 0.9327
Epoch 15/59
4067/4067 [==============================] - 1s 183us/step - loss: 0.2371 - acc: 0.9353 - val\_loss: 0.2884 - val\_acc: 0.9071
Epoch 16/59
4067/4067 [==============================] - 1s 183us/step - loss: 0.2146 - acc: 0.9449 - val\_loss: 0.3369 - val\_acc: 0.8865
Epoch 17/59
4067/4067 [==============================] - 1s 184us/step - loss: 0.2065 - acc: 0.9447 - val\_loss: 0.2776 - val\_acc: 0.9019
Epoch 18/59
4067/4067 [==============================] - 1s 184us/step - loss: 0.2056 - acc: 0.9420 - val\_loss: 0.3021 - val\_acc: 0.8891
Epoch 19/59
4067/4067 [==============================] - 1s 186us/step - loss: 0.2223 - acc: 0.9398 - val\_loss: 0.2380 - val\_acc: 0.9205
Epoch 20/59
4067/4067 [==============================] - 1s 184us/step - loss: 0.1979 - acc: 0.9442 - val\_loss: 2.4294 - val\_acc: 0.6051
Epoch 21/59
4067/4067 [==============================] - 1s 184us/step - loss: 0.2421 - acc: 0.9432 - val\_loss: 0.2461 - val\_acc: 0.9109
Epoch 22/59
4067/4067 [==============================] - 1s 184us/step - loss: 0.1836 - acc: 0.9498 - val\_loss: 0.2768 - val\_acc: 0.9115
Epoch 23/59
4067/4067 [==============================] - 1s 187us/step - loss: 0.1963 - acc: 0.9457 - val\_loss: 0.2667 - val\_acc: 0.9077
Epoch 24/59
4067/4067 [==============================] - 1s 184us/step - loss: 0.1863 - acc: 0.9462 - val\_loss: 0.2308 - val\_acc: 0.9128
Epoch 25/59
4067/4067 [==============================] - 1s 186us/step - loss: 0.1844 - acc: 0.9462 - val\_loss: 0.2726 - val\_acc: 0.9038
Epoch 26/59
4067/4067 [==============================] - 1s 184us/step - loss: 0.1754 - acc: 0.9525 - val\_loss: 0.2099 - val\_acc: 0.9417
Epoch 27/59
4067/4067 [==============================] - 1s 183us/step - loss: 0.1793 - acc: 0.9511 - val\_loss: 0.2814 - val\_acc: 0.9077
Epoch 28/59
4067/4067 [==============================] - 1s 184us/step - loss: 0.1665 - acc: 0.9555 - val\_loss: 0.2140 - val\_acc: 0.9378
Epoch 29/59
4067/4067 [==============================] - 1s 184us/step - loss: 0.1705 - acc: 0.9575 - val\_loss: 0.2413 - val\_acc: 0.9359
Epoch 30/59
4067/4067 [==============================] - 1s 183us/step - loss: 0.1712 - acc: 0.9577 - val\_loss: 0.2297 - val\_acc: 0.9391
Epoch 31/59
4067/4067 [==============================] - 1s 184us/step - loss: 0.1698 - acc: 0.9565 - val\_loss: 0.2055 - val\_acc: 0.9417
Epoch 32/59
4067/4067 [==============================] - 1s 184us/step - loss: 0.1621 - acc: 0.9580 - val\_loss: 0.2441 - val\_acc: 0.9109
Epoch 33/59
4067/4067 [==============================] - 1s 183us/step - loss: 0.1537 - acc: 0.9557 - val\_loss: 0.4118 - val\_acc: 0.8808
Epoch 34/59
4067/4067 [==============================] - 1s 184us/step - loss: 0.1592 - acc: 0.9552 - val\_loss: 0.2546 - val\_acc: 0.9109
Epoch 35/59
4067/4067 [==============================] - 1s 183us/step - loss: 0.1598 - acc: 0.9570 - val\_loss: 0.2582 - val\_acc: 0.9244
Epoch 36/59
4067/4067 [==============================] - 1s 195us/step - loss: 0.1561 - acc: 0.9570 - val\_loss: 0.2554 - val\_acc: 0.9128
Epoch 37/59
4067/4067 [==============================] - 1s 184us/step - loss: 0.1612 - acc: 0.9555 - val\_loss: 0.2365 - val\_acc: 0.9250
Epoch 38/59
4067/4067 [==============================] - 1s 183us/step - loss: 0.1535 - acc: 0.9577 - val\_loss: 0.2300 - val\_acc: 0.9179
Epoch 39/59
4067/4067 [==============================] - 1s 183us/step - loss: 0.1490 - acc: 0.9562 - val\_loss: 0.2189 - val\_acc: 0.9417
Epoch 40/59
4067/4067 [==============================] - 1s 183us/step - loss: 0.1476 - acc: 0.9604 - val\_loss: 0.2207 - val\_acc: 0.9346
Epoch 41/59
4067/4067 [==============================] - 1s 184us/step - loss: 0.1772 - acc: 0.9577 - val\_loss: 0.2618 - val\_acc: 0.9071
Epoch 42/59
4067/4067 [==============================] - 1s 183us/step - loss: 0.1421 - acc: 0.9609 - val\_loss: 0.2477 - val\_acc: 0.9410
Epoch 43/59
4067/4067 [==============================] - 1s 183us/step - loss: 0.1492 - acc: 0.9639 - val\_loss: 0.2982 - val\_acc: 0.9032
Epoch 44/59
4067/4067 [==============================] - 1s 183us/step - loss: 0.1643 - acc: 0.9575 - val\_loss: 0.2250 - val\_acc: 0.9359
Epoch 45/59
4067/4067 [==============================] - 1s 184us/step - loss: 0.1510 - acc: 0.9643 - val\_loss: 0.2813 - val\_acc: 0.9122
Epoch 46/59
4067/4067 [==============================] - 1s 183us/step - loss: 0.1519 - acc: 0.9639 - val\_loss: 0.2296 - val\_acc: 0.9474
Epoch 47/59
4067/4067 [==============================] - 1s 183us/step - loss: 0.1437 - acc: 0.9621 - val\_loss: 0.2104 - val\_acc: 0.9468
Epoch 48/59
4067/4067 [==============================] - 1s 187us/step - loss: 0.1351 - acc: 0.9636 - val\_loss: 0.3534 - val\_acc: 0.8942
Epoch 49/59
4067/4067 [==============================] - 1s 184us/step - loss: 0.1476 - acc: 0.9621 - val\_loss: 0.2574 - val\_acc: 0.9135
Epoch 50/59
4067/4067 [==============================] - 1s 184us/step - loss: 0.1399 - acc: 0.9634 - val\_loss: 0.2293 - val\_acc: 0.9378
Epoch 51/59
4067/4067 [==============================] - 1s 183us/step - loss: 0.1425 - acc: 0.9599 - val\_loss: 0.2763 - val\_acc: 0.9090
Epoch 52/59
4067/4067 [==============================] - 1s 183us/step - loss: 0.1390 - acc: 0.9641 - val\_loss: 0.2954 - val\_acc: 0.9083
Epoch 53/59
4067/4067 [==============================] - 1s 184us/step - loss: 0.1492 - acc: 0.9636 - val\_loss: 0.2367 - val\_acc: 0.9199
Epoch 54/59
4067/4067 [==============================] - 1s 183us/step - loss: 0.1344 - acc: 0.9656 - val\_loss: 0.2476 - val\_acc: 0.9256
Epoch 55/59
4067/4067 [==============================] - 1s 183us/step - loss: 0.1410 - acc: 0.9648 - val\_loss: 0.3849 - val\_acc: 0.8846
Epoch 56/59
4067/4067 [==============================] - 1s 183us/step - loss: 0.1417 - acc: 0.9636 - val\_loss: 0.2411 - val\_acc: 0.9340
Epoch 57/59
4067/4067 [==============================] - 1s 183us/step - loss: 0.1436 - acc: 0.9624 - val\_loss: 0.3697 - val\_acc: 0.9147
Epoch 58/59
4067/4067 [==============================] - 1s 183us/step - loss: 0.1390 - acc: 0.9675 - val\_loss: 0.2298 - val\_acc: 0.9442
Epoch 59/59
4067/4067 [==============================] - 1s 183us/step - loss: 0.1400 - acc: 0.9658 - val\_loss: 0.2142 - val\_acc: 0.9545

    \end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}78}]:} \PY{n}{\PYZus{}}\PY{p}{,}\PY{n}{acc\PYZus{}val} \PY{o}{=} \PY{n}{best\PYZus{}model}\PY{o}{.}\PY{n}{evaluate}\PY{p}{(}\PY{n}{X\PYZus{}val\PYZus{}s}\PY{p}{,}\PY{n}{Y\PYZus{}val\PYZus{}s}\PY{p}{,}\PY{n}{verbose}\PY{o}{=}\PY{l+m+mi}{0}\PY{p}{)}
         \PY{n}{\PYZus{}}\PY{p}{,}\PY{n}{acc\PYZus{}train} \PY{o}{=} \PY{n}{best\PYZus{}model}\PY{o}{.}\PY{n}{evaluate}\PY{p}{(}\PY{n}{X\PYZus{}train\PYZus{}s}\PY{p}{,}\PY{n}{Y\PYZus{}train\PYZus{}s}\PY{p}{,}\PY{n}{verbose}\PY{o}{=}\PY{l+m+mi}{0}\PY{p}{)}
         \PY{n+nb}{print}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Train\PYZus{}accuracy}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}\PY{n}{acc\PYZus{}train}\PY{p}{,}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{test\PYZus{}accuracy}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}\PY{n}{acc\PYZus{}val}\PY{p}{)}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
Train\_accuracy 0.9741824440619621 test\_accuracy 0.9544871794871795

    \end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}81}]:} \PY{c+c1}{\PYZsh{} Confusion Matrix}
         \PY{c+c1}{\PYZsh{} Activities are the class labels}
         \PY{c+c1}{\PYZsh{} It is a 3 class classification}
         \PY{k+kn}{from} \PY{n+nn}{sklearn} \PY{k}{import} \PY{n}{metrics}
         \PY{n}{ACTIVITIES} \PY{o}{=} \PY{p}{\PYZob{}}
             \PY{l+m+mi}{0}\PY{p}{:} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{SITTING}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}
             \PY{l+m+mi}{1}\PY{p}{:} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{STANDING}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}
             \PY{l+m+mi}{2}\PY{p}{:} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{LAYING}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}
         \PY{p}{\PYZcb{}}
         
         \PY{c+c1}{\PYZsh{} Utility function to print the confusion matrix}
         \PY{k}{def} \PY{n+nf}{confusion\PYZus{}matrix\PYZus{}cnn}\PY{p}{(}\PY{n}{Y\PYZus{}true}\PY{p}{,} \PY{n}{Y\PYZus{}pred}\PY{p}{)}\PY{p}{:}
             \PY{n}{Y\PYZus{}true} \PY{o}{=} \PY{n}{pd}\PY{o}{.}\PY{n}{Series}\PY{p}{(}\PY{p}{[}\PY{n}{ACTIVITIES}\PY{p}{[}\PY{n}{y}\PY{p}{]} \PY{k}{for} \PY{n}{y} \PY{o+ow}{in} \PY{n}{np}\PY{o}{.}\PY{n}{argmax}\PY{p}{(}\PY{n}{Y\PYZus{}true}\PY{p}{,} \PY{n}{axis}\PY{o}{=}\PY{l+m+mi}{1}\PY{p}{)}\PY{p}{]}\PY{p}{)}
             \PY{n}{Y\PYZus{}pred} \PY{o}{=} \PY{n}{pd}\PY{o}{.}\PY{n}{Series}\PY{p}{(}\PY{p}{[}\PY{n}{ACTIVITIES}\PY{p}{[}\PY{n}{y}\PY{p}{]} \PY{k}{for} \PY{n}{y} \PY{o+ow}{in} \PY{n}{np}\PY{o}{.}\PY{n}{argmax}\PY{p}{(}\PY{n}{Y\PYZus{}pred}\PY{p}{,} \PY{n}{axis}\PY{o}{=}\PY{l+m+mi}{1}\PY{p}{)}\PY{p}{]}\PY{p}{)}
         
             \PY{c+c1}{\PYZsh{}return pd.crosstab(Y\PYZus{}true, Y\PYZus{}pred, rownames=[\PYZsq{}True\PYZsq{}], colnames=[\PYZsq{}Pred\PYZsq{}])}
             \PY{k}{return} \PY{n}{metrics}\PY{o}{.}\PY{n}{confusion\PYZus{}matrix}\PY{p}{(}\PY{n}{Y\PYZus{}true}\PY{p}{,} \PY{n}{Y\PYZus{}pred}\PY{p}{)}
         
         \PY{c+c1}{\PYZsh{} Confusion Matrix}
         \PY{n+nb}{print}\PY{p}{(}\PY{n}{confusion\PYZus{}matrix\PYZus{}cnn}\PY{p}{(}\PY{n}{Y\PYZus{}val\PYZus{}s}\PY{p}{,} \PY{n}{best\PYZus{}model}\PY{o}{.}\PY{n}{predict}\PY{p}{(}\PY{n}{X\PYZus{}val\PYZus{}s}\PY{p}{)}\PY{p}{)}\PY{p}{)}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
[[534   3   0]
 [  0 450  41]
 [  0  27 505]]

    \end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}83}]:} \PY{n}{plt}\PY{o}{.}\PY{n}{figure}\PY{p}{(}\PY{n}{figsize}\PY{o}{=}\PY{p}{(}\PY{l+m+mi}{8}\PY{p}{,}\PY{l+m+mi}{8}\PY{p}{)}\PY{p}{)}
         \PY{n}{cm} \PY{o}{=} \PY{n}{confusion\PYZus{}matrix\PYZus{}cnn}\PY{p}{(}\PY{n}{Y\PYZus{}val\PYZus{}s}\PY{p}{,} \PY{n}{best\PYZus{}model}\PY{o}{.}\PY{n}{predict}\PY{p}{(}\PY{n}{X\PYZus{}val\PYZus{}s}\PY{p}{)}\PY{p}{)}
         \PY{n}{plot\PYZus{}confusion\PYZus{}matrix}\PY{p}{(}\PY{n}{cm}\PY{p}{,} \PY{n}{classes}\PY{o}{=}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{SITTING}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{STANDING}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{LAYING}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{,} \PY{n}{normalize}\PY{o}{=}\PY{k+kc}{True}\PY{p}{,} \PY{n}{title}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Normalized confusion matrix}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{cmap} \PY{o}{=} \PY{n}{plt}\PY{o}{.}\PY{n}{cm}\PY{o}{.}\PY{n}{Greens}\PY{p}{)}
         \PY{n}{plt}\PY{o}{.}\PY{n}{show}\PY{p}{(}\PY{p}{)}
\end{Verbatim}


    
    \begin{verbatim}
<matplotlib.figure.Figure at 0x148471fbee10>
    \end{verbatim}

    
    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{output_206_1.png}
    \end{center}
    { \hspace*{\fill} \\}
    
    it was better than confusion metric with all data. We improved our model
for classiying static activities alot than previous approc models.

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}84}]:} \PY{c+c1}{\PYZsh{}\PYZsh{}saving model}
         \PY{n}{best\PYZus{}model}\PY{o}{.}\PY{n}{save}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{final\PYZus{}model\PYZus{}static.h5}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
\end{Verbatim}


    \subsubsection{Classification of Dynamic activities
:}\label{classification-of-dynamic-activities}

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}151}]:} \PY{c+c1}{\PYZsh{}\PYZsh{}data preparation}
          \PY{k}{def} \PY{n+nf}{data\PYZus{}scaled\PYZus{}dynamic}\PY{p}{(}\PY{p}{)}\PY{p}{:}
              \PY{l+s+sd}{\PYZdq{}\PYZdq{}\PYZdq{}}
          \PY{l+s+sd}{    Obtain the dataset from multiple files.}
          \PY{l+s+sd}{    Returns: X\PYZus{}train, X\PYZus{}test, y\PYZus{}train, y\PYZus{}test}
          \PY{l+s+sd}{    \PYZdq{}\PYZdq{}\PYZdq{}}
              \PY{c+c1}{\PYZsh{} Data directory}
              \PY{n}{DATADIR} \PY{o}{=} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{UCI\PYZus{}HAR\PYZus{}Dataset}\PY{l+s+s1}{\PYZsq{}}
              \PY{c+c1}{\PYZsh{} Raw data signals}
              \PY{c+c1}{\PYZsh{} Signals are from Accelerometer and Gyroscope}
              \PY{c+c1}{\PYZsh{} The signals are in x,y,z directions}
              \PY{c+c1}{\PYZsh{} Sensor signals are filtered to have only body acceleration}
              \PY{c+c1}{\PYZsh{} excluding the acceleration due to gravity}
              \PY{c+c1}{\PYZsh{} Triaxial acceleration from the accelerometer is total acceleration}
              \PY{n}{SIGNALS} \PY{o}{=} \PY{p}{[}
                  \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{body\PYZus{}acc\PYZus{}x}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,}
                  \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{body\PYZus{}acc\PYZus{}y}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,}
                  \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{body\PYZus{}acc\PYZus{}z}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,}
                  \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{body\PYZus{}gyro\PYZus{}x}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,}
                  \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{body\PYZus{}gyro\PYZus{}y}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,}
                  \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{body\PYZus{}gyro\PYZus{}z}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,}
                  \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{total\PYZus{}acc\PYZus{}x}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,}
                  \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{total\PYZus{}acc\PYZus{}y}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,}
                  \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{total\PYZus{}acc\PYZus{}z}\PY{l+s+s2}{\PYZdq{}}
                  \PY{p}{]}
              \PY{k+kn}{from} \PY{n+nn}{sklearn}\PY{n+nn}{.}\PY{n+nn}{base} \PY{k}{import} \PY{n}{BaseEstimator}\PY{p}{,} \PY{n}{TransformerMixin}
              \PY{k}{class} \PY{n+nc}{scaling\PYZus{}tseries\PYZus{}data}\PY{p}{(}\PY{n}{BaseEstimator}\PY{p}{,} \PY{n}{TransformerMixin}\PY{p}{)}\PY{p}{:}
                  \PY{k+kn}{from} \PY{n+nn}{sklearn}\PY{n+nn}{.}\PY{n+nn}{preprocessing} \PY{k}{import} \PY{n}{StandardScaler}
                  \PY{k}{def} \PY{n+nf}{\PYZus{}\PYZus{}init\PYZus{}\PYZus{}}\PY{p}{(}\PY{n+nb+bp}{self}\PY{p}{)}\PY{p}{:}
                      \PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{scale} \PY{o}{=} \PY{k+kc}{None}
          
                  \PY{k}{def} \PY{n+nf}{transform}\PY{p}{(}\PY{n+nb+bp}{self}\PY{p}{,} \PY{n}{X}\PY{p}{)}\PY{p}{:}
                      \PY{n}{temp\PYZus{}X1} \PY{o}{=} \PY{n}{X}\PY{o}{.}\PY{n}{reshape}\PY{p}{(}\PY{p}{(}\PY{n}{X}\PY{o}{.}\PY{n}{shape}\PY{p}{[}\PY{l+m+mi}{0}\PY{p}{]} \PY{o}{*} \PY{n}{X}\PY{o}{.}\PY{n}{shape}\PY{p}{[}\PY{l+m+mi}{1}\PY{p}{]}\PY{p}{,} \PY{n}{X}\PY{o}{.}\PY{n}{shape}\PY{p}{[}\PY{l+m+mi}{2}\PY{p}{]}\PY{p}{)}\PY{p}{)}
                      \PY{n}{temp\PYZus{}X1} \PY{o}{=} \PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{scale}\PY{o}{.}\PY{n}{transform}\PY{p}{(}\PY{n}{temp\PYZus{}X1}\PY{p}{)}
                      \PY{k}{return} \PY{n}{temp\PYZus{}X1}\PY{o}{.}\PY{n}{reshape}\PY{p}{(}\PY{n}{X}\PY{o}{.}\PY{n}{shape}\PY{p}{)}
          
                  \PY{k}{def} \PY{n+nf}{fit}\PY{p}{(}\PY{n+nb+bp}{self}\PY{p}{,} \PY{n}{X}\PY{p}{)}\PY{p}{:}
                      \PY{c+c1}{\PYZsh{} remove overlaping}
                      \PY{n}{remove} \PY{o}{=} \PY{n+nb}{int}\PY{p}{(}\PY{n}{X}\PY{o}{.}\PY{n}{shape}\PY{p}{[}\PY{l+m+mi}{1}\PY{p}{]} \PY{o}{/} \PY{l+m+mi}{2}\PY{p}{)}
                      \PY{n}{temp\PYZus{}X} \PY{o}{=} \PY{n}{X}\PY{p}{[}\PY{p}{:}\PY{p}{,} \PY{o}{\PYZhy{}}\PY{n}{remove}\PY{p}{:}\PY{p}{,} \PY{p}{:}\PY{p}{]}
                      \PY{c+c1}{\PYZsh{} flatten data}
                      \PY{n}{temp\PYZus{}X} \PY{o}{=} \PY{n}{temp\PYZus{}X}\PY{o}{.}\PY{n}{reshape}\PY{p}{(}\PY{p}{(}\PY{n}{temp\PYZus{}X}\PY{o}{.}\PY{n}{shape}\PY{p}{[}\PY{l+m+mi}{0}\PY{p}{]} \PY{o}{*} \PY{n}{temp\PYZus{}X}\PY{o}{.}\PY{n}{shape}\PY{p}{[}\PY{l+m+mi}{1}\PY{p}{]}\PY{p}{,} \PY{n}{temp\PYZus{}X}\PY{o}{.}\PY{n}{shape}\PY{p}{[}\PY{l+m+mi}{2}\PY{p}{]}\PY{p}{)}\PY{p}{)}
                      \PY{n}{scale} \PY{o}{=} \PY{n}{StandardScaler}\PY{p}{(}\PY{p}{)}
                      \PY{n}{scale}\PY{o}{.}\PY{n}{fit}\PY{p}{(}\PY{n}{temp\PYZus{}X}\PY{p}{)}
                      \PY{n}{pickle}\PY{o}{.}\PY{n}{dump}\PY{p}{(}\PY{n}{scale}\PY{p}{,}\PY{n+nb}{open}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Scale\PYZus{}dynamic.p}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{wb}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}\PY{p}{)}
                      \PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{scale} \PY{o}{=} \PY{n}{scale}
                      \PY{k}{return} \PY{n+nb+bp}{self}
                  
              \PY{c+c1}{\PYZsh{} Utility function to read the data from csv file}
              \PY{k}{def} \PY{n+nf}{\PYZus{}read\PYZus{}csv}\PY{p}{(}\PY{n}{filename}\PY{p}{)}\PY{p}{:}
                  \PY{k}{return} \PY{n}{pd}\PY{o}{.}\PY{n}{read\PYZus{}csv}\PY{p}{(}\PY{n}{filename}\PY{p}{,} \PY{n}{delim\PYZus{}whitespace}\PY{o}{=}\PY{k+kc}{True}\PY{p}{,} \PY{n}{header}\PY{o}{=}\PY{k+kc}{None}\PY{p}{)}
          
              \PY{c+c1}{\PYZsh{} Utility function to load the load}
              \PY{k}{def} \PY{n+nf}{load\PYZus{}signals}\PY{p}{(}\PY{n}{subset}\PY{p}{)}\PY{p}{:}
                  \PY{n}{signals\PYZus{}data} \PY{o}{=} \PY{p}{[}\PY{p}{]}
          
                  \PY{k}{for} \PY{n}{signal} \PY{o+ow}{in} \PY{n}{SIGNALS}\PY{p}{:}
                      \PY{n}{filename} \PY{o}{=} \PY{n}{f}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{UCI\PYZus{}HAR\PYZus{}Dataset/}\PY{l+s+si}{\PYZob{}subset\PYZcb{}}\PY{l+s+s1}{/Inertial Signals/}\PY{l+s+si}{\PYZob{}signal\PYZcb{}}\PY{l+s+s1}{\PYZus{}}\PY{l+s+si}{\PYZob{}subset\PYZcb{}}\PY{l+s+s1}{.txt}\PY{l+s+s1}{\PYZsq{}}
                      \PY{n}{signals\PYZus{}data}\PY{o}{.}\PY{n}{append}\PY{p}{(} \PY{n}{\PYZus{}read\PYZus{}csv}\PY{p}{(}\PY{n}{filename}\PY{p}{)}\PY{o}{.}\PY{n}{as\PYZus{}matrix}\PY{p}{(}\PY{p}{)}\PY{p}{)} 
          
                  \PY{c+c1}{\PYZsh{} Transpose is used to change the dimensionality of the output,}
                  \PY{c+c1}{\PYZsh{} aggregating the signals by combination of sample/timestep.}
                  \PY{c+c1}{\PYZsh{} Resultant shape is (7352 train/2947 test samples, 128 timesteps, 9 signals)}
                  \PY{k}{return} \PY{n}{np}\PY{o}{.}\PY{n}{transpose}\PY{p}{(}\PY{n}{signals\PYZus{}data}\PY{p}{,} \PY{p}{(}\PY{l+m+mi}{1}\PY{p}{,} \PY{l+m+mi}{2}\PY{p}{,} \PY{l+m+mi}{0}\PY{p}{)}\PY{p}{)}
              
              \PY{k}{def} \PY{n+nf}{load\PYZus{}y}\PY{p}{(}\PY{n}{subset}\PY{p}{)}\PY{p}{:}
                  \PY{l+s+sd}{\PYZdq{}\PYZdq{}\PYZdq{}}
          \PY{l+s+sd}{        The objective that we are trying to predict is a integer, from 1 to 6,}
          \PY{l+s+sd}{        that represents a human activity. We return a binary representation of }
          \PY{l+s+sd}{        every sample objective as a 6 bits vector using One Hot Encoding}
          \PY{l+s+sd}{        (https://pandas.pydata.org/pandas\PYZhy{}docs/stable/generated/pandas.get\PYZus{}dummies.html)}
          \PY{l+s+sd}{        \PYZdq{}\PYZdq{}\PYZdq{}}
                  \PY{n}{filename} \PY{o}{=} \PY{n}{f}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{UCI\PYZus{}HAR\PYZus{}Dataset/}\PY{l+s+si}{\PYZob{}subset\PYZcb{}}\PY{l+s+s1}{/y\PYZus{}}\PY{l+s+si}{\PYZob{}subset\PYZcb{}}\PY{l+s+s1}{.txt}\PY{l+s+s1}{\PYZsq{}}
                  \PY{n}{y} \PY{o}{=} \PY{n}{\PYZus{}read\PYZus{}csv}\PY{p}{(}\PY{n}{filename}\PY{p}{)}\PY{p}{[}\PY{l+m+mi}{0}\PY{p}{]}
                  \PY{n}{y\PYZus{}subset} \PY{o}{=} \PY{n}{y}\PY{o}{\PYZlt{}}\PY{o}{=}\PY{l+m+mi}{3}
                  \PY{n}{y} \PY{o}{=} \PY{n}{y}\PY{p}{[}\PY{n}{y\PYZus{}subset}\PY{p}{]}
                  \PY{k}{return} \PY{n}{pd}\PY{o}{.}\PY{n}{get\PYZus{}dummies}\PY{p}{(}\PY{n}{y}\PY{p}{)}\PY{o}{.}\PY{n}{as\PYZus{}matrix}\PY{p}{(}\PY{p}{)}\PY{p}{,}\PY{n}{y\PYZus{}subset}
              
              \PY{n}{Y\PYZus{}train\PYZus{}d}\PY{p}{,}\PY{n}{y\PYZus{}train\PYZus{}sub} \PY{o}{=} \PY{n}{load\PYZus{}y}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{train}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
              \PY{n}{Y\PYZus{}val\PYZus{}d}\PY{p}{,}\PY{n}{y\PYZus{}test\PYZus{}sub} \PY{o}{=} \PY{n}{load\PYZus{}y}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{test}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
              \PY{n}{X\PYZus{}train\PYZus{}d}\PY{p}{,} \PY{n}{X\PYZus{}val\PYZus{}d} \PY{o}{=} \PY{n}{load\PYZus{}signals}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{train}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}\PY{p}{,} \PY{n}{load\PYZus{}signals}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{test}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
              \PY{n}{X\PYZus{}train\PYZus{}d} \PY{o}{=} \PY{n}{X\PYZus{}train\PYZus{}d}\PY{p}{[}\PY{n}{y\PYZus{}train\PYZus{}sub}\PY{p}{]}
              \PY{n}{X\PYZus{}val\PYZus{}d} \PY{o}{=} \PY{n}{X\PYZus{}val\PYZus{}d}\PY{p}{[}\PY{n}{y\PYZus{}test\PYZus{}sub}\PY{p}{]}
              
              \PY{c+c1}{\PYZsh{}\PYZsh{}\PYZsh{}Scling data}
              \PY{n}{Scale} \PY{o}{=} \PY{n}{scaling\PYZus{}tseries\PYZus{}data}\PY{p}{(}\PY{p}{)}
              \PY{n}{Scale}\PY{o}{.}\PY{n}{fit}\PY{p}{(}\PY{n}{X\PYZus{}train\PYZus{}d}\PY{p}{)}
              \PY{n}{X\PYZus{}train\PYZus{}d} \PY{o}{=} \PY{n}{Scale}\PY{o}{.}\PY{n}{transform}\PY{p}{(}\PY{n}{X\PYZus{}train\PYZus{}d}\PY{p}{)}
              \PY{n}{X\PYZus{}val\PYZus{}d} \PY{o}{=} \PY{n}{Scale}\PY{o}{.}\PY{n}{transform}\PY{p}{(}\PY{n}{X\PYZus{}val\PYZus{}d}\PY{p}{)}
          
              \PY{k}{return} \PY{n}{X\PYZus{}train\PYZus{}d}\PY{p}{,} \PY{n}{Y\PYZus{}train\PYZus{}d}\PY{p}{,} \PY{n}{X\PYZus{}val\PYZus{}d}\PY{p}{,}  \PY{n}{Y\PYZus{}val\PYZus{}d}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}152}]:} \PY{n}{X\PYZus{}train\PYZus{}d}\PY{p}{,} \PY{n}{Y\PYZus{}train\PYZus{}d}\PY{p}{,} \PY{n}{X\PYZus{}val\PYZus{}d}\PY{p}{,}  \PY{n}{Y\PYZus{}val\PYZus{}d} \PY{o}{=} \PY{n}{data\PYZus{}scaled\PYZus{}dynamic}\PY{p}{(}\PY{p}{)}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}153}]:} \PY{n+nb}{print}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Train X shape}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}\PY{n}{X\PYZus{}train\PYZus{}d}\PY{o}{.}\PY{n}{shape}\PY{p}{,}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Test X shape}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}\PY{n}{X\PYZus{}val\PYZus{}d}\PY{o}{.}\PY{n}{shape}\PY{p}{)}
          \PY{n+nb}{print}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Train Y shape}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}\PY{n}{Y\PYZus{}train\PYZus{}d}\PY{o}{.}\PY{n}{shape}\PY{p}{,}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Test Y shape}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}\PY{n}{Y\PYZus{}val\PYZus{}d}\PY{o}{.}\PY{n}{shape}\PY{p}{)}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
Train X shape (3285, 128, 9) Test X shape (1387, 128, 9)
Train Y shape (3285, 3) Test Y shape (1387, 3)

    \end{Verbatim}

    \paragraph{Baseline Model}\label{baseline-model}

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}96}]:} \PY{n}{np}\PY{o}{.}\PY{n}{random}\PY{o}{.}\PY{n}{seed}\PY{p}{(}\PY{l+m+mi}{0}\PY{p}{)}
         \PY{n}{tf}\PY{o}{.}\PY{n}{set\PYZus{}random\PYZus{}seed}\PY{p}{(}\PY{l+m+mi}{0}\PY{p}{)}
         \PY{n}{sess} \PY{o}{=} \PY{n}{tf}\PY{o}{.}\PY{n}{Session}\PY{p}{(}\PY{n}{graph}\PY{o}{=}\PY{n}{tf}\PY{o}{.}\PY{n}{get\PYZus{}default\PYZus{}graph}\PY{p}{(}\PY{p}{)}\PY{p}{)}
         \PY{n}{K}\PY{o}{.}\PY{n}{set\PYZus{}session}\PY{p}{(}\PY{n}{sess}\PY{p}{)}
         \PY{n}{model} \PY{o}{=} \PY{n}{Sequential}\PY{p}{(}\PY{p}{)}
         \PY{n}{model}\PY{o}{.}\PY{n}{add}\PY{p}{(}\PY{n}{Conv1D}\PY{p}{(}\PY{n}{filters}\PY{o}{=}\PY{l+m+mi}{64}\PY{p}{,} \PY{n}{kernel\PYZus{}size}\PY{o}{=}\PY{l+m+mi}{7}\PY{p}{,} \PY{n}{activation}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{relu}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}\PY{n}{kernel\PYZus{}initializer}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{he\PYZus{}uniform}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}\PY{n}{input\PYZus{}shape}\PY{o}{=}\PY{p}{(}\PY{l+m+mi}{128}\PY{p}{,}\PY{l+m+mi}{9}\PY{p}{)}\PY{p}{)}\PY{p}{)}
         \PY{n}{model}\PY{o}{.}\PY{n}{add}\PY{p}{(}\PY{n}{Conv1D}\PY{p}{(}\PY{n}{filters}\PY{o}{=}\PY{l+m+mi}{32}\PY{p}{,} \PY{n}{kernel\PYZus{}size}\PY{o}{=}\PY{l+m+mi}{3}\PY{p}{,} \PY{n}{activation}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{relu}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}\PY{n}{kernel\PYZus{}initializer}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{he\PYZus{}uniform}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}\PY{p}{)}
         \PY{n}{model}\PY{o}{.}\PY{n}{add}\PY{p}{(}\PY{n}{Dropout}\PY{p}{(}\PY{l+m+mf}{0.6}\PY{p}{)}\PY{p}{)}
         \PY{n}{model}\PY{o}{.}\PY{n}{add}\PY{p}{(}\PY{n}{MaxPooling1D}\PY{p}{(}\PY{n}{pool\PYZus{}size}\PY{o}{=}\PY{l+m+mi}{3}\PY{p}{)}\PY{p}{)}
         \PY{n}{model}\PY{o}{.}\PY{n}{add}\PY{p}{(}\PY{n}{Flatten}\PY{p}{(}\PY{p}{)}\PY{p}{)}
         \PY{n}{model}\PY{o}{.}\PY{n}{add}\PY{p}{(}\PY{n}{Dense}\PY{p}{(}\PY{l+m+mi}{30}\PY{p}{,} \PY{n}{activation}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{relu}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}\PY{p}{)}
         \PY{n}{model}\PY{o}{.}\PY{n}{add}\PY{p}{(}\PY{n}{Dense}\PY{p}{(}\PY{l+m+mi}{3}\PY{p}{,} \PY{n}{activation}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{softmax}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}\PY{p}{)}
         \PY{n}{model}\PY{o}{.}\PY{n}{summary}\PY{p}{(}\PY{p}{)}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_
Layer (type)                 Output Shape              Param \#   
=================================================================
conv1d\_1 (Conv1D)            (None, 122, 64)           4096      
\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_
conv1d\_2 (Conv1D)            (None, 120, 32)           6176      
\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_
dropout\_1 (Dropout)          (None, 120, 32)           0         
\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_
max\_pooling1d\_1 (MaxPooling1 (None, 40, 32)            0         
\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_
flatten\_1 (Flatten)          (None, 1280)              0         
\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_
dense\_1 (Dense)              (None, 30)                38430     
\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_
dense\_2 (Dense)              (None, 3)                 93        
=================================================================
Total params: 48,795
Trainable params: 48,795
Non-trainable params: 0
\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_

    \end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}97}]:} \PY{k+kn}{import} \PY{n+nn}{math}
         \PY{n}{adam} \PY{o}{=} \PY{n}{keras}\PY{o}{.}\PY{n}{optimizers}\PY{o}{.}\PY{n}{Adam}\PY{p}{(}\PY{n}{lr}\PY{o}{=}\PY{l+m+mf}{0.004}\PY{p}{)}
         \PY{n}{model}\PY{o}{.}\PY{n}{compile}\PY{p}{(}\PY{n}{loss}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{categorical\PYZus{}crossentropy}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{optimizer}\PY{o}{=}\PY{n}{adam}\PY{p}{,} \PY{n}{metrics}\PY{o}{=}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{accuracy}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{)}
         \PY{n}{model}\PY{o}{.}\PY{n}{fit}\PY{p}{(}\PY{n}{X\PYZus{}train\PYZus{}s}\PY{p}{,}\PY{n}{Y\PYZus{}train\PYZus{}s}\PY{p}{,} \PY{n}{epochs}\PY{o}{=}\PY{l+m+mi}{100}\PY{p}{,} \PY{n}{batch\PYZus{}size}\PY{o}{=}\PY{l+m+mi}{16}\PY{p}{,}\PY{n}{validation\PYZus{}data}\PY{o}{=}\PY{p}{(}\PY{n}{X\PYZus{}val\PYZus{}s}\PY{p}{,} \PY{n}{Y\PYZus{}val\PYZus{}s}\PY{p}{)}\PY{p}{,} \PY{n}{verbose}\PY{o}{=}\PY{l+m+mi}{1}\PY{p}{)}
         \PY{n}{K}\PY{o}{.}\PY{n}{clear\PYZus{}session}\PY{p}{(}\PY{p}{)}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
Train on 4067 samples, validate on 1560 samples
Epoch 1/100
4067/4067 [==============================] - 3s 646us/step - loss: 0.3741 - acc: 0.8835 - val\_loss: 0.2909 - val\_acc: 0.8885
Epoch 2/100
4067/4067 [==============================] - 2s 469us/step - loss: 0.2112 - acc: 0.9179 - val\_loss: 0.3365 - val\_acc: 0.8718
Epoch 3/100
4067/4067 [==============================] - 2s 469us/step - loss: 0.2055 - acc: 0.9179 - val\_loss: 0.2613 - val\_acc: 0.8981
Epoch 4/100
4067/4067 [==============================] - 2s 471us/step - loss: 0.1922 - acc: 0.9240 - val\_loss: 0.2663 - val\_acc: 0.8814
Epoch 5/100
4067/4067 [==============================] - 2s 469us/step - loss: 0.2058 - acc: 0.9292 - val\_loss: 0.1815 - val\_acc: 0.9224
Epoch 6/100
4067/4067 [==============================] - 2s 469us/step - loss: 0.1774 - acc: 0.9336 - val\_loss: 0.2734 - val\_acc: 0.8814
Epoch 7/100
4067/4067 [==============================] - 2s 469us/step - loss: 0.1617 - acc: 0.9405 - val\_loss: 0.2008 - val\_acc: 0.9038
Epoch 8/100
4067/4067 [==============================] - 2s 469us/step - loss: 0.1881 - acc: 0.9363 - val\_loss: 0.2781 - val\_acc: 0.8763
Epoch 9/100
4067/4067 [==============================] - 2s 468us/step - loss: 0.2020 - acc: 0.9385 - val\_loss: 0.2372 - val\_acc: 0.8917
Epoch 10/100
4067/4067 [==============================] - 2s 469us/step - loss: 0.1497 - acc: 0.9476 - val\_loss: 0.1934 - val\_acc: 0.9186
Epoch 11/100
4067/4067 [==============================] - 2s 469us/step - loss: 0.2372 - acc: 0.9294 - val\_loss: 0.2185 - val\_acc: 0.9051
Epoch 12/100
4067/4067 [==============================] - 2s 469us/step - loss: 0.2053 - acc: 0.9348 - val\_loss: 0.1926 - val\_acc: 0.9071
Epoch 13/100
4067/4067 [==============================] - 2s 469us/step - loss: 0.2254 - acc: 0.9223 - val\_loss: 0.2202 - val\_acc: 0.8878
Epoch 14/100
4067/4067 [==============================] - 2s 482us/step - loss: 0.1488 - acc: 0.9410 - val\_loss: 0.1968 - val\_acc: 0.9019
Epoch 15/100
4067/4067 [==============================] - 2s 473us/step - loss: 0.1156 - acc: 0.9548 - val\_loss: 0.2031 - val\_acc: 0.9327
Epoch 16/100
4067/4067 [==============================] - 2s 474us/step - loss: 0.1348 - acc: 0.9523 - val\_loss: 0.2138 - val\_acc: 0.9231
Epoch 17/100
4067/4067 [==============================] - 2s 469us/step - loss: 0.2656 - acc: 0.9393 - val\_loss: 0.1896 - val\_acc: 0.9346
Epoch 18/100
4067/4067 [==============================] - 2s 468us/step - loss: 0.4346 - acc: 0.9171 - val\_loss: 0.4111 - val\_acc: 0.9192
Epoch 19/100
4067/4067 [==============================] - 2s 467us/step - loss: 0.2026 - acc: 0.9385 - val\_loss: 0.2235 - val\_acc: 0.9218
Epoch 20/100
4067/4067 [==============================] - 2s 468us/step - loss: 0.1679 - acc: 0.9511 - val\_loss: 0.2388 - val\_acc: 0.9173
Epoch 21/100
4067/4067 [==============================] - 2s 470us/step - loss: 0.1626 - acc: 0.9525 - val\_loss: 0.2714 - val\_acc: 0.9231
Epoch 22/100
4067/4067 [==============================] - 2s 469us/step - loss: 0.1852 - acc: 0.9452 - val\_loss: 0.5511 - val\_acc: 0.8962
Epoch 23/100
4067/4067 [==============================] - 2s 468us/step - loss: 0.2965 - acc: 0.9233 - val\_loss: 0.5497 - val\_acc: 0.8769
Epoch 24/100
4067/4067 [==============================] - 2s 475us/step - loss: 0.2631 - acc: 0.9358 - val\_loss: 0.4660 - val\_acc: 0.9173
Epoch 25/100
4067/4067 [==============================] - 2s 469us/step - loss: 0.2342 - acc: 0.9432 - val\_loss: 0.3215 - val\_acc: 0.9353
Epoch 26/100
4067/4067 [==============================] - 2s 469us/step - loss: 0.3714 - acc: 0.9257 - val\_loss: 0.4106 - val\_acc: 0.9192
Epoch 27/100
4067/4067 [==============================] - 2s 468us/step - loss: 0.3692 - acc: 0.9312 - val\_loss: 0.3672 - val\_acc: 0.8942
Epoch 28/100
4067/4067 [==============================] - 2s 469us/step - loss: 0.3338 - acc: 0.9380 - val\_loss: 0.2591 - val\_acc: 0.9237
Epoch 29/100
4067/4067 [==============================] - 2s 469us/step - loss: 0.3166 - acc: 0.9462 - val\_loss: 0.2539 - val\_acc: 0.9237
Epoch 30/100
4067/4067 [==============================] - 2s 470us/step - loss: 0.3306 - acc: 0.9437 - val\_loss: 0.2518 - val\_acc: 0.9115
Epoch 31/100
4067/4067 [==============================] - 2s 470us/step - loss: 0.3000 - acc: 0.9466 - val\_loss: 0.2865 - val\_acc: 0.9077
Epoch 32/100
4067/4067 [==============================] - 2s 469us/step - loss: 0.2992 - acc: 0.9459 - val\_loss: 0.2693 - val\_acc: 0.9154
Epoch 33/100
4067/4067 [==============================] - 2s 476us/step - loss: 0.3235 - acc: 0.9430 - val\_loss: 0.2308 - val\_acc: 0.9301
Epoch 34/100
4067/4067 [==============================] - 2s 469us/step - loss: 0.2924 - acc: 0.9516 - val\_loss: 0.3129 - val\_acc: 0.9321
Epoch 35/100
4067/4067 [==============================] - 2s 468us/step - loss: 0.2561 - acc: 0.9439 - val\_loss: 0.3511 - val\_acc: 0.9122
Epoch 36/100
4067/4067 [==============================] - 2s 469us/step - loss: 0.1771 - acc: 0.9587 - val\_loss: 0.2372 - val\_acc: 0.9199
Epoch 37/100
4067/4067 [==============================] - 2s 469us/step - loss: 0.1556 - acc: 0.9653 - val\_loss: 0.2733 - val\_acc: 0.9365
Epoch 38/100
4067/4067 [==============================] - 2s 469us/step - loss: 0.1674 - acc: 0.9643 - val\_loss: 0.3179 - val\_acc: 0.9308
Epoch 39/100
4067/4067 [==============================] - 2s 469us/step - loss: 0.1850 - acc: 0.9619 - val\_loss: 0.3449 - val\_acc: 0.9205
Epoch 40/100
4067/4067 [==============================] - 2s 469us/step - loss: 0.2294 - acc: 0.9565 - val\_loss: 1.1749 - val\_acc: 0.8558
Epoch 41/100
4067/4067 [==============================] - 2s 469us/step - loss: 0.8426 - acc: 0.8618 - val\_loss: 0.6446 - val\_acc: 0.9096
Epoch 42/100
4067/4067 [==============================] - 2s 470us/step - loss: 0.3695 - acc: 0.9095 - val\_loss: 0.5939 - val\_acc: 0.8949
Epoch 43/100
4067/4067 [==============================] - 2s 469us/step - loss: 0.2976 - acc: 0.8957 - val\_loss: 0.3787 - val\_acc: 0.8878
Epoch 44/100
4067/4067 [==============================] - 2s 469us/step - loss: 0.3169 - acc: 0.8842 - val\_loss: 0.5096 - val\_acc: 0.8756
Epoch 45/100
4067/4067 [==============================] - 2s 481us/step - loss: 0.2832 - acc: 0.9299 - val\_loss: 0.5141 - val\_acc: 0.9231
Epoch 46/100
4067/4067 [==============================] - 2s 473us/step - loss: 0.2590 - acc: 0.9253 - val\_loss: 0.3977 - val\_acc: 0.9224
Epoch 47/100
4067/4067 [==============================] - 2s 470us/step - loss: 0.2411 - acc: 0.9058 - val\_loss: 0.3055 - val\_acc: 0.8942
Epoch 48/100
4067/4067 [==============================] - 2s 469us/step - loss: 0.2444 - acc: 0.9339 - val\_loss: 0.3800 - val\_acc: 0.9224
Epoch 49/100
4067/4067 [==============================] - 2s 471us/step - loss: 0.2571 - acc: 0.9398 - val\_loss: 0.3745 - val\_acc: 0.9308
Epoch 50/100
4067/4067 [==============================] - 2s 470us/step - loss: 0.2081 - acc: 0.9329 - val\_loss: 0.3633 - val\_acc: 0.9199
Epoch 51/100
4067/4067 [==============================] - 2s 470us/step - loss: 0.1975 - acc: 0.9459 - val\_loss: 0.4758 - val\_acc: 0.9365
Epoch 52/100
4067/4067 [==============================] - 2s 468us/step - loss: 0.1934 - acc: 0.9506 - val\_loss: 0.3417 - val\_acc: 0.9237
Epoch 53/100
4067/4067 [==============================] - 2s 469us/step - loss: 0.1805 - acc: 0.9560 - val\_loss: 0.4377 - val\_acc: 0.9353
Epoch 54/100
4067/4067 [==============================] - 2s 469us/step - loss: 0.1955 - acc: 0.9422 - val\_loss: 0.3526 - val\_acc: 0.9378
Epoch 55/100
4067/4067 [==============================] - 2s 470us/step - loss: 0.2695 - acc: 0.9420 - val\_loss: 0.4296 - val\_acc: 0.9263
Epoch 56/100
4067/4067 [==============================] - 2s 472us/step - loss: 0.2427 - acc: 0.9545 - val\_loss: 0.5022 - val\_acc: 0.9295
Epoch 57/100
4067/4067 [==============================] - 2s 472us/step - loss: 0.2529 - acc: 0.9486 - val\_loss: 0.3581 - val\_acc: 0.9244
Epoch 58/100
4067/4067 [==============================] - 2s 472us/step - loss: 0.2147 - acc: 0.9469 - val\_loss: 0.3759 - val\_acc: 0.9212
Epoch 59/100
4067/4067 [==============================] - 2s 469us/step - loss: 0.2057 - acc: 0.9599 - val\_loss: 0.3434 - val\_acc: 0.9429
Epoch 60/100
4067/4067 [==============================] - 2s 469us/step - loss: 1.0452 - acc: 0.8975 - val\_loss: 6.0890 - val\_acc: 0.5833
Epoch 61/100
4067/4067 [==============================] - 2s 470us/step - loss: 5.7147 - acc: 0.6027 - val\_loss: 5.9525 - val\_acc: 0.6026
Epoch 62/100
4067/4067 [==============================] - 2s 469us/step - loss: 5.6650 - acc: 0.6078 - val\_loss: 5.7521 - val\_acc: 0.6077
Epoch 63/100
4067/4067 [==============================] - 2s 469us/step - loss: 5.6250 - acc: 0.6164 - val\_loss: 5.7895 - val\_acc: 0.6090
Epoch 64/100
4067/4067 [==============================] - 2s 468us/step - loss: 5.5582 - acc: 0.6191 - val\_loss: 5.7602 - val\_acc: 0.6013
Epoch 65/100
4067/4067 [==============================] - 2s 469us/step - loss: 5.2745 - acc: 0.6410 - val\_loss: 0.4785 - val\_acc: 0.9340
Epoch 66/100
4067/4067 [==============================] - 2s 472us/step - loss: 0.2632 - acc: 0.9388 - val\_loss: 0.5110 - val\_acc: 0.9372
Epoch 67/100
4067/4067 [==============================] - 2s 469us/step - loss: 0.2281 - acc: 0.9550 - val\_loss: 0.4420 - val\_acc: 0.9404
Epoch 68/100
4067/4067 [==============================] - 2s 470us/step - loss: 0.4060 - acc: 0.9353 - val\_loss: 0.4028 - val\_acc: 0.9064
Epoch 69/100
4067/4067 [==============================] - 2s 470us/step - loss: 0.4286 - acc: 0.9071 - val\_loss: 0.5253 - val\_acc: 0.9013
Epoch 70/100
4067/4067 [==============================] - 2s 469us/step - loss: 0.3854 - acc: 0.9142 - val\_loss: 0.5623 - val\_acc: 0.9006
Epoch 71/100
4067/4067 [==============================] - 2s 470us/step - loss: 0.3436 - acc: 0.9415 - val\_loss: 0.4089 - val\_acc: 0.9224
Epoch 72/100
4067/4067 [==============================] - 2s 469us/step - loss: 0.2453 - acc: 0.9491 - val\_loss: 0.3462 - val\_acc: 0.9237
Epoch 73/100
4067/4067 [==============================] - 2s 470us/step - loss: 0.1925 - acc: 0.9501 - val\_loss: 0.3247 - val\_acc: 0.9128
Epoch 74/100
4067/4067 [==============================] - 2s 470us/step - loss: 0.1871 - acc: 0.9567 - val\_loss: 0.4141 - val\_acc: 0.9353
Epoch 75/100
4067/4067 [==============================] - 2s 470us/step - loss: 0.2512 - acc: 0.9444 - val\_loss: 0.3955 - val\_acc: 0.9212
Epoch 76/100
4067/4067 [==============================] - 2s 468us/step - loss: 0.2315 - acc: 0.9481 - val\_loss: 0.5539 - val\_acc: 0.9103
Epoch 77/100
4067/4067 [==============================] - 2s 483us/step - loss: 0.2328 - acc: 0.9594 - val\_loss: 0.4957 - val\_acc: 0.9269
Epoch 78/100
4067/4067 [==============================] - 2s 471us/step - loss: 0.2192 - acc: 0.9619 - val\_loss: 0.5239 - val\_acc: 0.9250
Epoch 79/100
4067/4067 [==============================] - 2s 470us/step - loss: 0.2219 - acc: 0.9584 - val\_loss: 0.4986 - val\_acc: 0.9372
Epoch 80/100
4067/4067 [==============================] - 2s 471us/step - loss: 0.2892 - acc: 0.9324 - val\_loss: 0.4853 - val\_acc: 0.8904
Epoch 81/100
4067/4067 [==============================] - 2s 468us/step - loss: 0.2685 - acc: 0.9223 - val\_loss: 0.6160 - val\_acc: 0.9167
Epoch 82/100
4067/4067 [==============================] - 2s 470us/step - loss: 0.2445 - acc: 0.9385 - val\_loss: 0.4613 - val\_acc: 0.9051
Epoch 83/100
4067/4067 [==============================] - 2s 468us/step - loss: 0.2005 - acc: 0.9459 - val\_loss: 0.4366 - val\_acc: 0.9006
Epoch 84/100
4067/4067 [==============================] - 2s 469us/step - loss: 0.2433 - acc: 0.9417 - val\_loss: 0.5138 - val\_acc: 0.9141
Epoch 85/100
4067/4067 [==============================] - 2s 468us/step - loss: 0.2071 - acc: 0.9275 - val\_loss: 0.4254 - val\_acc: 0.8929
Epoch 86/100
4067/4067 [==============================] - 2s 469us/step - loss: 0.1931 - acc: 0.9511 - val\_loss: 0.4990 - val\_acc: 0.9205
Epoch 87/100
4067/4067 [==============================] - 2s 471us/step - loss: 0.1786 - acc: 0.9629 - val\_loss: 0.4127 - val\_acc: 0.9160
Epoch 88/100
4067/4067 [==============================] - 2s 469us/step - loss: 0.1616 - acc: 0.9648 - val\_loss: 0.4734 - val\_acc: 0.9205
Epoch 89/100
4067/4067 [==============================] - 2s 468us/step - loss: 0.1567 - acc: 0.9592 - val\_loss: 0.4669 - val\_acc: 0.9256
Epoch 90/100
4067/4067 [==============================] - 2s 469us/step - loss: 0.1951 - acc: 0.9636 - val\_loss: 0.4250 - val\_acc: 0.9192
Epoch 91/100
4067/4067 [==============================] - 2s 468us/step - loss: 0.1813 - acc: 0.9646 - val\_loss: 0.3796 - val\_acc: 0.9423
Epoch 92/100
4067/4067 [==============================] - 2s 468us/step - loss: 0.1771 - acc: 0.9629 - val\_loss: 0.3891 - val\_acc: 0.9353
Epoch 93/100
4067/4067 [==============================] - 2s 468us/step - loss: 0.3397 - acc: 0.9570 - val\_loss: 4.7079 - val\_acc: 0.6622
Epoch 94/100
4067/4067 [==============================] - 2s 468us/step - loss: 3.7788 - acc: 0.7037 - val\_loss: 4.1848 - val\_acc: 0.6423
Epoch 95/100
4067/4067 [==============================] - 2s 468us/step - loss: 4.0658 - acc: 0.6922 - val\_loss: 4.7790 - val\_acc: 0.6321
Epoch 96/100
4067/4067 [==============================] - 2s 475us/step - loss: 3.0969 - acc: 0.7335 - val\_loss: 0.5272 - val\_acc: 0.9032
Epoch 97/100
4067/4067 [==============================] - 2s 467us/step - loss: 0.4589 - acc: 0.9171 - val\_loss: 0.4549 - val\_acc: 0.8974
Epoch 98/100
4067/4067 [==============================] - 2s 470us/step - loss: 0.3379 - acc: 0.9169 - val\_loss: 0.4321 - val\_acc: 0.9218
Epoch 99/100
4067/4067 [==============================] - 2s 468us/step - loss: 0.3399 - acc: 0.9184 - val\_loss: 0.4533 - val\_acc: 0.9192
Epoch 100/100
4067/4067 [==============================] - 2s 469us/step - loss: 0.2668 - acc: 0.9341 - val\_loss: 0.4545 - val\_acc: 0.9173

    \end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}7}]:} \PY{k}{def} \PY{n+nf}{model\PYZus{}cnn}\PY{p}{(}\PY{n}{X\PYZus{}train\PYZus{}d}\PY{p}{,} \PY{n}{Y\PYZus{}train\PYZus{}d}\PY{p}{,} \PY{n}{X\PYZus{}val\PYZus{}d}\PY{p}{,} \PY{n}{Y\PYZus{}val\PYZus{}d}\PY{p}{)}\PY{p}{:}
            \PY{n}{np}\PY{o}{.}\PY{n}{random}\PY{o}{.}\PY{n}{seed}\PY{p}{(}\PY{l+m+mi}{0}\PY{p}{)}
            \PY{n}{tf}\PY{o}{.}\PY{n}{set\PYZus{}random\PYZus{}seed}\PY{p}{(}\PY{l+m+mi}{0}\PY{p}{)}
            \PY{n}{sess} \PY{o}{=} \PY{n}{tf}\PY{o}{.}\PY{n}{Session}\PY{p}{(}\PY{n}{graph}\PY{o}{=}\PY{n}{tf}\PY{o}{.}\PY{n}{get\PYZus{}default\PYZus{}graph}\PY{p}{(}\PY{p}{)}\PY{p}{)}
            \PY{n}{K}\PY{o}{.}\PY{n}{set\PYZus{}session}\PY{p}{(}\PY{n}{sess}\PY{p}{)}
            \PY{c+c1}{\PYZsh{} Initiliazing the sequential model}
            \PY{n}{model} \PY{o}{=} \PY{n}{Sequential}\PY{p}{(}\PY{p}{)}
            
            \PY{n}{model}\PY{o}{.}\PY{n}{add}\PY{p}{(}\PY{n}{Conv1D}\PY{p}{(}\PY{n}{filters}\PY{o}{=}\PY{p}{\PYZob{}}\PY{p}{\PYZob{}}\PY{n}{choice}\PY{p}{(}\PY{p}{[}\PY{l+m+mi}{28}\PY{p}{,}\PY{l+m+mi}{32}\PY{p}{,}\PY{l+m+mi}{42}\PY{p}{]}\PY{p}{)}\PY{p}{\PYZcb{}}\PY{p}{\PYZcb{}}\PY{p}{,} \PY{n}{kernel\PYZus{}size}\PY{o}{=}\PY{p}{\PYZob{}}\PY{p}{\PYZob{}}\PY{n}{choice}\PY{p}{(}\PY{p}{[}\PY{l+m+mi}{3}\PY{p}{,}\PY{l+m+mi}{5}\PY{p}{,}\PY{l+m+mi}{7}\PY{p}{]}\PY{p}{)}\PY{p}{\PYZcb{}}\PY{p}{\PYZcb{}}\PY{p}{,}\PY{n}{activation}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{relu}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}\PY{n}{kernel\PYZus{}initializer}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{he\PYZus{}uniform}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}
                         \PY{n}{kernel\PYZus{}regularizer}\PY{o}{=}\PY{n}{l2}\PY{p}{(}\PY{p}{\PYZob{}}\PY{p}{\PYZob{}}\PY{n}{uniform}\PY{p}{(}\PY{l+m+mi}{0}\PY{p}{,}\PY{l+m+mi}{3}\PY{p}{)}\PY{p}{\PYZcb{}}\PY{p}{\PYZcb{}}\PY{p}{)}\PY{p}{,}\PY{n}{input\PYZus{}shape}\PY{o}{=}\PY{p}{(}\PY{l+m+mi}{128}\PY{p}{,}\PY{l+m+mi}{9}\PY{p}{)}\PY{p}{)}\PY{p}{)}
            
            \PY{n}{model}\PY{o}{.}\PY{n}{add}\PY{p}{(}\PY{n}{Conv1D}\PY{p}{(}\PY{n}{filters}\PY{o}{=}\PY{p}{\PYZob{}}\PY{p}{\PYZob{}}\PY{n}{choice}\PY{p}{(}\PY{p}{[}\PY{l+m+mi}{16}\PY{p}{,}\PY{l+m+mi}{24}\PY{p}{,}\PY{l+m+mi}{32}\PY{p}{]}\PY{p}{)}\PY{p}{\PYZcb{}}\PY{p}{\PYZcb{}}\PY{p}{,} \PY{n}{kernel\PYZus{}size}\PY{o}{=}\PY{p}{\PYZob{}}\PY{p}{\PYZob{}}\PY{n}{choice}\PY{p}{(}\PY{p}{[}\PY{l+m+mi}{3}\PY{p}{,}\PY{l+m+mi}{5}\PY{p}{,}\PY{l+m+mi}{7}\PY{p}{]}\PY{p}{)}\PY{p}{\PYZcb{}}\PY{p}{\PYZcb{}}\PY{p}{,} 
                             \PY{n}{activation}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{relu}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}\PY{n}{kernel\PYZus{}regularizer}\PY{o}{=}\PY{n}{l2}\PY{p}{(}\PY{p}{\PYZob{}}\PY{p}{\PYZob{}}\PY{n}{uniform}\PY{p}{(}\PY{l+m+mi}{0}\PY{p}{,}\PY{l+m+mi}{2}\PY{p}{)}\PY{p}{\PYZcb{}}\PY{p}{\PYZcb{}}\PY{p}{)}\PY{p}{,}\PY{n}{kernel\PYZus{}initializer}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{he\PYZus{}uniform}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}\PY{p}{)}
            \PY{n}{model}\PY{o}{.}\PY{n}{add}\PY{p}{(}\PY{n}{Dropout}\PY{p}{(}\PY{p}{\PYZob{}}\PY{p}{\PYZob{}}\PY{n}{uniform}\PY{p}{(}\PY{l+m+mf}{0.45}\PY{p}{,}\PY{l+m+mf}{0.7}\PY{p}{)}\PY{p}{\PYZcb{}}\PY{p}{\PYZcb{}}\PY{p}{)}\PY{p}{)}
            \PY{n}{model}\PY{o}{.}\PY{n}{add}\PY{p}{(}\PY{n}{MaxPooling1D}\PY{p}{(}\PY{n}{pool\PYZus{}size}\PY{o}{=}\PY{p}{\PYZob{}}\PY{p}{\PYZob{}}\PY{n}{choice}\PY{p}{(}\PY{p}{[}\PY{l+m+mi}{2}\PY{p}{,}\PY{l+m+mi}{3}\PY{p}{,}\PY{l+m+mi}{5}\PY{p}{]}\PY{p}{)}\PY{p}{\PYZcb{}}\PY{p}{\PYZcb{}}\PY{p}{)}\PY{p}{)}
            \PY{n}{model}\PY{o}{.}\PY{n}{add}\PY{p}{(}\PY{n}{Flatten}\PY{p}{(}\PY{p}{)}\PY{p}{)}
            \PY{n}{model}\PY{o}{.}\PY{n}{add}\PY{p}{(}\PY{n}{Dense}\PY{p}{(}\PY{p}{\PYZob{}}\PY{p}{\PYZob{}}\PY{n}{choice}\PY{p}{(}\PY{p}{[}\PY{l+m+mi}{16}\PY{p}{,}\PY{l+m+mi}{32}\PY{p}{,}\PY{l+m+mi}{64}\PY{p}{]}\PY{p}{)}\PY{p}{\PYZcb{}}\PY{p}{\PYZcb{}}\PY{p}{,} \PY{n}{activation}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{relu}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}\PY{p}{)}
            \PY{n}{model}\PY{o}{.}\PY{n}{add}\PY{p}{(}\PY{n}{Dense}\PY{p}{(}\PY{l+m+mi}{3}\PY{p}{,} \PY{n}{activation}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{softmax}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}\PY{p}{)}
                
            \PY{n}{adam} \PY{o}{=} \PY{n}{keras}\PY{o}{.}\PY{n}{optimizers}\PY{o}{.}\PY{n}{Adam}\PY{p}{(}\PY{n}{lr}\PY{o}{=}\PY{p}{\PYZob{}}\PY{p}{\PYZob{}}\PY{n}{uniform}\PY{p}{(}\PY{l+m+mf}{0.00065}\PY{p}{,}\PY{l+m+mf}{0.004}\PY{p}{)}\PY{p}{\PYZcb{}}\PY{p}{\PYZcb{}}\PY{p}{)}
            \PY{n}{rmsprop} \PY{o}{=} \PY{n}{keras}\PY{o}{.}\PY{n}{optimizers}\PY{o}{.}\PY{n}{RMSprop}\PY{p}{(}\PY{n}{lr}\PY{o}{=}\PY{p}{\PYZob{}}\PY{p}{\PYZob{}}\PY{n}{uniform}\PY{p}{(}\PY{l+m+mf}{0.00065}\PY{p}{,}\PY{l+m+mf}{0.004}\PY{p}{)}\PY{p}{\PYZcb{}}\PY{p}{\PYZcb{}}\PY{p}{)}
           
            \PY{n}{choiceval} \PY{o}{=} \PY{p}{\PYZob{}}\PY{p}{\PYZob{}}\PY{n}{choice}\PY{p}{(}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{adam}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{rmsprop}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{)}\PY{p}{\PYZcb{}}\PY{p}{\PYZcb{}}
            
            \PY{k}{if} \PY{n}{choiceval} \PY{o}{==} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{adam}\PY{l+s+s1}{\PYZsq{}}\PY{p}{:}
                \PY{n}{optim} \PY{o}{=} \PY{n}{adam}
            \PY{k}{else}\PY{p}{:}
                \PY{n}{optim} \PY{o}{=} \PY{n}{rmsprop}
            
            \PY{n+nb}{print}\PY{p}{(}\PY{n}{model}\PY{o}{.}\PY{n}{summary}\PY{p}{(}\PY{p}{)}\PY{p}{)}
                
            \PY{n}{model}\PY{o}{.}\PY{n}{compile}\PY{p}{(}\PY{n}{loss}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{categorical\PYZus{}crossentropy}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{metrics}\PY{o}{=}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{accuracy}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{,}\PY{n}{optimizer}\PY{o}{=}\PY{n}{optim}\PY{p}{)}
            
            \PY{n}{result} \PY{o}{=} \PY{n}{model}\PY{o}{.}\PY{n}{fit}\PY{p}{(}\PY{n}{X\PYZus{}train\PYZus{}d}\PY{p}{,} \PY{n}{Y\PYZus{}train\PYZus{}d}\PY{p}{,}
                      \PY{n}{batch\PYZus{}size}\PY{o}{=}\PY{p}{\PYZob{}}\PY{p}{\PYZob{}}\PY{n}{choice}\PY{p}{(}\PY{p}{[}\PY{l+m+mi}{16}\PY{p}{,}\PY{l+m+mi}{32}\PY{p}{,}\PY{l+m+mi}{64}\PY{p}{]}\PY{p}{)}\PY{p}{\PYZcb{}}\PY{p}{\PYZcb{}}\PY{p}{,}
                      \PY{n}{nb\PYZus{}epoch}\PY{o}{=}\PY{p}{\PYZob{}}\PY{p}{\PYZob{}}\PY{n}{choice}\PY{p}{(}\PY{p}{[}\PY{l+m+mi}{35}\PY{p}{,}\PY{l+m+mi}{40}\PY{p}{,}\PY{l+m+mi}{55}\PY{p}{]}\PY{p}{)}\PY{p}{\PYZcb{}}\PY{p}{\PYZcb{}}\PY{p}{,}
                      \PY{n}{verbose}\PY{o}{=}\PY{l+m+mi}{2}\PY{p}{,}
                      \PY{n}{validation\PYZus{}data}\PY{o}{=}\PY{p}{(}\PY{n}{X\PYZus{}val\PYZus{}d}\PY{p}{,} \PY{n}{Y\PYZus{}val\PYZus{}d}\PY{p}{)}\PY{p}{)}
                               
            \PY{n}{score}\PY{p}{,} \PY{n}{acc} \PY{o}{=} \PY{n}{model}\PY{o}{.}\PY{n}{evaluate}\PY{p}{(}\PY{n}{X\PYZus{}val\PYZus{}d}\PY{p}{,} \PY{n}{Y\PYZus{}val\PYZus{}d}\PY{p}{,} \PY{n}{verbose}\PY{o}{=}\PY{l+m+mi}{0}\PY{p}{)}
            \PY{n}{score1}\PY{p}{,} \PY{n}{acc1} \PY{o}{=} \PY{n}{model}\PY{o}{.}\PY{n}{evaluate}\PY{p}{(}\PY{n}{X\PYZus{}train\PYZus{}d}\PY{p}{,} \PY{n}{Y\PYZus{}train\PYZus{}d}\PY{p}{,} \PY{n}{verbose}\PY{o}{=}\PY{l+m+mi}{0}\PY{p}{)}
            \PY{n+nb}{print}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Train accuracy}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}\PY{n}{acc1}\PY{p}{,}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Test accuracy:}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{acc}\PY{p}{)}
            \PY{n+nb}{print}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
            \PY{n}{K}\PY{o}{.}\PY{n}{clear\PYZus{}session}\PY{p}{(}\PY{p}{)}
            \PY{k}{return} \PY{p}{\PYZob{}}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{loss}\PY{l+s+s1}{\PYZsq{}}\PY{p}{:} \PY{o}{\PYZhy{}}\PY{n}{acc}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{status}\PY{l+s+s1}{\PYZsq{}}\PY{p}{:} \PY{n}{STATUS\PYZus{}OK}\PY{p}{,}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{train\PYZus{}acc}\PY{l+s+s1}{\PYZsq{}}\PY{p}{:}\PY{n}{acc1}\PY{p}{\PYZcb{}}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}8}]:} \PY{k+kn}{import} \PY{n+nn}{pickle}
        \PY{n}{best\PYZus{}run}\PY{p}{,} \PY{n}{best\PYZus{}model}\PY{p}{,} \PY{n}{space} \PY{o}{=} \PY{n}{pickle}\PY{o}{.}\PY{n}{load}\PY{p}{(}\PY{n+nb}{open}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{/home/u20112/final\PYZus{}result\PYZus{}cnn5.p}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{rb}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}\PY{p}{)}
        \PY{n}{trials} \PY{o}{=} \PY{n}{pickle}\PY{o}{.}\PY{n}{load}\PY{p}{(}\PY{n+nb}{open}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{/home/u20112/trials\PYZus{}cnn5.p}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{rb}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}\PY{p}{)}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor} }]:} \PY{n}{X\PYZus{}train\PYZus{}d}\PY{p}{,} \PY{n}{Y\PYZus{}train\PYZus{}d}\PY{p}{,} \PY{n}{X\PYZus{}val\PYZus{}d}\PY{p}{,} \PY{n}{Y\PYZus{}val\PYZus{}d} \PY{o}{=} \PY{n}{data\PYZus{}scaled\PYZus{}dynamic}\PY{p}{(}\PY{p}{)}
        \PY{n}{trials} \PY{o}{=} \PY{n}{Trials}\PY{p}{(}\PY{p}{)}
        \PY{n}{best\PYZus{}run}\PY{p}{,} \PY{n}{best\PYZus{}model}\PY{p}{,} \PY{n}{space} \PY{o}{=} \PY{n}{optim}\PY{o}{.}\PY{n}{minimize}\PY{p}{(}\PY{n}{model}\PY{o}{=}\PY{n}{model\PYZus{}cnn}\PY{p}{,}
                                              \PY{n}{data}\PY{o}{=}\PY{n}{data\PYZus{}scaled\PYZus{}dynamic}\PY{p}{,}
                                              \PY{n}{algo}\PY{o}{=}\PY{n}{tpe}\PY{o}{.}\PY{n}{suggest}\PY{p}{,}
                                              \PY{n}{max\PYZus{}evals}\PY{o}{=}\PY{l+m+mi}{120}\PY{p}{,}\PY{n}{rseed} \PY{o}{=} \PY{l+m+mi}{0}\PY{p}{,}                                           
                                              \PY{n}{trials}\PY{o}{=}\PY{n}{trials}\PY{p}{,}\PY{n}{notebook\PYZus{}name}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Human Activity Detection}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}
                                              \PY{n}{return\PYZus{}space} \PY{o}{=} \PY{k+kc}{True}\PY{p}{)}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}11}]:} \PY{k+kn}{from} \PY{n+nn}{hyperas}\PY{n+nn}{.}\PY{n+nn}{utils} \PY{k}{import} \PY{n}{eval\PYZus{}hyperopt\PYZus{}space}
         \PY{n}{total\PYZus{}trials} \PY{o}{=} \PY{n+nb}{dict}\PY{p}{(}\PY{p}{)}
         \PY{k}{for} \PY{n}{t}\PY{p}{,} \PY{n}{trial} \PY{o+ow}{in} \PY{n+nb}{enumerate}\PY{p}{(}\PY{n}{trials}\PY{p}{)}\PY{p}{:}
                 \PY{n}{vals} \PY{o}{=} \PY{n}{trial}\PY{o}{.}\PY{n}{get}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{misc}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}\PY{o}{.}\PY{n}{get}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{vals}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
                 \PY{n}{z} \PY{o}{=} \PY{n}{eval\PYZus{}hyperopt\PYZus{}space}\PY{p}{(}\PY{n}{space}\PY{p}{,} \PY{n}{vals}\PY{p}{)}
                 \PY{n}{total\PYZus{}trials}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{M}\PY{l+s+s1}{\PYZsq{}}\PY{o}{+}\PY{n+nb}{str}\PY{p}{(}\PY{n}{t}\PY{o}{+}\PY{l+m+mi}{1}\PY{p}{)}\PY{p}{]} \PY{o}{=} \PY{n}{z}
         \PY{c+c1}{\PYZsh{}best Hyper params from hyperas}
         \PY{n}{best\PYZus{}params} \PY{o}{=} \PY{n}{eval\PYZus{}hyperopt\PYZus{}space}\PY{p}{(}\PY{n}{space}\PY{p}{,} \PY{n}{best\PYZus{}run}\PY{p}{)}
         \PY{n}{best\PYZus{}params}
\end{Verbatim}


\begin{Verbatim}[commandchars=\\\{\}]
{\color{outcolor}Out[{\color{outcolor}11}]:} \{'Dense': 64,
          'Dense\_1': 32,
          'Dropout': 0.6725241946290972,
          'choiceval': 'adam',
          'filters': 32,
          'filters\_1': 32,
          'kernel\_size': 7,
          'kernel\_size\_1': 7,
          'l2': 0.548595947917793,
          'l2\_1': 0.28312064960787986,
          'lr': 0.00083263584783479,
          'lr\_1': 0.0020986605171288,
          'nb\_epoch': 35,
          'pool\_size': 5\}
\end{Verbatim}
            
    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}18}]:} \PY{k+kn}{import} \PY{n+nn}{keras}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}23}]:} \PY{c+c1}{\PYZsh{}Hyperas model}
         \PY{k}{def} \PY{n+nf}{model\PYZus{}hyperas}\PY{p}{(}\PY{n}{space}\PY{p}{,}\PY{n}{verbose}\PY{o}{=}\PY{l+m+mi}{1}\PY{p}{)}\PY{p}{:}   
             \PY{n}{np}\PY{o}{.}\PY{n}{random}\PY{o}{.}\PY{n}{seed}\PY{p}{(}\PY{l+m+mi}{0}\PY{p}{)}
             \PY{n}{tf}\PY{o}{.}\PY{n}{set\PYZus{}random\PYZus{}seed}\PY{p}{(}\PY{l+m+mi}{0}\PY{p}{)}
             \PY{n}{sess} \PY{o}{=} \PY{n}{tf}\PY{o}{.}\PY{n}{Session}\PY{p}{(}\PY{n}{graph}\PY{o}{=}\PY{n}{tf}\PY{o}{.}\PY{n}{get\PYZus{}default\PYZus{}graph}\PY{p}{(}\PY{p}{)}\PY{p}{)}
             \PY{n}{K}\PY{o}{.}\PY{n}{set\PYZus{}session}\PY{p}{(}\PY{n}{sess}\PY{p}{)}
             \PY{c+c1}{\PYZsh{} Initiliazing the sequential model}
             \PY{n}{model} \PY{o}{=} \PY{n}{Sequential}\PY{p}{(}\PY{p}{)}
             \PY{n}{model}\PY{o}{.}\PY{n}{add}\PY{p}{(}\PY{n}{Conv1D}\PY{p}{(}\PY{n}{filters}\PY{o}{=}\PY{n}{space}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{filters}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{,} \PY{n}{kernel\PYZus{}size}\PY{o}{=}\PY{n}{space}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{kernel\PYZus{}size}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{,}\PY{n}{activation}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{relu}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}
                             \PY{n}{kernel\PYZus{}initializer}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{he\PYZus{}uniform}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}
                             \PY{n}{kernel\PYZus{}regularizer}\PY{o}{=}\PY{n}{l2}\PY{p}{(}\PY{n}{space}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{l2}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{)}\PY{p}{,}\PY{n}{input\PYZus{}shape}\PY{o}{=}\PY{p}{(}\PY{l+m+mi}{128}\PY{p}{,}\PY{l+m+mi}{9}\PY{p}{)}\PY{p}{)}\PY{p}{)}
             \PY{n}{model}\PY{o}{.}\PY{n}{add}\PY{p}{(}\PY{n}{Conv1D}\PY{p}{(}\PY{n}{filters}\PY{o}{=}\PY{n}{space}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{filters\PYZus{}1}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{,} \PY{n}{kernel\PYZus{}size}\PY{o}{=}\PY{n}{space}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{kernel\PYZus{}size\PYZus{}1}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{,} 
                         \PY{n}{activation}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{relu}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}\PY{n}{kernel\PYZus{}regularizer}\PY{o}{=}\PY{n}{l2}\PY{p}{(}\PY{n}{space}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{l2\PYZus{}1}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{)}\PY{p}{,}\PY{n}{kernel\PYZus{}initializer}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{he\PYZus{}uniform}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}\PY{p}{)}
             \PY{n}{model}\PY{o}{.}\PY{n}{add}\PY{p}{(}\PY{n}{Dropout}\PY{p}{(}\PY{n}{space}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Dropout}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{)}\PY{p}{)}
             \PY{n}{model}\PY{o}{.}\PY{n}{add}\PY{p}{(}\PY{n}{MaxPooling1D}\PY{p}{(}\PY{n}{pool\PYZus{}size}\PY{o}{=}\PY{n}{space}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{pool\PYZus{}size}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{)}\PY{p}{)}
             \PY{n}{model}\PY{o}{.}\PY{n}{add}\PY{p}{(}\PY{n}{Flatten}\PY{p}{(}\PY{p}{)}\PY{p}{)}
             \PY{n}{model}\PY{o}{.}\PY{n}{add}\PY{p}{(}\PY{n}{Dense}\PY{p}{(}\PY{n}{space}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Dense}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{,} \PY{n}{activation}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{relu}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}\PY{p}{)}
             \PY{n}{model}\PY{o}{.}\PY{n}{add}\PY{p}{(}\PY{n}{Dense}\PY{p}{(}\PY{l+m+mi}{3}\PY{p}{,} \PY{n}{activation}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{softmax}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}\PY{p}{)}
             \PY{n}{adam} \PY{o}{=} \PY{n}{keras}\PY{o}{.}\PY{n}{optimizers}\PY{o}{.}\PY{n}{Adam}\PY{p}{(}\PY{n}{lr}\PY{o}{=}\PY{n}{space}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{lr}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{)}
             \PY{n}{rmsprop} \PY{o}{=} \PY{n}{keras}\PY{o}{.}\PY{n}{optimizers}\PY{o}{.}\PY{n}{RMSprop}\PY{p}{(}\PY{n}{lr}\PY{o}{=}\PY{n}{space}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{lr\PYZus{}1}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{)}
             \PY{n}{choiceval} \PY{o}{=} \PY{n}{space}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{choiceval}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}
             \PY{k}{if} \PY{n}{choiceval} \PY{o}{==} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{adam}\PY{l+s+s1}{\PYZsq{}}\PY{p}{:}
                 \PY{n}{optim} \PY{o}{=} \PY{n}{adam}
             \PY{k}{else}\PY{p}{:}
                 \PY{n}{optim} \PY{o}{=} \PY{n}{rmsprop}
             \PY{n+nb}{print}\PY{p}{(}\PY{n}{model}\PY{o}{.}\PY{n}{summary}\PY{p}{(}\PY{p}{)}\PY{p}{)}
             \PY{n}{model}\PY{o}{.}\PY{n}{compile}\PY{p}{(}\PY{n}{loss}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{categorical\PYZus{}crossentropy}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{metrics}\PY{o}{=}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{accuracy}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{,}\PY{n}{optimizer}\PY{o}{=}\PY{n}{optim}\PY{p}{)}
             \PY{n}{result} \PY{o}{=} \PY{n}{model}\PY{o}{.}\PY{n}{fit}\PY{p}{(}\PY{n}{X\PYZus{}train\PYZus{}d}\PY{p}{,} \PY{n}{Y\PYZus{}train\PYZus{}d}\PY{p}{,}
                             \PY{n}{batch\PYZus{}size}\PY{o}{=}\PY{n}{space}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Dense\PYZus{}1}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{,}
                             \PY{n}{nb\PYZus{}epoch}\PY{o}{=}\PY{n}{space}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{nb\PYZus{}epoch}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{,}
                             \PY{n}{verbose}\PY{o}{=}\PY{n}{verbose}\PY{p}{,}
                             \PY{n}{validation\PYZus{}data}\PY{o}{=}\PY{p}{(}\PY{n}{X\PYZus{}val\PYZus{}d}\PY{p}{,} \PY{n}{Y\PYZus{}val\PYZus{}d}\PY{p}{)}\PY{p}{)}
             \PY{c+c1}{\PYZsh{}K.clear\PYZus{}session()}
             \PY{k}{return} \PY{n}{model}\PY{p}{,}\PY{n}{result}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}24}]:} \PY{n}{best\PYZus{}model}\PY{p}{,}\PY{n}{result} \PY{o}{=} \PY{n}{model\PYZus{}hyperas}\PY{p}{(}\PY{n}{best\PYZus{}params}\PY{p}{)}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_
Layer (type)                 Output Shape              Param \#   
=================================================================
conv1d\_1 (Conv1D)            (None, 122, 32)           2048      
\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_
conv1d\_2 (Conv1D)            (None, 116, 32)           7200      
\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_
dropout\_1 (Dropout)          (None, 116, 32)           0         
\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_
max\_pooling1d\_1 (MaxPooling1 (None, 23, 32)            0         
\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_
flatten\_1 (Flatten)          (None, 736)               0         
\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_
dense\_1 (Dense)              (None, 64)                47168     
\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_
dense\_2 (Dense)              (None, 3)                 195       
=================================================================
Total params: 56,611
Trainable params: 56,611
Non-trainable params: 0
\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_
None
Train on 3285 samples, validate on 1387 samples
Epoch 1/35
3285/3285 [==============================] - 2s 553us/step - loss: 36.5170 - acc: 0.6493 - val\_loss: 21.6438 - val\_acc: 0.6936
Epoch 2/35
3285/3285 [==============================] - 1s 331us/step - loss: 13.4174 - acc: 0.9428 - val\_loss: 7.9785 - val\_acc: 0.9250
Epoch 3/35
3285/3285 [==============================] - 1s 320us/step - loss: 4.8053 - acc: 0.9772 - val\_loss: 3.1436 - val\_acc: 0.8457
Epoch 4/35
3285/3285 [==============================] - 1s 319us/step - loss: 1.7396 - acc: 0.9851 - val\_loss: 1.3414 - val\_acc: 0.9423
Epoch 5/35
3285/3285 [==============================] - 1s 319us/step - loss: 0.6754 - acc: 0.9921 - val\_loss: 0.7540 - val\_acc: 0.9517
Epoch 6/35
3285/3285 [==============================] - 1s 316us/step - loss: 0.3342 - acc: 0.9906 - val\_loss: 0.5434 - val\_acc: 0.9654
Epoch 7/35
3285/3285 [==============================] - 1s 316us/step - loss: 0.2152 - acc: 0.9930 - val\_loss: 0.5026 - val\_acc: 0.9308
Epoch 8/35
3285/3285 [==============================] - 1s 322us/step - loss: 0.1851 - acc: 0.9918 - val\_loss: 0.4687 - val\_acc: 0.9207
Epoch 9/35
3285/3285 [==============================] - 1s 320us/step - loss: 0.1573 - acc: 0.9954 - val\_loss: 0.3979 - val\_acc: 0.9589
Epoch 10/35
3285/3285 [==============================] - 1s 320us/step - loss: 0.1468 - acc: 0.9960 - val\_loss: 0.4149 - val\_acc: 0.9293
Epoch 11/35
3285/3285 [==============================] - 1s 330us/step - loss: 0.1295 - acc: 0.9960 - val\_loss: 0.3815 - val\_acc: 0.9495
Epoch 12/35
3285/3285 [==============================] - 1s 325us/step - loss: 0.1278 - acc: 0.9942 - val\_loss: 0.3490 - val\_acc: 0.9762
Epoch 13/35
3285/3285 [==============================] - 1s 326us/step - loss: 0.1144 - acc: 0.9960 - val\_loss: 0.3637 - val\_acc: 0.9726
Epoch 14/35
3285/3285 [==============================] - 1s 320us/step - loss: 0.1066 - acc: 0.9979 - val\_loss: 0.3378 - val\_acc: 0.9553
Epoch 15/35
3285/3285 [==============================] - 1s 320us/step - loss: 0.1332 - acc: 0.9896 - val\_loss: 0.3065 - val\_acc: 0.9719
Epoch 16/35
3285/3285 [==============================] - 1s 322us/step - loss: 0.1043 - acc: 0.9973 - val\_loss: 0.3214 - val\_acc: 0.9654
Epoch 17/35
3285/3285 [==============================] - 1s 320us/step - loss: 0.1074 - acc: 0.9951 - val\_loss: 0.2908 - val\_acc: 0.9712
Epoch 18/35
3285/3285 [==============================] - 1s 319us/step - loss: 0.0913 - acc: 0.9982 - val\_loss: 0.3016 - val\_acc: 0.9625
Epoch 19/35
3285/3285 [==============================] - 1s 317us/step - loss: 0.1172 - acc: 0.9884 - val\_loss: 0.2784 - val\_acc: 0.9805
Epoch 20/35
3285/3285 [==============================] - 1s 318us/step - loss: 0.1035 - acc: 0.9921 - val\_loss: 0.2836 - val\_acc: 0.9632
Epoch 21/35
3285/3285 [==============================] - 1s 317us/step - loss: 0.0959 - acc: 0.9948 - val\_loss: 0.2899 - val\_acc: 0.9769
Epoch 22/35
3285/3285 [==============================] - 1s 319us/step - loss: 0.0769 - acc: 0.9994 - val\_loss: 0.2944 - val\_acc: 0.9690
Epoch 23/35
3285/3285 [==============================] - 1s 319us/step - loss: 0.0766 - acc: 0.9985 - val\_loss: 0.2612 - val\_acc: 0.9697
Epoch 24/35
3285/3285 [==============================] - 1s 319us/step - loss: 0.1604 - acc: 0.9732 - val\_loss: 0.4175 - val\_acc: 0.8940
Epoch 25/35
3285/3285 [==============================] - 1s 316us/step - loss: 0.1246 - acc: 0.9951 - val\_loss: 0.2583 - val\_acc: 0.9676
Epoch 26/35
3285/3285 [==============================] - 1s 317us/step - loss: 0.0749 - acc: 0.9997 - val\_loss: 0.2711 - val\_acc: 0.9553
Epoch 27/35
3285/3285 [==============================] - 1s 318us/step - loss: 0.0703 - acc: 0.9997 - val\_loss: 0.2728 - val\_acc: 0.9712
Epoch 28/35
3285/3285 [==============================] - 1s 318us/step - loss: 0.0794 - acc: 0.9957 - val\_loss: 0.2454 - val\_acc: 0.9813
Epoch 29/35
3285/3285 [==============================] - 1s 316us/step - loss: 0.0679 - acc: 0.9985 - val\_loss: 0.2333 - val\_acc: 0.9798
Epoch 30/35
3285/3285 [==============================] - 1s 318us/step - loss: 0.0769 - acc: 0.9942 - val\_loss: 0.2243 - val\_acc: 0.9805
Epoch 31/35
3285/3285 [==============================] - 1s 318us/step - loss: 0.0952 - acc: 0.9924 - val\_loss: 0.2394 - val\_acc: 0.9805
Epoch 32/35
3285/3285 [==============================] - 1s 323us/step - loss: 0.0615 - acc: 0.9994 - val\_loss: 0.2289 - val\_acc: 0.9820
Epoch 33/35
3285/3285 [==============================] - 1s 318us/step - loss: 0.0574 - acc: 0.9988 - val\_loss: 0.2460 - val\_acc: 0.9726
Epoch 34/35
3285/3285 [==============================] - 1s 316us/step - loss: 0.1272 - acc: 0.9784 - val\_loss: 0.4408 - val\_acc: 0.9250
Epoch 35/35
3285/3285 [==============================] - 1s 318us/step - loss: 0.1743 - acc: 0.9860 - val\_loss: 0.2274 - val\_acc: 0.9704

    \end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}21}]:} \PY{n}{\PYZus{}}\PY{p}{,}\PY{n}{acc\PYZus{}val} \PY{o}{=} \PY{n}{best\PYZus{}model}\PY{o}{.}\PY{n}{evaluate}\PY{p}{(}\PY{n}{X\PYZus{}val\PYZus{}d}\PY{p}{,}\PY{n}{Y\PYZus{}val\PYZus{}d}\PY{p}{,}\PY{n}{verbose}\PY{o}{=}\PY{l+m+mi}{0}\PY{p}{)}
         \PY{n}{\PYZus{}}\PY{p}{,}\PY{n}{acc\PYZus{}train} \PY{o}{=} \PY{n}{best\PYZus{}model}\PY{o}{.}\PY{n}{evaluate}\PY{p}{(}\PY{n}{X\PYZus{}train\PYZus{}d}\PY{p}{,}\PY{n}{Y\PYZus{}train\PYZus{}d}\PY{p}{,}\PY{n}{verbose}\PY{o}{=}\PY{l+m+mi}{0}\PY{p}{)}
         \PY{n+nb}{print}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Train\PYZus{}accuracy}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}\PY{n}{acc\PYZus{}train}\PY{p}{,}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{test\PYZus{}accuracy}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}\PY{n}{acc\PYZus{}val}\PY{p}{)}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
Train\_accuracy 1.0 test\_accuracy 0.9704397981254506

    \end{Verbatim}

    We can observe that some models are having around 0.99 accuracy for some
epochs. will investgate some models(model 59, 99).

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}47}]:} \PY{n}{M59} \PY{o}{=} \PY{n}{total\PYZus{}trials}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{M59}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}
         \PY{n}{M59}
\end{Verbatim}


\begin{Verbatim}[commandchars=\\\{\}]
{\color{outcolor}Out[{\color{outcolor}47}]:} \{'Dense': 32,
          'Dense\_1': 32,
          'Dropout': 0.48642317342570957,
          'choiceval': 'adam',
          'filters': 32,
          'filters\_1': 32,
          'kernel\_size': 7,
          'kernel\_size\_1': 7,
          'l2': 0.10401484931072974,
          'l2\_1': 0.7228970346142163,
          'lr': 0.000772514731035696,
          'lr\_1': 0.003074353392879209,
          'nb\_epoch': 35,
          'pool\_size': 5\}
\end{Verbatim}
            
    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}62}]:} \PY{n}{K}\PY{o}{.}\PY{n}{clear\PYZus{}session}\PY{p}{(}\PY{p}{)}
         \PY{n}{M59}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{nb\PYZus{}epoch}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]} \PY{o}{=} \PY{l+m+mi}{70}
         \PY{n}{best\PYZus{}model\PYZus{}all}\PY{p}{,}\PY{n}{result} \PY{o}{=} \PY{n}{model\PYZus{}hyperas}\PY{p}{(}\PY{n}{M59}\PY{p}{)}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_
Layer (type)                 Output Shape              Param \#   
=================================================================
conv1d\_1 (Conv1D)            (None, 122, 32)           2048      
\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_
conv1d\_2 (Conv1D)            (None, 116, 32)           7200      
\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_
dropout\_1 (Dropout)          (None, 116, 32)           0         
\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_
max\_pooling1d\_1 (MaxPooling1 (None, 23, 32)            0         
\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_
flatten\_1 (Flatten)          (None, 736)               0         
\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_
dense\_1 (Dense)              (None, 32)                23584     
\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_
dense\_2 (Dense)              (None, 3)                 99        
=================================================================
Total params: 32,931
Trainable params: 32,931
Non-trainable params: 0
\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_
None
Train on 3285 samples, validate on 1387 samples
Epoch 1/70
3285/3285 [==============================] - 2s 597us/step - loss: 30.8432 - acc: 0.5963 - val\_loss: 14.3953 - val\_acc: 0.7808
Epoch 2/70
3285/3285 [==============================] - 1s 312us/step - loss: 7.8188 - acc: 0.9209 - val\_loss: 4.0805 - val\_acc: 0.8926
Epoch 3/70
3285/3285 [==============================] - 1s 313us/step - loss: 2.3103 - acc: 0.9863 - val\_loss: 1.6611 - val\_acc: 0.8666
Epoch 4/70
3285/3285 [==============================] - 1s 312us/step - loss: 0.9391 - acc: 0.9875 - val\_loss: 0.8736 - val\_acc: 0.9452
Epoch 5/70
3285/3285 [==============================] - 1s 312us/step - loss: 0.4885 - acc: 0.9933 - val\_loss: 0.6108 - val\_acc: 0.9459
Epoch 6/70
3285/3285 [==============================] - 1s 312us/step - loss: 0.3024 - acc: 0.9948 - val\_loss: 0.4641 - val\_acc: 0.9582
Epoch 7/70
3285/3285 [==============================] - 1s 313us/step - loss: 0.2201 - acc: 0.9954 - val\_loss: 0.4053 - val\_acc: 0.9582
Epoch 8/70
3285/3285 [==============================] - 1s 312us/step - loss: 0.1842 - acc: 0.9942 - val\_loss: 0.4262 - val\_acc: 0.9056
Epoch 9/70
3285/3285 [==============================] - 1s 311us/step - loss: 0.1602 - acc: 0.9967 - val\_loss: 0.3393 - val\_acc: 0.9495
Epoch 10/70
3285/3285 [==============================] - 1s 313us/step - loss: 0.1459 - acc: 0.9970 - val\_loss: 0.4134 - val\_acc: 0.8832
Epoch 11/70
3285/3285 [==============================] - 1s 310us/step - loss: 0.1402 - acc: 0.9945 - val\_loss: 0.3054 - val\_acc: 0.9611
Epoch 12/70
3285/3285 [==============================] - 1s 312us/step - loss: 0.1285 - acc: 0.9970 - val\_loss: 0.3474 - val\_acc: 0.9120
Epoch 13/70
3285/3285 [==============================] - 1s 317us/step - loss: 0.1155 - acc: 0.9985 - val\_loss: 0.2674 - val\_acc: 0.9733
Epoch 14/70
3285/3285 [==============================] - 1s 311us/step - loss: 0.1013 - acc: 0.9997 - val\_loss: 0.2624 - val\_acc: 0.9726
Epoch 15/70
3285/3285 [==============================] - 1s 311us/step - loss: 0.1029 - acc: 0.9967 - val\_loss: 0.2534 - val\_acc: 0.9769
Epoch 16/70
3285/3285 [==============================] - 1s 313us/step - loss: 0.0954 - acc: 0.9985 - val\_loss: 0.2426 - val\_acc: 0.9798
Epoch 17/70
3285/3285 [==============================] - 1s 313us/step - loss: 0.0997 - acc: 0.9960 - val\_loss: 0.2372 - val\_acc: 0.9733
Epoch 18/70
3285/3285 [==============================] - 1s 313us/step - loss: 0.0949 - acc: 0.9973 - val\_loss: 0.2542 - val\_acc: 0.9560
Epoch 19/70
3285/3285 [==============================] - 1s 311us/step - loss: 0.1709 - acc: 0.9744 - val\_loss: 0.2684 - val\_acc: 0.9863
Epoch 20/70
3285/3285 [==============================] - 1s 312us/step - loss: 0.1247 - acc: 0.9970 - val\_loss: 0.2157 - val\_acc: 0.9791
Epoch 21/70
3285/3285 [==============================] - 1s 310us/step - loss: 0.0822 - acc: 0.9994 - val\_loss: 0.2185 - val\_acc: 0.9769
Epoch 22/70
3285/3285 [==============================] - 1s 312us/step - loss: 0.0757 - acc: 0.9994 - val\_loss: 0.2226 - val\_acc: 0.9712
Epoch 23/70
3285/3285 [==============================] - 1s 311us/step - loss: 0.0787 - acc: 0.9985 - val\_loss: 0.2192 - val\_acc: 0.9704
Epoch 24/70
3285/3285 [==============================] - 1s 315us/step - loss: 0.0778 - acc: 0.9985 - val\_loss: 0.2143 - val\_acc: 0.9762
Epoch 25/70
3285/3285 [==============================] - 1s 323us/step - loss: 0.0711 - acc: 0.9991 - val\_loss: 0.2230 - val\_acc: 0.9683
Epoch 26/70
3285/3285 [==============================] - 1s 314us/step - loss: 0.0691 - acc: 1.0000 - val\_loss: 0.2136 - val\_acc: 0.9625
Epoch 27/70
3285/3285 [==============================] - 1s 312us/step - loss: 0.0662 - acc: 0.9997 - val\_loss: 0.2110 - val\_acc: 0.9726
Epoch 28/70
3285/3285 [==============================] - 1s 311us/step - loss: 0.0678 - acc: 0.9988 - val\_loss: 0.2034 - val\_acc: 0.9733
Epoch 29/70
3285/3285 [==============================] - 1s 310us/step - loss: 0.0651 - acc: 0.9988 - val\_loss: 0.2382 - val\_acc: 0.9409
Epoch 30/70
3285/3285 [==============================] - 1s 310us/step - loss: 0.0836 - acc: 0.9939 - val\_loss: 0.1809 - val\_acc: 0.9776
Epoch 31/70
3285/3285 [==============================] - 1s 311us/step - loss: 0.0618 - acc: 0.9991 - val\_loss: 0.1661 - val\_acc: 0.9813
Epoch 32/70
3285/3285 [==============================] - 1s 310us/step - loss: 0.0718 - acc: 0.9942 - val\_loss: 0.2447 - val\_acc: 0.9243
Epoch 33/70
3285/3285 [==============================] - 1s 310us/step - loss: 0.0659 - acc: 0.9988 - val\_loss: 0.1770 - val\_acc: 0.9798
Epoch 34/70
3285/3285 [==============================] - 1s 311us/step - loss: 0.0736 - acc: 0.9939 - val\_loss: 0.2253 - val\_acc: 0.9488
Epoch 35/70
3285/3285 [==============================] - 1s 310us/step - loss: 0.1024 - acc: 0.9872 - val\_loss: 0.2004 - val\_acc: 0.9697
Epoch 36/70
3285/3285 [==============================] - 1s 311us/step - loss: 0.0790 - acc: 0.9967 - val\_loss: 0.1588 - val\_acc: 0.9834
Epoch 37/70
3285/3285 [==============================] - 1s 311us/step - loss: 0.0555 - acc: 0.9991 - val\_loss: 0.1750 - val\_acc: 0.9719
Epoch 38/70
3285/3285 [==============================] - 1s 311us/step - loss: 0.0731 - acc: 0.9945 - val\_loss: 0.1918 - val\_acc: 0.9668
Epoch 39/70
3285/3285 [==============================] - 1s 310us/step - loss: 0.0523 - acc: 0.9997 - val\_loss: 0.1727 - val\_acc: 0.9784
Epoch 40/70
3285/3285 [==============================] - 1s 313us/step - loss: 0.0496 - acc: 0.9997 - val\_loss: 0.1779 - val\_acc: 0.9791
Epoch 41/70
3285/3285 [==============================] - 1s 312us/step - loss: 0.0468 - acc: 1.0000 - val\_loss: 0.1658 - val\_acc: 0.9798
Epoch 42/70
3285/3285 [==============================] - 1s 311us/step - loss: 0.1016 - acc: 0.9860 - val\_loss: 0.2262 - val\_acc: 0.9474
Epoch 43/70
3285/3285 [==============================] - 1s 312us/step - loss: 0.1060 - acc: 0.9896 - val\_loss: 0.1898 - val\_acc: 0.9567
Epoch 44/70
3285/3285 [==============================] - 1s 311us/step - loss: 0.0531 - acc: 0.9997 - val\_loss: 0.1729 - val\_acc: 0.9762
Epoch 45/70
3285/3285 [==============================] - 1s 310us/step - loss: 0.0484 - acc: 1.0000 - val\_loss: 0.1584 - val\_acc: 0.9798
Epoch 46/70
3285/3285 [==============================] - 1s 311us/step - loss: 0.0448 - acc: 1.0000 - val\_loss: 0.1779 - val\_acc: 0.9719
Epoch 47/70
3285/3285 [==============================] - 1s 311us/step - loss: 0.0447 - acc: 0.9997 - val\_loss: 0.1695 - val\_acc: 0.9748
Epoch 48/70
3285/3285 [==============================] - 1s 309us/step - loss: 0.0443 - acc: 0.9997 - val\_loss: 0.1743 - val\_acc: 0.9676
Epoch 49/70
3285/3285 [==============================] - 1s 310us/step - loss: 0.0435 - acc: 1.0000 - val\_loss: 0.1537 - val\_acc: 0.9813
Epoch 50/70
3285/3285 [==============================] - 1s 310us/step - loss: 0.0445 - acc: 0.9994 - val\_loss: 0.1616 - val\_acc: 0.9784
Epoch 51/70
3285/3285 [==============================] - 1s 310us/step - loss: 0.0477 - acc: 0.9979 - val\_loss: 0.1727 - val\_acc: 0.9668
Epoch 52/70
3285/3285 [==============================] - 1s 310us/step - loss: 0.0388 - acc: 1.0000 - val\_loss: 0.1729 - val\_acc: 0.9661
Epoch 53/70
3285/3285 [==============================] - 1s 310us/step - loss: 0.0387 - acc: 1.0000 - val\_loss: 0.1752 - val\_acc: 0.9726
Epoch 54/70
3285/3285 [==============================] - 1s 311us/step - loss: 0.0454 - acc: 0.9985 - val\_loss: 0.1591 - val\_acc: 0.9791
Epoch 55/70
3285/3285 [==============================] - 1s 310us/step - loss: 0.0723 - acc: 0.9918 - val\_loss: 0.3355 - val\_acc: 0.9185
Epoch 56/70
3285/3285 [==============================] - 1s 309us/step - loss: 0.0712 - acc: 0.9973 - val\_loss: 0.1457 - val\_acc: 0.9798
Epoch 57/70
3285/3285 [==============================] - 1s 311us/step - loss: 0.0404 - acc: 1.0000 - val\_loss: 0.1419 - val\_acc: 0.9784
Epoch 58/70
3285/3285 [==============================] - 1s 310us/step - loss: 0.0399 - acc: 0.9994 - val\_loss: 0.2314 - val\_acc: 0.9171
Epoch 59/70
3285/3285 [==============================] - 1s 310us/step - loss: 0.0866 - acc: 0.9875 - val\_loss: 0.3363 - val\_acc: 0.9193
Epoch 60/70
3285/3285 [==============================] - 1s 308us/step - loss: 0.0687 - acc: 0.9973 - val\_loss: 0.1326 - val\_acc: 0.9784
Epoch 61/70
3285/3285 [==============================] - 1s 309us/step - loss: 0.0385 - acc: 1.0000 - val\_loss: 0.1571 - val\_acc: 0.9755
Epoch 62/70
3285/3285 [==============================] - 1s 310us/step - loss: 0.0370 - acc: 1.0000 - val\_loss: 0.1691 - val\_acc: 0.9661
Epoch 63/70
3285/3285 [==============================] - 1s 309us/step - loss: 0.0416 - acc: 0.9985 - val\_loss: 0.1648 - val\_acc: 0.9784
Epoch 64/70
3285/3285 [==============================] - 1s 310us/step - loss: 0.0354 - acc: 0.9997 - val\_loss: 0.1901 - val\_acc: 0.9640
Epoch 65/70
3285/3285 [==============================] - 1s 310us/step - loss: 0.0348 - acc: 0.9997 - val\_loss: 0.1648 - val\_acc: 0.9726
Epoch 66/70
3285/3285 [==============================] - 1s 309us/step - loss: 0.0340 - acc: 1.0000 - val\_loss: 0.1467 - val\_acc: 0.9805
Epoch 67/70
3285/3285 [==============================] - 1s 309us/step - loss: 0.0327 - acc: 0.9997 - val\_loss: 0.1658 - val\_acc: 0.9755
Epoch 68/70
3285/3285 [==============================] - 1s 310us/step - loss: 0.0624 - acc: 0.9921 - val\_loss: 0.3186 - val\_acc: 0.9185
Epoch 69/70
3285/3285 [==============================] - 1s 310us/step - loss: 0.0514 - acc: 0.9976 - val\_loss: 0.1876 - val\_acc: 0.9755
Epoch 70/70
3285/3285 [==============================] - 1s 311us/step - loss: 0.0376 - acc: 0.9994 - val\_loss: 0.1400 - val\_acc: 0.9769

    \end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}64}]:} \PY{n}{plt}\PY{o}{.}\PY{n}{figure}\PY{p}{(}\PY{n}{figsize}\PY{o}{=}\PY{p}{(}\PY{l+m+mi}{12}\PY{p}{,}\PY{l+m+mi}{8}\PY{p}{)}\PY{p}{)}
         \PY{n}{plt}\PY{o}{.}\PY{n}{plot}\PY{p}{(}\PY{n}{result}\PY{o}{.}\PY{n}{history}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{loss}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{,}\PY{n}{label}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Train loss}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
         \PY{n}{plt}\PY{o}{.}\PY{n}{plot}\PY{p}{(}\PY{n}{result}\PY{o}{.}\PY{n}{history}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{val\PYZus{}loss}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{,}\PY{n}{label} \PY{o}{=} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Validation loss}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
         \PY{n}{plt}\PY{o}{.}\PY{n}{xlabel}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{epoch no}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
         \PY{n}{plt}\PY{o}{.}\PY{n}{ylabel}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{loss}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
         \PY{n}{plt}\PY{o}{.}\PY{n}{legend}\PY{p}{(}\PY{p}{)}
         \PY{n}{plt}\PY{o}{.}\PY{n}{show}\PY{p}{(}\PY{p}{)}
\end{Verbatim}


    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{output_227_0.png}
    \end{center}
    { \hspace*{\fill} \\}
    
    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}65}]:} \PY{n}{plt}\PY{o}{.}\PY{n}{figure}\PY{p}{(}\PY{n}{figsize}\PY{o}{=}\PY{p}{(}\PY{l+m+mi}{12}\PY{p}{,}\PY{l+m+mi}{8}\PY{p}{)}\PY{p}{)}
         \PY{n}{plt}\PY{o}{.}\PY{n}{plot}\PY{p}{(}\PY{n}{result}\PY{o}{.}\PY{n}{history}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{acc}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{,}\PY{n}{label}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Train acc}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
         \PY{n}{plt}\PY{o}{.}\PY{n}{plot}\PY{p}{(}\PY{n}{result}\PY{o}{.}\PY{n}{history}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{val\PYZus{}acc}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{,}\PY{n}{label} \PY{o}{=} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Validation acc}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
         \PY{n}{plt}\PY{o}{.}\PY{n}{xlabel}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{epoch no}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
         \PY{n}{plt}\PY{o}{.}\PY{n}{ylabel}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{acc}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
         \PY{n}{plt}\PY{o}{.}\PY{n}{legend}\PY{p}{(}\PY{p}{)}
         \PY{n}{plt}\PY{o}{.}\PY{n}{show}\PY{p}{(}\PY{p}{)}
\end{Verbatim}


    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{output_228_0.png}
    \end{center}
    { \hspace*{\fill} \\}
    
    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}45}]:} \PY{c+c1}{\PYZsh{}\PYZsh{}upto 19 epoces will give good score }
         \PY{n}{K}\PY{o}{.}\PY{n}{clear\PYZus{}session}\PY{p}{(}\PY{p}{)}
         \PY{n}{M59}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{nb\PYZus{}epoch}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]} \PY{o}{=} \PY{l+m+mi}{19}
         \PY{n}{best\PYZus{}model}\PY{p}{,}\PY{n}{result} \PY{o}{=} \PY{n}{model\PYZus{}hyperas}\PY{p}{(}\PY{n}{M59}\PY{p}{)}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_
Layer (type)                 Output Shape              Param \#   
=================================================================
conv1d\_1 (Conv1D)            (None, 122, 32)           2048      
\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_
conv1d\_2 (Conv1D)            (None, 116, 32)           7200      
\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_
dropout\_1 (Dropout)          (None, 116, 32)           0         
\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_
max\_pooling1d\_1 (MaxPooling1 (None, 23, 32)            0         
\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_
flatten\_1 (Flatten)          (None, 736)               0         
\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_
dense\_1 (Dense)              (None, 32)                23584     
\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_
dense\_2 (Dense)              (None, 3)                 99        
=================================================================
Total params: 32,931
Trainable params: 32,931
Non-trainable params: 0
\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_
None
Train on 3285 samples, validate on 1387 samples
Epoch 1/19
3285/3285 [==============================] - 2s 587us/step - loss: 30.8432 - acc: 0.5963 - val\_loss: 14.3953 - val\_acc: 0.7808
Epoch 2/19
3285/3285 [==============================] - 1s 311us/step - loss: 7.8188 - acc: 0.9209 - val\_loss: 4.0805 - val\_acc: 0.8926
Epoch 3/19
3285/3285 [==============================] - 1s 312us/step - loss: 2.3103 - acc: 0.9863 - val\_loss: 1.6611 - val\_acc: 0.8666
Epoch 4/19
3285/3285 [==============================] - 1s 310us/step - loss: 0.9391 - acc: 0.9875 - val\_loss: 0.8736 - val\_acc: 0.9452
Epoch 5/19
3285/3285 [==============================] - 1s 311us/step - loss: 0.4885 - acc: 0.9933 - val\_loss: 0.6108 - val\_acc: 0.9459
Epoch 6/19
3285/3285 [==============================] - 1s 311us/step - loss: 0.3024 - acc: 0.9948 - val\_loss: 0.4641 - val\_acc: 0.9582
Epoch 7/19
3285/3285 [==============================] - 1s 313us/step - loss: 0.2201 - acc: 0.9954 - val\_loss: 0.4053 - val\_acc: 0.9582
Epoch 8/19
3285/3285 [==============================] - 1s 312us/step - loss: 0.1842 - acc: 0.9942 - val\_loss: 0.4262 - val\_acc: 0.9056
Epoch 9/19
3285/3285 [==============================] - 1s 310us/step - loss: 0.1602 - acc: 0.9967 - val\_loss: 0.3393 - val\_acc: 0.9495
Epoch 10/19
3285/3285 [==============================] - 1s 312us/step - loss: 0.1459 - acc: 0.9970 - val\_loss: 0.4134 - val\_acc: 0.8832
Epoch 11/19
3285/3285 [==============================] - 1s 312us/step - loss: 0.1402 - acc: 0.9945 - val\_loss: 0.3054 - val\_acc: 0.9611
Epoch 12/19
3285/3285 [==============================] - 1s 313us/step - loss: 0.1285 - acc: 0.9970 - val\_loss: 0.3474 - val\_acc: 0.9120
Epoch 13/19
3285/3285 [==============================] - 1s 312us/step - loss: 0.1155 - acc: 0.9985 - val\_loss: 0.2674 - val\_acc: 0.9733
Epoch 14/19
3285/3285 [==============================] - 1s 310us/step - loss: 0.1013 - acc: 0.9997 - val\_loss: 0.2624 - val\_acc: 0.9726
Epoch 15/19
3285/3285 [==============================] - 1s 315us/step - loss: 0.1029 - acc: 0.9967 - val\_loss: 0.2534 - val\_acc: 0.9769
Epoch 16/19
3285/3285 [==============================] - 1s 312us/step - loss: 0.0954 - acc: 0.9985 - val\_loss: 0.2426 - val\_acc: 0.9798
Epoch 17/19
3285/3285 [==============================] - 1s 313us/step - loss: 0.0997 - acc: 0.9960 - val\_loss: 0.2372 - val\_acc: 0.9733
Epoch 18/19
3285/3285 [==============================] - 1s 310us/step - loss: 0.0949 - acc: 0.9973 - val\_loss: 0.2542 - val\_acc: 0.9560
Epoch 19/19
3285/3285 [==============================] - 1s 313us/step - loss: 0.1709 - acc: 0.9744 - val\_loss: 0.2684 - val\_acc: 0.9863

    \end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}49}]:} \PY{k+kn}{from} \PY{n+nn}{sklearn} \PY{k}{import} \PY{n}{metrics}
         \PY{n}{ACTIVITIES} \PY{o}{=} \PY{p}{\PYZob{}}
             \PY{l+m+mi}{0}\PY{p}{:} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{WALKING}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}
             \PY{l+m+mi}{1}\PY{p}{:} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{WALKING\PYZus{}UPSTAIRS}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}
             \PY{l+m+mi}{2}\PY{p}{:} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{WALKING\PYZus{}DOWNSTAIRS}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}
         \PY{p}{\PYZcb{}}
         
         \PY{c+c1}{\PYZsh{} Utility function to print the confusion matrix}
         \PY{k}{def} \PY{n+nf}{confusion\PYZus{}matrix\PYZus{}cnn}\PY{p}{(}\PY{n}{Y\PYZus{}true}\PY{p}{,} \PY{n}{Y\PYZus{}pred}\PY{p}{)}\PY{p}{:}
             \PY{n}{Y\PYZus{}true} \PY{o}{=} \PY{n}{pd}\PY{o}{.}\PY{n}{Series}\PY{p}{(}\PY{p}{[}\PY{n}{ACTIVITIES}\PY{p}{[}\PY{n}{y}\PY{p}{]} \PY{k}{for} \PY{n}{y} \PY{o+ow}{in} \PY{n}{np}\PY{o}{.}\PY{n}{argmax}\PY{p}{(}\PY{n}{Y\PYZus{}true}\PY{p}{,} \PY{n}{axis}\PY{o}{=}\PY{l+m+mi}{1}\PY{p}{)}\PY{p}{]}\PY{p}{)}
             \PY{n}{Y\PYZus{}pred} \PY{o}{=} \PY{n}{pd}\PY{o}{.}\PY{n}{Series}\PY{p}{(}\PY{p}{[}\PY{n}{ACTIVITIES}\PY{p}{[}\PY{n}{y}\PY{p}{]} \PY{k}{for} \PY{n}{y} \PY{o+ow}{in} \PY{n}{np}\PY{o}{.}\PY{n}{argmax}\PY{p}{(}\PY{n}{Y\PYZus{}pred}\PY{p}{,} \PY{n}{axis}\PY{o}{=}\PY{l+m+mi}{1}\PY{p}{)}\PY{p}{]}\PY{p}{)}
         
             \PY{c+c1}{\PYZsh{}return pd.crosstab(Y\PYZus{}true, Y\PYZus{}pred, rownames=[\PYZsq{}True\PYZsq{}], colnames=[\PYZsq{}Pred\PYZsq{}])}
             \PY{k}{return} \PY{n}{metrics}\PY{o}{.}\PY{n}{confusion\PYZus{}matrix}\PY{p}{(}\PY{n}{Y\PYZus{}true}\PY{p}{,} \PY{n}{Y\PYZus{}pred}\PY{p}{)}
         
         \PY{c+c1}{\PYZsh{} Confusion Matrix}
         \PY{n+nb}{print}\PY{p}{(}\PY{n}{confusion\PYZus{}matrix\PYZus{}cnn}\PY{p}{(}\PY{n}{Y\PYZus{}val\PYZus{}d}\PY{p}{,} \PY{n}{best\PYZus{}model}\PY{o}{.}\PY{n}{predict}\PY{p}{(}\PY{n}{X\PYZus{}val\PYZus{}d}\PY{p}{)}\PY{p}{)}\PY{p}{)}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
[[486   0  10]
 [  1 417   2]
 [  3   3 465]]

    \end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}57}]:} \PY{n}{plt}\PY{o}{.}\PY{n}{figure}\PY{p}{(}\PY{n}{figsize}\PY{o}{=}\PY{p}{(}\PY{l+m+mi}{8}\PY{p}{,}\PY{l+m+mi}{8}\PY{p}{)}\PY{p}{)}
         \PY{n}{cm} \PY{o}{=} \PY{n}{confusion\PYZus{}matrix\PYZus{}cnn}\PY{p}{(}\PY{n}{Y\PYZus{}val\PYZus{}d}\PY{p}{,} \PY{n}{best\PYZus{}model}\PY{o}{.}\PY{n}{predict}\PY{p}{(}\PY{n}{X\PYZus{}val\PYZus{}d}\PY{p}{)}\PY{p}{)}
         \PY{n}{plot\PYZus{}confusion\PYZus{}matrix}\PY{p}{(}\PY{n}{cm}\PY{p}{,} \PY{n}{classes}\PY{o}{=}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{WALKING}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{WALKING\PYZus{}UPSTAIRS}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{WALKING\PYZus{}DOWNSTAIRS}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{,} 
                               \PY{n}{normalize}\PY{o}{=}\PY{k+kc}{True}\PY{p}{,} \PY{n}{title}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Normalized confusion matrix}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{cmap} \PY{o}{=} \PY{n}{plt}\PY{o}{.}\PY{n}{cm}\PY{o}{.}\PY{n}{Greens}\PY{p}{)}
         \PY{n}{plt}\PY{o}{.}\PY{n}{show}\PY{p}{(}\PY{p}{)}
\end{Verbatim}


    
    \begin{verbatim}
<matplotlib.figure.Figure at 0x147481785470>
    \end{verbatim}

    
    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{output_231_1.png}
    \end{center}
    { \hspace*{\fill} \\}
    
    it is also giving good scores than previous

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}58}]:} \PY{c+c1}{\PYZsh{}saving model}
         \PY{n}{best\PYZus{}model}\PY{o}{.}\PY{n}{save}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{final\PYZus{}model\PYZus{}dynamic.h5}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}154}]:} \PY{k}{def} \PY{n+nf}{data}\PY{p}{(}\PY{p}{)}\PY{p}{:}
              \PY{l+s+sd}{\PYZdq{}\PYZdq{}\PYZdq{}}
          \PY{l+s+sd}{    Obtain the dataset from multiple files.}
          \PY{l+s+sd}{    Returns: X\PYZus{}train, X\PYZus{}test, y\PYZus{}train, y\PYZus{}test}
          \PY{l+s+sd}{    \PYZdq{}\PYZdq{}\PYZdq{}}
              \PY{c+c1}{\PYZsh{} Data directory}
              \PY{n}{DATADIR} \PY{o}{=} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{UCI\PYZus{}HAR\PYZus{}Dataset}\PY{l+s+s1}{\PYZsq{}}
              \PY{c+c1}{\PYZsh{} Raw data signals}
              \PY{c+c1}{\PYZsh{} Signals are from Accelerometer and Gyroscope}
              \PY{c+c1}{\PYZsh{} The signals are in x,y,z directions}
              \PY{c+c1}{\PYZsh{} Sensor signals are filtered to have only body acceleration}
              \PY{c+c1}{\PYZsh{} excluding the acceleration due to gravity}
              \PY{c+c1}{\PYZsh{} Triaxial acceleration from the accelerometer is total acceleration}
              \PY{n}{SIGNALS} \PY{o}{=} \PY{p}{[}
                  \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{body\PYZus{}acc\PYZus{}x}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,}
                  \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{body\PYZus{}acc\PYZus{}y}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,}
                  \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{body\PYZus{}acc\PYZus{}z}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,}
                  \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{body\PYZus{}gyro\PYZus{}x}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,}
                  \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{body\PYZus{}gyro\PYZus{}y}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,}
                  \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{body\PYZus{}gyro\PYZus{}z}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,}
                  \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{total\PYZus{}acc\PYZus{}x}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,}
                  \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{total\PYZus{}acc\PYZus{}y}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,}
                  \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{total\PYZus{}acc\PYZus{}z}\PY{l+s+s2}{\PYZdq{}}
                  \PY{p}{]}
              \PY{c+c1}{\PYZsh{} Utility function to read the data from csv file}
              \PY{k}{def} \PY{n+nf}{\PYZus{}read\PYZus{}csv}\PY{p}{(}\PY{n}{filename}\PY{p}{)}\PY{p}{:}
                  \PY{k}{return} \PY{n}{pd}\PY{o}{.}\PY{n}{read\PYZus{}csv}\PY{p}{(}\PY{n}{filename}\PY{p}{,} \PY{n}{delim\PYZus{}whitespace}\PY{o}{=}\PY{k+kc}{True}\PY{p}{,} \PY{n}{header}\PY{o}{=}\PY{k+kc}{None}\PY{p}{)}
          
              \PY{c+c1}{\PYZsh{} Utility function to load the load}
              \PY{k}{def} \PY{n+nf}{load\PYZus{}signals}\PY{p}{(}\PY{n}{subset}\PY{p}{)}\PY{p}{:}
                  \PY{n}{signals\PYZus{}data} \PY{o}{=} \PY{p}{[}\PY{p}{]}
          
                  \PY{k}{for} \PY{n}{signal} \PY{o+ow}{in} \PY{n}{SIGNALS}\PY{p}{:}
                      \PY{n}{filename} \PY{o}{=} \PY{n}{f}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{UCI\PYZus{}HAR\PYZus{}Dataset/}\PY{l+s+si}{\PYZob{}subset\PYZcb{}}\PY{l+s+s1}{/Inertial Signals/}\PY{l+s+si}{\PYZob{}signal\PYZcb{}}\PY{l+s+s1}{\PYZus{}}\PY{l+s+si}{\PYZob{}subset\PYZcb{}}\PY{l+s+s1}{.txt}\PY{l+s+s1}{\PYZsq{}}
                      \PY{n}{signals\PYZus{}data}\PY{o}{.}\PY{n}{append}\PY{p}{(} \PY{n}{\PYZus{}read\PYZus{}csv}\PY{p}{(}\PY{n}{filename}\PY{p}{)}\PY{o}{.}\PY{n}{as\PYZus{}matrix}\PY{p}{(}\PY{p}{)}\PY{p}{)} 
          
                  \PY{c+c1}{\PYZsh{} Transpose is used to change the dimensionality of the output,}
                  \PY{c+c1}{\PYZsh{} aggregating the signals by combination of sample/timestep.}
                  \PY{c+c1}{\PYZsh{} Resultant shape is (7352 train/2947 test samples, 128 timesteps, 9 signals)}
                  \PY{k}{return} \PY{n}{np}\PY{o}{.}\PY{n}{transpose}\PY{p}{(}\PY{n}{signals\PYZus{}data}\PY{p}{,} \PY{p}{(}\PY{l+m+mi}{1}\PY{p}{,} \PY{l+m+mi}{2}\PY{p}{,} \PY{l+m+mi}{0}\PY{p}{)}\PY{p}{)}
              
              \PY{k}{def} \PY{n+nf}{load\PYZus{}y}\PY{p}{(}\PY{n}{subset}\PY{p}{)}\PY{p}{:}
                  \PY{l+s+sd}{\PYZdq{}\PYZdq{}\PYZdq{}}
          \PY{l+s+sd}{        The objective that we are trying to predict is a integer, from 1 to 6,}
          \PY{l+s+sd}{        that represents a human activity. We return a binary representation of }
          \PY{l+s+sd}{        every sample objective as a 6 bits vector using One Hot Encoding}
          \PY{l+s+sd}{        (https://pandas.pydata.org/pandas\PYZhy{}docs/stable/generated/pandas.get\PYZus{}dummies.html)}
          \PY{l+s+sd}{        \PYZdq{}\PYZdq{}\PYZdq{}}
                  \PY{n}{filename} \PY{o}{=} \PY{n}{f}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{UCI\PYZus{}HAR\PYZus{}Dataset/}\PY{l+s+si}{\PYZob{}subset\PYZcb{}}\PY{l+s+s1}{/y\PYZus{}}\PY{l+s+si}{\PYZob{}subset\PYZcb{}}\PY{l+s+s1}{.txt}\PY{l+s+s1}{\PYZsq{}}
                  \PY{n}{y} \PY{o}{=} \PY{n}{\PYZus{}read\PYZus{}csv}\PY{p}{(}\PY{n}{filename}\PY{p}{)}\PY{p}{[}\PY{l+m+mi}{0}\PY{p}{]}
                  \PY{k}{return} \PY{n}{y}
              
              \PY{n}{X\PYZus{}train}\PY{p}{,} \PY{n}{X\PYZus{}val} \PY{o}{=} \PY{n}{load\PYZus{}signals}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{train}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}\PY{p}{,} \PY{n}{load\PYZus{}signals}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{test}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
              \PY{n}{Y\PYZus{}train}\PY{p}{,} \PY{n}{Y\PYZus{}val} \PY{o}{=} \PY{n}{load\PYZus{}y}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{train}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}\PY{p}{,} \PY{n}{load\PYZus{}y}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{test}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
          
              \PY{k}{return} \PY{n}{X\PYZus{}train}\PY{p}{,} \PY{n}{Y\PYZus{}train}\PY{p}{,} \PY{n}{X\PYZus{}val}\PY{p}{,}  \PY{n}{Y\PYZus{}val}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}155}]:} \PY{n}{X\PYZus{}train}\PY{p}{,} \PY{n}{Y\PYZus{}train}\PY{p}{,} \PY{n}{X\PYZus{}val}\PY{p}{,}  \PY{n}{Y\PYZus{}val} \PY{o}{=} \PY{n}{data}\PY{p}{(}\PY{p}{)}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}167}]:} \PY{n+nb}{print}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{shape of test Y}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}\PY{n}{Y\PYZus{}val}\PY{o}{.}\PY{n}{shape}\PY{p}{)}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
shape of test Y (2947,)

    \end{Verbatim}

    \subsubsection{Final prediction
pipeline}\label{final-prediction-pipeline}

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}159}]:} \PY{c+c1}{\PYZsh{}\PYZsh{}loading keras models and picle files for scaling data }
          \PY{k+kn}{from} \PY{n+nn}{keras}\PY{n+nn}{.}\PY{n+nn}{models} \PY{k}{import} \PY{n}{load\PYZus{}model}
          \PY{k+kn}{import} \PY{n+nn}{pickle}
          \PY{n}{model\PYZus{}2class} \PY{o}{=} \PY{n}{load\PYZus{}model}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{final\PYZus{}model\PYZus{}2class.h5}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
          \PY{n}{model\PYZus{}dynamic} \PY{o}{=} \PY{n}{load\PYZus{}model}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{final\PYZus{}model\PYZus{}dynamic.h5}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
          \PY{n}{model\PYZus{}static} \PY{o}{=} \PY{n}{load\PYZus{}model}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{final\PYZus{}model\PYZus{}static.h5}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
          \PY{n}{scale\PYZus{}2class} \PY{o}{=} \PY{n}{pickle}\PY{o}{.}\PY{n}{load}\PY{p}{(}\PY{n+nb}{open}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Scale\PYZus{}2class.p}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{rb}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}\PY{p}{)}
          \PY{n}{scale\PYZus{}static} \PY{o}{=} \PY{n}{pickle}\PY{o}{.}\PY{n}{load}\PY{p}{(}\PY{n+nb}{open}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Scale\PYZus{}static.p}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{rb}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}\PY{p}{)}
          \PY{n}{scale\PYZus{}dynamic} \PY{o}{=} \PY{n}{pickle}\PY{o}{.}\PY{n}{load}\PY{p}{(}\PY{n+nb}{open}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Scale\PYZus{}dynamic.p}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{rb}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}\PY{p}{)}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}162}]:} \PY{c+c1}{\PYZsh{}\PYZsh{}scaling the data}
          \PY{k}{def} \PY{n+nf}{transform\PYZus{}data}\PY{p}{(}\PY{n}{X}\PY{p}{,}\PY{n}{scale}\PY{p}{)}\PY{p}{:}
              \PY{n}{X\PYZus{}temp} \PY{o}{=} \PY{n}{X}\PY{o}{.}\PY{n}{reshape}\PY{p}{(}\PY{p}{(}\PY{n}{X}\PY{o}{.}\PY{n}{shape}\PY{p}{[}\PY{l+m+mi}{0}\PY{p}{]} \PY{o}{*} \PY{n}{X}\PY{o}{.}\PY{n}{shape}\PY{p}{[}\PY{l+m+mi}{1}\PY{p}{]}\PY{p}{,} \PY{n}{X}\PY{o}{.}\PY{n}{shape}\PY{p}{[}\PY{l+m+mi}{2}\PY{p}{]}\PY{p}{)}\PY{p}{)}
              \PY{n}{X\PYZus{}temp} \PY{o}{=} \PY{n}{scale}\PY{o}{.}\PY{n}{transform}\PY{p}{(}\PY{n}{X\PYZus{}temp}\PY{p}{)}
              \PY{k}{return} \PY{n}{X\PYZus{}temp}\PY{o}{.}\PY{n}{reshape}\PY{p}{(}\PY{n}{X}\PY{o}{.}\PY{n}{shape}\PY{p}{)}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}169}]:} \PY{c+c1}{\PYZsh{}predicting output activity}
          \PY{k}{def} \PY{n+nf}{predict\PYZus{}activity}\PY{p}{(}\PY{n}{X}\PY{p}{)}\PY{p}{:}
              \PY{c+c1}{\PYZsh{}\PYZsh{}predicting whether dynamic or static}
              \PY{n}{predict\PYZus{}2class} \PY{o}{=} \PY{n}{model\PYZus{}2class}\PY{o}{.}\PY{n}{predict}\PY{p}{(}\PY{n}{transform\PYZus{}data}\PY{p}{(}\PY{n}{X}\PY{p}{,}\PY{n}{scale\PYZus{}2class}\PY{p}{)}\PY{p}{)}
              \PY{n}{Y\PYZus{}pred\PYZus{}2class} \PY{o}{=}  \PY{n}{np}\PY{o}{.}\PY{n}{argmax}\PY{p}{(}\PY{n}{predict\PYZus{}2class}\PY{p}{,} \PY{n}{axis}\PY{o}{=}\PY{l+m+mi}{1}\PY{p}{)}
              \PY{c+c1}{\PYZsh{}static data filter}
              \PY{n}{X\PYZus{}static} \PY{o}{=} \PY{n}{X}\PY{p}{[}\PY{n}{Y\PYZus{}pred\PYZus{}2class}\PY{o}{==}\PY{l+m+mi}{1}\PY{p}{]}
              \PY{c+c1}{\PYZsh{}dynamic data filter}
              \PY{n}{X\PYZus{}dynamic} \PY{o}{=} \PY{n}{X}\PY{p}{[}\PY{n}{Y\PYZus{}pred\PYZus{}2class}\PY{o}{==}\PY{l+m+mi}{0}\PY{p}{]}
              \PY{c+c1}{\PYZsh{}predicting static activities}
              \PY{n}{predict\PYZus{}static} \PY{o}{=} \PY{n}{model\PYZus{}static}\PY{o}{.}\PY{n}{predict}\PY{p}{(}\PY{n}{transform\PYZus{}data}\PY{p}{(}\PY{n}{X\PYZus{}static}\PY{p}{,}\PY{n}{scale\PYZus{}static}\PY{p}{)}\PY{p}{)}
              \PY{n}{predict\PYZus{}static} \PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{argmax}\PY{p}{(}\PY{n}{predict\PYZus{}static}\PY{p}{,}\PY{n}{axis}\PY{o}{=}\PY{l+m+mi}{1}\PY{p}{)}
              \PY{c+c1}{\PYZsh{}adding 4 because need to get inal prediction lable as output}
              \PY{n}{predict\PYZus{}static} \PY{o}{=} \PY{n}{predict\PYZus{}static} \PY{o}{+} \PY{l+m+mi}{4}
              \PY{c+c1}{\PYZsh{}predicting dynamic activites}
              \PY{n}{predict\PYZus{}dynamic} \PY{o}{=} \PY{n}{model\PYZus{}dynamic}\PY{o}{.}\PY{n}{predict}\PY{p}{(}\PY{n}{transform\PYZus{}data}\PY{p}{(}\PY{n}{X\PYZus{}dynamic}\PY{p}{,}\PY{n}{scale\PYZus{}dynamic}\PY{p}{)}\PY{p}{)}
              \PY{n}{predict\PYZus{}dynamic} \PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{argmax}\PY{p}{(}\PY{n}{predict\PYZus{}dynamic}\PY{p}{,}\PY{n}{axis}\PY{o}{=}\PY{l+m+mi}{1}\PY{p}{)}
              \PY{c+c1}{\PYZsh{}adding 1 because need to get inal prediction lable as output}
              \PY{n}{predict\PYZus{}dynamic} \PY{o}{=} \PY{n}{predict\PYZus{}dynamic} \PY{o}{+} \PY{l+m+mi}{1}
              \PY{c+c1}{\PYZsh{}\PYZsh{}appending final output to one list in the same sequence of input data}
              \PY{n}{i}\PY{p}{,}\PY{n}{j} \PY{o}{=} \PY{l+m+mi}{0}\PY{p}{,}\PY{l+m+mi}{0} 
              \PY{n}{final\PYZus{}pred} \PY{o}{=} \PY{p}{[}\PY{p}{]}
              \PY{k}{for} \PY{n}{mask} \PY{o+ow}{in} \PY{n}{Y\PYZus{}pred\PYZus{}2class}\PY{p}{:}
                  \PY{k}{if} \PY{n}{mask} \PY{o}{==} \PY{l+m+mi}{1}\PY{p}{:}
                      \PY{n}{final\PYZus{}pred}\PY{o}{.}\PY{n}{append}\PY{p}{(}\PY{n}{predict\PYZus{}static}\PY{p}{[}\PY{n}{i}\PY{p}{]}\PY{p}{)}
                      \PY{n}{i} \PY{o}{=} \PY{n}{i} \PY{o}{+} \PY{l+m+mi}{1}
                  \PY{k}{else}\PY{p}{:}
                      \PY{n}{final\PYZus{}pred}\PY{o}{.}\PY{n}{append}\PY{p}{(}\PY{n}{predict\PYZus{}dynamic}\PY{p}{[}\PY{n}{j}\PY{p}{]}\PY{p}{)}
                      \PY{n}{j} \PY{o}{=} \PY{n}{j} \PY{o}{+} \PY{l+m+mi}{1} 
              \PY{k}{return} \PY{n}{final\PYZus{}pred}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}170}]:} \PY{c+c1}{\PYZsh{}\PYZsh{}predicting }
          \PY{n}{final\PYZus{}pred\PYZus{}val} \PY{o}{=} \PY{n}{predict\PYZus{}activity}\PY{p}{(}\PY{n}{X\PYZus{}val}\PY{p}{)}
          \PY{n}{final\PYZus{}pred\PYZus{}train} \PY{o}{=} \PY{n}{predict\PYZus{}activity}\PY{p}{(}\PY{n}{X\PYZus{}train}\PY{p}{)}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}173}]:} \PY{c+c1}{\PYZsh{}\PYZsh{}accuracy of train and test}
          \PY{k+kn}{from} \PY{n+nn}{sklearn}\PY{n+nn}{.}\PY{n+nn}{metrics} \PY{k}{import} \PY{n}{accuracy\PYZus{}score}
          \PY{n+nb}{print}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Accuracy of train data}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}\PY{n}{accuracy\PYZus{}score}\PY{p}{(}\PY{n}{Y\PYZus{}train}\PY{p}{,}\PY{n}{final\PYZus{}pred\PYZus{}train}\PY{p}{)}\PY{p}{)}
          \PY{n+nb}{print}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Accuracy of validation data}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}\PY{n}{accuracy\PYZus{}score}\PY{p}{(}\PY{n}{Y\PYZus{}val}\PY{p}{,}\PY{n}{final\PYZus{}pred\PYZus{}val}\PY{p}{)}\PY{p}{)}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
Accuracy of train data 0.9832698585418934
Accuracy of validation data 0.9684424838819138

    \end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}182}]:} \PY{c+c1}{\PYZsh{}confusion metric}
          \PY{n}{cm} \PY{o}{=} \PY{n}{metrics}\PY{o}{.}\PY{n}{confusion\PYZus{}matrix}\PY{p}{(}\PY{n}{Y\PYZus{}val}\PY{p}{,} \PY{n}{final\PYZus{}pred\PYZus{}val}\PY{p}{,}\PY{n}{labels}\PY{o}{=}\PY{n+nb}{range}\PY{p}{(}\PY{l+m+mi}{1}\PY{p}{,}\PY{l+m+mi}{7}\PY{p}{)}\PY{p}{)}
          \PY{n}{cm}
\end{Verbatim}


\begin{Verbatim}[commandchars=\\\{\}]
{\color{outcolor}Out[{\color{outcolor}182}]:} array([[486,  10,   0,   0,   0,   0],
                 [  3, 465,   3,   0,   0,   0],
                 [  1,   2, 417,   0,   0,   0],
                 [  1,   2,   0, 447,  41,   0],
                 [  0,   0,   0,  27, 505,   0],
                 [  0,   0,   0,   3,   0, 534]])
\end{Verbatim}
            
    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}184}]:} \PY{n}{plt}\PY{o}{.}\PY{n}{figure}\PY{p}{(}\PY{n}{figsize}\PY{o}{=}\PY{p}{(}\PY{l+m+mi}{8}\PY{p}{,}\PY{l+m+mi}{8}\PY{p}{)}\PY{p}{)}
          \PY{n}{labels}\PY{o}{=}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{WALKING}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{WALKING\PYZus{}UPSTAIRS}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{WALKING\PYZus{}DOWNSTAIRS}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{SITTING}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{STANDING}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{LAYING}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}
          \PY{n}{plot\PYZus{}confusion\PYZus{}matrix}\PY{p}{(}\PY{n}{cm}\PY{p}{,} \PY{n}{classes}\PY{o}{=}\PY{n}{labels}\PY{p}{,} 
                                \PY{n}{normalize}\PY{o}{=}\PY{k+kc}{True}\PY{p}{,} \PY{n}{title}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Normalized confusion matrix}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{cmap} \PY{o}{=} \PY{n}{plt}\PY{o}{.}\PY{n}{cm}\PY{o}{.}\PY{n}{Greens}\PY{p}{)}
          \PY{n}{plt}\PY{o}{.}\PY{n}{show}\PY{p}{(}\PY{p}{)}
\end{Verbatim}


    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{output_244_0.png}
    \end{center}
    { \hspace*{\fill} \\}
    
    Divide and Conquer approch with CNN is giving good result with final
test accuracy of \textasciitilde{}0.97. and train accuracy
\textasciitilde{}0.98.


    % Add a bibliography block to the postdoc
    
    
    
    \end{document}
